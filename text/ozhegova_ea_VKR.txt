БУ ВО Ханты-Мансийского автономного округа – Югры
«СУРГУТСКИЙ ГОСУДАРСТВЕННЫЙ УНИВЕРСИТЕТ»
Политехнический институт

Кафедра прикладной математики ОЖЕГОВА ЕКАТЕРИНА АЛЕКСЕЕВНА
АЛГЕБРАИЧЕСКИЙ МНОГОСЕТОЧНЫЙ МЕТОД
РЕШЕНИЯ СИСТЕМ ЛИНЕЙНЫХ АЛГЕБРАИЧЕСКИХ УРАВНЕНИЙ НА ГРАФИЧЕСКИХ УСКОРИТЕЛЯХ

БАКАЛАВРСКАЯ РАБОТА
по направлению 01.03.02 «Прикладная математика и информатика» направленность (профиль): «Прикладная математика и информатика»



Научный руководитель: старший преподаватель каф. ПМ Бычин И.В.

(подпись) Допущено к защите:
	20	
Зав. кафедрой ПМ,
доцент, к.ф.-м.н. Гореликов А.В.

(подпись) Студент гр. № 601-01
Ожегова Екатерина Алексеевна


(подпись)

Сургут 2024 г.



Содержание
ВВЕДЕНИЕ	3
Глава 1. Многосеточные методы: этапы развития, современное состояние и программные библиотеки	5
Глава 2. Численное решение внутренних краевых задач для уравнения Пуассона	12
2.1Постановка задачи и математическая модель	12
2.2Дискретный аналог уравнения Пуассона	13
Глава 3. Алгебраический многосеточный метод	15
3.1Введение	15
3.2Алгоритмы построения	16
3.3Сходимость метода	19
3.4Свойства оператора сглаживания	21
3.5Свойства операторов интерполяции и коррекции	23
Глава	4.	Архитектура  графического  ускорителя  и  специфика  его программирования	27
4.1Архитектура графического ускорителя	27
4.2Технологии  параллельного  программирования  графического ускорителя	32
Глава 5. Результаты тестовых расчетов	39
ЗАКЛЮЧЕНИЕ	72
Список литературы	73
Приложение	79


ВВЕДЕНИЕ

Актуальность
Решение систем линейных алгебраических уравнений (СЛАУ) представляет собой один из наиболее важных и доминирующих моментов вычислительной процедуры с точки зрения затрат машинных ресурсов. Применение разностных схем при решении большинства задач механики сплошных сред приводит к большим сильно разреженным СЛАУ. В зависимости от типа исходного дифференциального уравнения и способа его аппроксимации могут использоваться различные численные методы для решения таких систем. К наиболее универсальным и потенциально масштабируемым методам, активно используемым в настоящее время, можно отнести многосеточные методы. Две ключевые особенности этих методов:
() арифметических действий, где  – размер матрицы СЛАУ;
скорость сходимости не зависит от размера задачи,

делают многосеточные методы наиболее востребованными при проведении численного моделирования на массивно параллельных вычислительных устройствах типа графических ускорителей. Одной из задач ВКР является оценка перспектив применения графических ускорителей для решения больших разреженных СЛАУ, в частности получаемых при дискретизации уравнения Пуассона.
Цели и задачи

Цель работы: разработать, отладить и протестировать вычислительную программу для численного решения алгебраическим многосеточным методом на графических ускорителях систем линейных алгебраических уравнений, которые получаются в результате дискретизации уравнения Пуассона.



Задачи:

1.Изучить алгебраический многосеточный метод.
2.Изучить особенности архитектуры современных графических ускорителей и их параллельные технологии программирования.
3.Исследовать существующие программные библиотеки для графических ускорителей, реализующие алгебраический многосеточный метод.
4.С использованием выбранной библиотеки и технологии параллельного программирования разработать вычислительную программу для численного решения дискретного аналога уравнения Пуассона на графических ускорителях.
5.Провести серию тестовых расчётов и проанализировать эффективность алгебраического многосеточного метода для решения внутренних краевых задач для уравнения Пуассона.



Глава 1. Многосеточные методы: этапы развития, современное состояние и программные библиотеки
Историю зарождения многосеточных методов принято вести с работы [1] 1961 года советского математика Федоренко Р.П. Федоренко сформулировал итерационный метод решения разностных краевых задач, основанный на введении дополнительных сеток для уменьшения объёма вычислений и получил простейшую оценку скорости сходимости многосеточного метода [2] при решении задачи Дирихле для уравнения Пуассона. Математический аппарат исследования свойств и эффективности многосеточных методов основан на применении Фурье-анализа вектора невязки, получаемой при решении СЛАУ итерационным методом. Фурье-анализ показывает [3-5], что на основе нескольких уровней сеточной аппроксимации уравнения, многосеточные методы разрешают конфликты между высокочастотными (аппроксимация на подробной сетке) и низкочастотными (аппроксимация на грубой сетке) компонентами решения, позволяя достигать высокой скорости сходимости и эффективности метода решения СЛАУ.
Дальнейшее развитие многосеточный метод получил в работе Бахвалова Н.С. [6], в которой была исследована сходимость метода для общего эллиптического уравнения с гладкими коэффициентами. Позднее Астраханцевым Г.П. в работе [7] был получен подобный результат для разностной аппроксимации третьей краевой задачи для самосопряжённого эллиптического уравнения в произвольной двухмерной области с гладкой границей. Хотя основная идея Федоренко – комбинирования дискретизаций на различных сетках для итерационной схемы, была вполне естественной, потенциал этой идеи не получил развития до середины 1970-ых.
Зарубежом многосеточный метод был заново открыт Брандтом [8] в 1973 году и получил широкое признание благодаря статье Бранта [3] и докладу



Хакбуша [9]. Количество публикаций по данной тематике стало стремительно расти. В 1981 году в Кёльне состоялась первая международная конференция по многосеточным методам. Данное событие считается важной вехой развития многосеточных методов. В 1982 году были опубликованы материалы конференции [10] под редакцией Хакбуша и Троттенберга. Начальный этап развития многосеточных методов завершился с выходом в свет работы [11] Хакбуша 1985 года с изложением теоретических основ и прикладных аспектов.
Большой вклад в развитие многосеточных методов внесли советские и российские ученые. Государственная премия РФ в области науки и техники 2003 г. за «Цикл основополагающих работ по созданию и последующее внедрение высокоэффективного многосеточного метода численного решения широкого класса задач математической физики» вручена д.ф.-м.н. Астраханцеву Г.П., академику РАН Бахвалову Н.С., д.ф.-м.н. Федоренко Р.П., член-корр. РАН Шайдурову В.В. [12]. Также необходимо отметить вклад отечественных ученных: Кузнецова Ю.А., Тишкина В.Ф., Жукова В.Т. [13], Ольшанского М.А. [14], Мартыненко С.И. [15].
В настоящее время многосеточные методы используются почти во всех областях, где уравнения в частных производных решаются численными методами. Многосеточные методы [16] относятся к группе итерационных решателей и являются одними из наиболее эффективных и распространенных методов решения больших разреженных СЛАУ [17]. В современных численных методах используются многоуровневые многосеточные методы с явным (геометрические многосеточные методы, ГММ) и с неявным (алгебраические многосеточные методы, АММ) построением последовательности сеток. Основная разница [18] между подходами заключается в том, что в АММ не требуется информации о геометрии области [19]. В методе ГММ [16] используются иерархии фиксированных сеток, и поэтому эффективное взаимодействие между сглаживанием и коррекцией грубой сетки должно быть



обеспечено путем выбора соответствующих операторов сглаживания. С другой стороны, метод АММ [18, 19] сводит сглаживание решения к некоторой простой схеме релаксации и обеспечивает эффективное взаимодействие с коррекцией грубой сетки путем выбора подходящих более грубых уровней и интерполяции.
Реализация алгебраического многосеточного метода [20] состоит из шага формирования сеток (матриц) на различных уровнях и шага решения. В процессе создания последовательности грубых сеточных уровней используется информация, которая содержится в матрице коэффициентов системы разностных уравнений. В соответствии с выбранным способом формирования сеток определяется оператор интерполяции с грубой сетки на подробную. Число узлов (уравнений) на самой грубой сетке обычно выбирается достаточно малым, что позволяет применить для решения системы разностных уравнений прямой метод.
ГММ представляются подходящими для решения нелинейных задач, поскольку нелинейности исходной системы уравнений передаются вниз по иерархии сеток (от подробной сетки к грубой). АММ применяются в тех областях, где применение геометрических методов является непрактичным [21] или сталкивается с серьезными трудностями: неструктурированные сетки, анизотропные задачи, декомпозиция области и др. АММ требуют значительного времени для инициализации, в связи с чем не применяются для решения систем разностных уравнений малого и среднего размера, а также при использовании дискретизации низкого порядка. В [22] проводится подробное сравнение методов ГММ и АММ. Методы реализуют схожие этапы. Первый – генерация более грубых сеток (уровней) с последующей передачей информации между различными сетками (операторы ограничения и продолжения). Затем линейная система на каждой сетке решается итерационным сглаживателем (решателем) в соответствии с выбором многосеточного цикла (F-цикл, V-цикл, W-цикл) [16].



В работах [23–25] исследована зависимость времени решения СЛАУ методами ГММ и АММ от числа неизвестных, типа цикла и их количества. В работе [26] проведено сравнение производительности ГММ и АММ как с распараллеленными, так и с предварительно обусловленными алгоритмами, подходящими для нелинейной системы дифференциальных уравнений. В результате тестов вычислительная производительность АММ оказалась выше, чем у ГММ. Систематические исследования многосеточных параметров были обнаружены только для ГММ. Так в статье [27] представлены теоретические и численные результаты для ГММ на треугольных сетках. Многосеточные методы активно используется в вычислительной гидродинамике. Наиболее ранние результаты в данном направлении представлены в [28, 29].
Реализация алгебраического многосеточного метода (AMG) рассматривалась многими авторами [18, 30]. В частности, несглаженная агрегация, основанная на локальных эвристиках, изучалась в [31–33], сглаженная агрегация была предложена в [34, 35], а классический подход, основанный на глобальной эвристике, рассмотрен в [36]. Сама реализация AMG на различных параллельных компьютерных платформах на базе CPU рассматривалась в [37– 39]. Методы AMG широко используются в качестве предобуславливателей для итерационных методов типа Крылова при решении общих разреженных линейных систем, когда отсутствует информация о происхождении системы [40, 41, 16].
В данной главе будут рассмотрены некоторые из существующих методов для разработки AMG на распределенных платформах с несколькими графическими процессами: AMGX, BootCMathG, LAMA, XAMG, BoomerAMG, AMGCL [42].
Библиотека AMGX [42] реализует алгебраический многосеточный метод и другие итерационные методы с предобуславливанием для решения СЛАУ на



GPU [42]. В ней содержится множество стандартных и гибких итерационных методов подпространства Крылова, которые можно комбинировать с любыми доступными многосеточными методами. Алгоритм AMG, реализованный в данной библиотеке AMGX, обеспечивает ускорение в 2-5 раз на одном GPU по сравнению с параллельной реализацией на CPU.
BootCMathG – одна из программных реализаций AMG, имеющая модульную структуру [30] с различными компонентами для настройки метода и для его применения в качестве предобуславливателя в оптимизированной версии метода сопряженных градиентов [43]. Данная библиотека обеспечивает гибкость в отношении особенностей задачи и требований к сходимости и точности. Метод, описанный в BootCMathG, основан на стратегии, которая составляет разнообразные иерархии AMG и собирает их аддитивным или мультипликативным способом для получения желаемой скорости сходимости [44, 45]. В настоящее время в качестве сглаживателя в библиотеке используется параллельная версия метода Якоби, реализованная для GPU.
Библиотека для ускоренных математических приложений LAMA [46] – это проект с открытым кодом, расположенным в [47]. Пакет разделен на две части: библиотека С, обеспечивающая функциональность BLAS (Basic Linear Algebra Subprograms – базовые подпрограммы линейной алгебры) для плотных и разреженных типов, и часть С++, которая поддерживает расширяемость и обеспечивает математический синтаксис. Кроме того, в ней реализована специализация сглаживателя Якоби для различных форматов хранения разреженных матриц.
Библиотека XAMG так же предназначена для решения больших разреженных систем линейных алгебраических уравнений [48]. Данная библиотека содержит реализацию набора итерационных методов решения СЛАУ, широко используемых для решения эллиптических уравнений, а именно:



набор методов подпространства Крылова, классический алгебраический многосеточный метод (на основе библиотеки hypre), метод итераций Чебышева, Якоби и Гаусса-Зейделя. Отличительной особенностью библиотеки является возможность решения СЛАУ со многими правыми частями. Библиотека XAMG реализована на языке С++ и основана на стандарте С++11. Дополнительно разработан API сопряжения для вычислительных кодов, реализованных на языке С. В коде [49] предусмотрена поддержка гибридного трехуровневого распараллеливания на основе модели программирования MPI+POSIX shared memory, что позволяет учесть особенности NUMA-архитектуры. В коде реализован ряд специфических оптимизаций, таких как: возможность использования смешанной точности, сжатие целочисленных типов представления индексов матриц, флаги нулевых векторов, векторизация вычислений по правым частям, и ряд других.
BoomerAMG [50] является наиболее распространенным линейным решателем и предобуславливателем в HYPRE. Его можно использовать как решатель или как предобуславливатель [51]. Пользователь может выбирать между различными параллельными методами огрубления, схемами интерполяции и релаксации. Последняя версия BoomerAMG применяется для решения уравнения Лапласа и класса двумерных уравнений радиационной диффузии. Численные результаты показывают, что данный метод обеспечивает лучшую масштабируемость и эффективность.
В данной ВКР использована библиотека AMGCL [61] с открытым исходным кодом, реализующая AMG. Библиотека поддерживает вычисления и в общей, и в распределённой памяти, имеется возможность распараллеливания посредством технологий OpenMP, OpenCL, CUDA. При работе с AMGCL предоставляется возможность ее расширения и добавления новых типов данных. Кроме  того,  библиотека  имеет  минимальный  набор  зависимостей  и



поддерживает современные многоядерные архитектуры, в том числе и графические ускорители.
Основополагающая идея Федоренко оказалась весьма плодотворной. За прошедшие полвека многосеточные методы так и не достигли апогея своего развития [15]: постоянно появляются новые области применения многосеточных методов, в которых они продолжают демонстрировать свою удивительную вычислительную эффективность, в том числе и на современных графических ускорителях.



Глава 2. Численное решение внутренних краевых задач для уравнения Пуассона
2.1Постановка задачи и математическая модель

Рассматривается задача о стационарном распределении температуры
(, , )	в	параллелепипеде	 = {(, , ): 0 <  < , 0 <  < , 0 <  < }
(рис. 1), заполненном однородной изотропной теплопроводящей средой.


Рис. 1. Расчетная область 

Математической моделью задачи является уравнение Пуассона:

(, , ) = (, , )	(7)


(где T – температура,  = 


– источниковый член, f – плотность тепловых

источников, k –	коэффициент теплопроводности) с заданными краевыми условиями на границе области :


( +  )|





= 	(8)

(где , ,  – заданные непрерывные функции на , причем   0,   0,
 +  > 0).



2.2Дискретный аналог уравнения Пуассона

Получим дискретный аналог уравнения (7) методом контрольного объема. Для этого разобьем расчетную область на непересекающиеся контрольные объемы. В центре каждого контрольного объема выберем расчетную точку . На рис. 2 изображен типичный контрольный объём для расчётной точки , где , , , , ,  – соседние расчётные точки, а , , , ,
,  – грани между соседними контрольными объемами, ,  и  длина, ширина и соответственно высота контрольного объёма. Далее будем рассматривать равномерную сетку, т.е.  =  = .


Рис 2. Типичный контрольный объем для расчетной точки 

Тогда получим:





2
2  + 


2
2  + 


2
2  =   ,


(где cv – контрольный объём,  =			);
	  




	

 2

	

 2

	

 2

   2  +    2  +    2 

		


		

		

		

=      ;
		


	





	





   (|   |  )  +   (|	 | ) 

		
	  




			

+    (|  | )  = ,
			
(где  – сеточное значение источникового члена  в расчетной точке , 
– объем контрольного объёма, ).

Аппроксимируя производные в окрестности точки , получим:


  

  

  

  

  

  

(
(

)


(

)

) + (

( )



( )


) + (

(

)


(

)
)

= ,

(где , ,  – расстояние между соседними узловыми точками по ,  и 
соответственно (см. рис 2).

В итоге дискретный аналог уравнения (7) запишется в виде (9).

T =  T + T + T + T + T +  T + ,	(9)

где 	=  ,		=  ,		=  ,	  =  , 	=  ,		= 

	()

	()

	()

	()

	()

	()


 =  +  +  +  +  + ,	 = .

Подробный алгоритм нахождения дискретного аналога описан в [52–54].



Глава 3. Алгебраический многосеточный метод

3.1Введение

В	основе описания	алгебраического	многосеточного метода	лежит алгоритм, рассмотренный в [55].
Решаем систему вида

 = ,	(10)

где   	матрица, ,   	вектора. Формируем последовательность систем для того, чтобы решить систему (10) аналогично многосеточному методу:
 = , 1    ,	(11)

где 1 = ,   ,  < 1  для 2    . Системы при   2
соответствуют системам уравнений на грубых сетках.

Определение 1.1. Определим операторы


	:	R+1

>	R

,	интерполяция (пролонгация)

+1

(грубая сетка)

(мелкая сетка)



+1 :	R

>	R+1

,	сужение (рестрикция)

	(мелкая сетка)

(грубая сетка)

: R > R.	оператор сглаживания
Имея   последовательность   операторов   ,   ,    
+1 , +1  +1	можно построить метод, подобный многосеточному. Пусть  > 0 – симметричная положительно определенная матрица, оператор интерполяции   задан и имеет полный ранг. Тогда можно
задать
+1 = (	),	оператор сужения	(12)
	+1
+1 = +1	,	система на грубой сетке	(13)
	+1



 =   ()1,	оператор сглаживания	(14)

 =   	(+1)1+1,	оператор коррекции на грубой сетке	(15)
+1	
где  – единичная матрица необходимого размера.

При таком выборе  является ортогональным проектором. Сглаживание
 принимает общий вид, а элемент  зависит от используемого метода:

Метод Гаусса-Зейделя:  – нижняя треугольная часть  с диагональю.
Метод Якоби:  диагональ , помноженная на скаляр.
Метод неполной факторизации:  =  =  + , где  – ошибка разложения.
Для метода Гаусса-Зейделя и метода Якоби построение и обращение ()1 является тривиальным и вычислительно недорогим. А кроме того, второй метод поддается распараллеливанию.
При задании оператора интерполяции  получаем все необходимые составляющие для дальнейшего построения AMG.
3.2Алгоритмы построения

Определение 2.1. Введем  – сетку на уровне , элементы которой представлены действительными числами [1, ], а связи – оператором .
Определение 2.2. Введем множество связей элемента ,  = { :   0,   }.
Определение 2.3. Введем /-разбиение на уровне  для сетки  =   , где  – множество элементов сетки , представленных на грубой сетке +1 =   , а F – множество элементов, представленных только на мелкой сетке F = \.



Определение 2.4. Определим действие оператора интерполяции 	:  >
   на вектор +1  +1

+1	  ,

 = 	+1 = { 

(16)

+1

 +1

  ,

	  

где    – множество интерполяционных связей элемента  на уровне  с
	
вектором	весов	 = {  0 :   }.	Таким	образом,	интерполяция
		
элемента  определяется множеством связей  и вектором весов .
	
На уровне  интерполятор 	, сужение +1 и система на грубом
+1	
уровне +1 строятся в три этапа:

Для всех элементов выберем /-разбиение.
Для каждого элемента  выберем множество  и веса .
	
Посчитаем +1 = (+1) и +1+1	.
			+1
Описанные шаги являются настройкой AMG. Реализация данного этапа представлена Алгоритмом 1.

Определение 2.5. Назовем элемент  связанным сильно с элементом   ,
если ||   max ||, где 0 <  < 1, обычно  = 1/4.









Определение	2.6.	Определим	 = { : ||   max ||}	–	множество

	





сильных связей элемента ,   , введем множество смежных сильных
	
связей элемента , () = { :   }.
	
Выборка /-разбиение на уровне  происходит согласно определенным подходам:
1. должно быть максимальным подмножеством всех элементов ,
с условием, что никакие два элемента из  не являются сильно связанными.

2.   каждый элемент    должен либо принадлежать ,
либо должен быть сильно связан хотя бы с одним элементом из   .

Алгоритм 2 находит первоначальное приближение к множеству .
Алгоритм ищет множество, выбирая  с максимальным значением  = |() 
|+2|()  |, тем самым отбирая элементы с наибольшим числом связей.


Определение 2.7. Определим  = \ – множество пропущенных связей.
		
Определение 2.8. Определим разбиение множества пропущенных связей  =
  , где  =    – множество сильных пропущенных связей и  =
					
\ – множество слабых пропущенных связей.
	



Необходимое расширение данного множества описано в Алгоритме 3.
Для каждого элемента    производится проверка, что каждый элемент из 
имеет сильную связь к хотя бы одному элементу из .


Для	определения	интерполятора	Алгоритмом	4	устанавливаются соответствующие веса.


3.3Сходимость метода

Сходимость	метода		зависит	от	действия		на	полученную	ошибку операторов	сглаживания		и	коррекции	на	грубой	сетке	.		Далее



представлены	некоторые	теоремы	о	сходимости	метода,	где	заданы определенные свойства рассматриваемых операторов.
Определение 3.1. Назовем ошибкой вектор    приближенного решения
  ,	заданный	 =   .	Скорость	сходимости	метода определяется уменьшением нормы ошибки после применения метода.
Определение	3.2.	Введем	скалярное	произведение	вида	, =
(()1)1, 	для	векторов	,   ,	где	 = ()	и соответствующую норму |||| = v,.
Определение 3.3. Введем  – оператор рекурсивной коррекции на грубой сетке с использованием -цикла.
Отличие  от  заключается в неточном обращении (+1)1 в первом операторе.
Теорема 3.1. При условиях  > 0, 	имеет полный ранг и (12)-(13) и предположении, что 1 > 0 :    выполняется условие
||| 2  ||| 2   ||| 2,	(17)
|	|	|
1	1	1
где 1 не зависит от  и . Тогда 1 < 1, при условии, что система  решается точно и оператор сглаживания применяется после шага коррекции на грубой сетке , то скорость сходимости -цикла для системы (10) ограничена сверху

 = v1  1.
Доказательство теоремы представлено в [55].
Теорема 3.2. Если при тех же условиях вместо условия (17) выполняется условие
||| 2  ||||2   ||| 2,	(18)
|	|
1	1	1



и оператор сглаживания применяется перед шагом коррекции на грубой сетке
, то скорость сходимости -цикла для системы (10) ограничена сверху  = 1/v1 + 2.
Доказательство теоремы представлено в [55].
Следствие 3.2.1. Если оператор сглаживания  применяется и перед и после шага коррекции на грубой сетке  и условия (17) и (18) выполняются с параметрами 1 и 2, соответственно, то скорость сходимости -цикла ограничена сверху  = v(1  1)/(1 + 2).
Условие (17) можно заменить на пару условий
||| 2  ||| 2   ||| 2, || 2  ||| 2	(19)
|	|	|	|	|	|
1	1	2	1	2
тогда 1 = 1/ и аналогично (18) можно заменить на пару условий
||| 2  ||| 2   ||| 2, || 2  ||| 2,	(20)
|	|	|	|	|	|
1	1	2	1	2
тогда 2 = 2/. Таким образом, 1 и 2 определяют свойство оператора сглаживания , а  определяет свойство оператора коррекции на грубой сетке
.

Следствие 3.2.2. Оператор сглаживания  должен уменьшать те компоненты ошибки , которые  не затрагивает. И наоборот, т.е. образы линейных операторов ортогональны ()  ().
3.4Свойства оператора сглаживания

Свойства оператора сглаживания  можно оценить, используя лемму, приведенную ниже. Далее опустим индекс уровня .
Лемма 4.1. Пусть оператор сглаживания  матрицы  > 0 имеет общий вид  =
  1, где  – не вырождена. Тогда неравенства вида




2
||||

2
 ||||

2
 1||||

2
, ||||

2
 ||||

2
 2||||

,	(21)

1	1	2	1	1	2
эквиваленты неравенствам вида

11   +   , 2(  )1(  )   +   ,	(22)
где  = ().

Доказательство леммы представлено в [55].

Теорема 4.1. Пусть  > 0 – симметричная, положительно определенная,   . Если оператор сглаживания  – метод релаксаций Гаусса-Зейделя, то  – нижняя треугольная часть  с диагональю. Тогда    :  зададим
	= max (  1		 |  |) , 	= max (  1		 |  |),	(23)

	1  

<		

+	1




>		



тогда



где 1, 2 параметры (21).



1




	1
(1+)(1++)



, 2




	1
+



,	(24)

Доказательство теоремы представлено в [55].
Следствие 4.1.1. Пусть  > 0 имеет ширину , т.е. не более  ненулевых элементов на строку. Выберем  = 1/v и получим  <  и + < , т.к. 2 <
. Таким образом, 1 = (1 + )2 и 2 = 2.
Замечание 4.1. Если  > 0 – диагонально доминантная матрица, т.е. || 
, то на практике можно ожидать +,  ~ 1, что дает более оптимистичные оценки.
Определение 4.1.   ,  > 0 является симметричной М-матрицей, если
  0 при   .



Замечание 4.2. Пусть  – симметричная М-матрица. Тогда  :  > 0. Выбирая
 =  в теореме 4.1, получим
	= max ( 1		 |  |) = max (1 	1		   ) < 1.	(25)

	1




< 



1




< 




Аналогично, получим + < 1. Таким образом, 1 = 1/4 и 2 = 1.
3.5Свойства операторов интерполяции и коррекции
Свойства	оператора	коррекции		зависит	от	свойств	оператора интерполяции 		. Построим оператор интерполяции. Согласно замечанию
3.2.2 образ интерполятора должен содержать ошибку оператора сглаживания. Рассмотрим свойства ошибок оператора сглаживания.
Определение 5.1. Назовем ошибку    гладкой, если ||||  ||||.

Для стандартных методов сглаживания, невязка от гладкой ошибки  =
 на практике является малой по отношению к самой ошибке  после нескольких итераций сглаживания. Таким образом, для гладкой ошибки выполняется свойство 2  1 или
 2
	( )   	,	(26)

=1




=1 	

откуда в среднем для любого  можно ожидать ||  ||.
		
Таким образом, хорошей аппроксимацией компоненты 	гладкой ошибки в зависимости от значений  из соседних элементов    является
	
выражение
 =  +     0.	(27)

		

	  


Исходя из (27) можно построить интерполятор взяв  =  и  =
		
/. Однако, как правило,  слишком велико, что при подобном выборе
		
приводит к сильному заполнению системы на грубой сетке +1. Следует



уменьшить	множество	.	Для	отбрасывания	связей	из	множества	
	
воспользуемся	следующим	свойством	симметричных	матриц.	Исходя	из неравенства Коши-Буняковского имеем


2	1/2


1/2

1	1

||||1 = , = 

,

  ||

2|| ||2|| = ||||2||||0,	(28)


тогда из ||||2  ||||1 следует ||||1  ||||0, что для симметричной матрицы 
приводит к


||||2 = , =  1   

(

2
  )  +  ( 

) 2   

2 = , = ||||2, (29)

1	2	

		

	

	

    	0

тогда если  ||   и матрица  является симметричной -матрицей, то в среднем для каждого  выполнено
2
 	 ()   1,	(30)
 	2

что означает, что ошибка меняется медленно в направлении сильных связей, если ||/ достаточно велико.
Замечание 5.1. Данные рассуждения не используют свойства и структуру конкретного оператора сглаживания . Используются наблюдения за поведением решения для специального вида матриц.
Замечание 5.2. Произведем /-разбиение для  следующим образом. Положим в  все элементы не имеющие связи друг с другом и определим веса
интерполяции   = /,   ,   .  Затем  сужение  и  система  на







грубом уровне вычисляются согласно (12)-(13) и процедура выбора узлов для
+1 повторяется. При таком построении ()  ( ). Тогда, на каждом уровне элементы можно упорядочить так, что ошибка после применения метода Гаусса-Зейделя для элементов из  равна нулю и метод сойдется за один - цикл.



Теорема 5.1. Пусть  > 0 и для оператора сглаживания  выполняется свойство
||| 2  ||| 2   ||| 2.	(31)
|	|	|
1	1	2
Пусть интерполятор 	имеет полный ранг и  выполнено

min  	+12  2,	(32)

+1

+1	0	1

где  > 0 не зависит от . Тогда   1 и выполняется неравенство

1  v1  1/1,	(33)

т.е. фактор сходимости  = v1  1/.
Доказательство теоремы представлено в [55].
Теорема 5.2. Пусть  > 0 и для произвольного выбранного множества -
элементов 	имеет вид (16), где   0 и    1. Тогда свойство (32)

+1





выполнено, если  > 0 не зависящего от  такое, что
	 (  )2     (   2,


 



		



2
,

	

  )



(34)

  (1    ) ()2    ( ) ()2.







	


	

	




Доказательство теоремы представлено в [55].
Разобьём множество связей -го элемента на два множества  =  
.	Множество	связей	    	состоит	из	элементов,	которые
		
используются при интерполяции, а  – которые пропускаются. Для элементов
   зададим веса



 = ||,   ,   ,	(35)
		

где  параметр удовлетворяющий

0    (||)	,	(36)

введенный для выполнения условия	   1 теоремы (5.2). Чтобы выполнялось свойство (32) согласно теореме 5.2 достаточно потребовать  
,   :

0    ||, 0  (1   )    .	(37)









	




Следствие	5.2.1.	Пусть	  1	фиксировано,		–	симметричная	слабо диагонально – доминантная М-матрица, а множество  выбрано так, что  
 :        и выполняется свойство в ( +  )  ,

	

	
  1



определим веса интерполяции согласно (35) с  = ( +   )	, тогда
свойство (32) выполнено.
Замечание 5.3. Достаточно задать   1 и строить интерполятор автоматически согласно следствию 5.2.1 для заданного /-разбиения. Чем больше , тем слабее (32) и тем хуже сходимость.
Теорема 5.3. Пусть  - симметричная слабо диагонально – доминантная - матрица и веса интерполяции удовлетворяют (37) с   2, тогда +1 имеет те же свойства, что и .
Доказательство теоремы представлено в [55].



Глава	4.	Архитектура	графического	ускорителя	и	специфика	его программирования
4.1Архитектура графического ускорителя

В данном пункте изложение базируется на обзорных статьях [56–58].
Говоря простым языком, графический ускоритель (GPU) состоит из набора потоковых мультипроцессоров SM. Каждый из них может обрабатывать от 1024 нитей одновременно. Количество нитей зависит от модели видеокарты и объёма памяти DRAM, который сейчас составляет от 2 до 16 ГБ.
Поскольку существует множество различных архитектур графических ускорителей, необходимо определить, какая архитектура будет использоваться для разработки высокопроизводительной программы. Мы проводим вычисления на графическом ускорителе Nvidia Titan V (вычислительная архитектура Nvidia Volta), так как CUDA работает только с ускорителями этой компании.
Данная видеокарта основана на графическом чипе GV100. В графическом процессоре архитектуры Volta используется 16 ГБ памяти высоких скоростей с пропускной способность в 1.5 раза выше, чем у GPU прошлого поколения.
Новый процессор GV100 имеет сходства с GP100 (Nvidia Pascal) благодаря наличию нескольких вычислительных кластеров Graphics Processing Cluster (GPC), включающих кластеры Texture Processing Cluster (TPC), а также контроллеров памяти. А вторые в свою очередь заключают в себе несколько Streaming Multiprocessor (SM) – потоковых мультипроцессоров.
На рис. 3 представлен полноценный процессор GV100, имеющий 84 мультипроцессора SM. При этом в GPU Titan V используется вариант с 80 активными мультипроцессорами. Полная версия чипа архитектуры Volta имеет 6 кластеров GPC и 42 кластера TPC, которые содержат по 2 SM каждый.





Рис 3. Архитектура Volta GV100


Приведем сравнение четырех последних графических ускорителей, выпущенных компанией Nvidia, по их основным характеристикам и пиковым показателям производительности (расчеты выполнены на основе турбо-частот GPU) (таблица 1). Согласно данным из таблицы видно значительное повышение производительности различных типов вычислений.
Усовершенствование чипа привело к его усложнению – GV100 (Volta) втрое сложнее ускорителя с архитектурой Kepler – однако благодаря совершенствованию в том числе технологических процессов размер этого графического ускорителя вырос всего в полтора раза.



Таблица 1. Сравнение ускорителей Tesla K40, Tesla M40, Tesla P100, TitanV




В архитектуре графического ускорителя Volta были проведены большие изменения, которые привели к увеличению производительности SM. Мультипроцессор в GV100 разделен на 4 блока обработки, имеющих по 16 FP32- ядер, 8 FP64-ядер, 16 INT32-ядер, два новых тензорных ядра, новый кэш инструкций, один планировщик варпов, один блок диспетчера и регистровый файл на 64 Кб. На рис. 4 представлена подробная схема SM.

Рис. 4. Потоковый мультипроцессор Volta GV100 (SM)



В ранних версиях GPU применялись буферы инструкций. Рассматриваемая видеокарта содержит в каждом своем разделе новый кэш инструкций нулевого уровня, который обладает большей эффективностью. Благодаря проведенным поправкам, данный графический ускоритель способен поддерживать больше одновременно выполняемых потоков, варпов и блоков потоков, нежели предыдущие поколения видеокарт.
Рассмотрим ядро CUDA, или унифицированный потоковый процессор. Унифицированным его называют потому, что он может выполнять различные типы задач: пиксельные и вершинные шейдеры, а также физические и геометрические расчёты (рис. 5). Это скалярный процессор общего назначения, который может обрабатывать целочисленные данные и данные с плавающей точкой. В состав ядра входят два блока: INT Unit для работы с целочисленными операндами и FP Unit для обработки данных с плавающей точкой. Важно отметить, что эти ядра работают на удвоенной частоте видеокарты.

Рис. 5. Схема ядра CUDA


На самом деле изучать архитектуру каждой модели графического ускорителя заново нет никакой необходимости. Можно просто изучить её особенности, потому что каждая новая архитектура – это наследник предыдущей.



4.2Технологии параллельного программирования графического ускорителя
Одним из изменений в Titan V является появление новых эффективных алгоритмов управления потоками и варпами. Это сделано для перспективы упрощения программирования GPU, что поспособствует повышению продуктивности работы программистов.
Потоки видеокарты разделены на секции по 32 нити, которые называются warp. Нити одного warp физически выполняются одновременно, но нити из разных секций могут находиться на разных этапах выполнения программы. Программист может управлять warp с центрального процессора.
Видеокарта GV100 поддерживает независимое управление потоками, что определяет лучшую связь потоков и высокую точность синхронизации. Модель исполнения SIMT (single instruction, multiple thread – одна инструкция, много потоков) в процессоре Titan V обеспечивает использование равного параллелизма между всеми потоками. Для увеличения эффективности параллельного исполнения, в данном GPU имеется оптимизатор планирования (schedule optimizer), группирующий активные потоки в блоки SIMT.
Исполнение осуществляется по-прежнему по модели SIMT, при любом такте ядра CUDA выполняют одну и ту же последовательность действий для всех активных потоков. Способность Titan V контролировать потоки в рамках варпа позволяет выполнять более сложные алгоритмы и структуры данных.
CUDA – самая популярная и эффективная технология от компании NVIDIA для создания высокопроизводительного кода для вычислений на видеокарте. Чтобы качественно разработать программный код, необходимо разобраться в особенностях этого инструмента.
CUDA (Compute Unified Device Architecture) – программно-аппаратная вычислительная архитектура от NVIDIA, основанная на расширении языка C.



Она позволяет организовать доступ к набору инструкций графического ускорителя и управлять его памятью при параллельных вычислениях.
Основная идея разработки с применением этой технологии заключается в том, что графический ускоритель (GPU) выступает сопроцессором к центральному процессору (CPU). Программа запускается на CPU, но участки кода, которые могут быть эффективно распараллелены, выполняются на GPU одновременно в виде потоков (threads). У графического ускорителя есть собственная память.
На первый взгляд потоки GPU похожи на потоки CPU, однако это не совсем так.
1.В отличие от центрального процессора, на GPU создание и уничтожение нитей происходит очень быстро. Контекст нитей минимален, а регистры распределяются заранее.
2.Для того чтобы эффективно использовать возможности графического ускорителя, необходимо задействовать несколько тысяч нитей одновременно, тогда как центральному процессору достаточно всего лишь 15–20 потоков.
Код пишется на расширении языка C, хотя существует возможность использования языка C++. При таком подходе разработчик имеет больше контроля над GPU, нежели при использовании шейдерных языков программирования.
Говоря про расширение, имеется в виду включение новых конструкций: спецификаторов типа, встроенных переменных и типов, а также директив запуска ядра. Функция, выполняющаяся на видеокарте, называется ядром. При запуске программы каждая нить выполняет код ядра.
Общая модель написания кода для  GPU с использованием  CUDA
расположена в [59]:
1.Выделяем необходимую память на графическом процессоре;



2.Копируем данные из памяти центрального процессора в выделенную память графического процессора;
3.Производим запуск ядра (или последовательно запускаем несколько ядер);
4.Копируем результаты вычислений из памяти GPU в память CPU;
5.Освобождаем выделенную память GPU.
В технологии CUDA потоки объединены некоторой иерархией. Верхним уровнем является сетка (Grid), представляющая собой одномерный или двумерный массив блоков. Блоки имеют идентичный размер и состоят из одномерного, двумерного или трехмерного набора потоков (threads). На рис. 6 представлена иерархия потоков в технологии CUDA для двумерных сетки и блока.
Блоки обладают собственным адресом, который содержит одно или два положительных числа в зависимости от количества измерений сетки. Адрес потока также представлен положительными числами от 1 до 3 и зависит от размерности блока.

Рис. 6. Иерархия потоков в CUDA
Поскольку одновременно запускается огромное количество потоков, необходимо, чтобы их номер был определен ядром, и по этому номеру поток будет получать набор данных для обработки. Для этих целей используются встроенные переменные, которые помогают определить данные номера. Номер



вычисляется путем умножения номера потока в блоке на размер блока и добавления номера блока. Таким образом, с использованием переменных threadIdx и blockIdx можно вычислить индекс потока. Такие переменные представляют собой трехмерные векторы целых чисел. Для определения размера блока и сетки используются встроенные переменные gridDim и blockDim. Они доступны только на графическом устройстве, поскольку на центральном процессоре они не имеют значения.
Как было упомянуто ранее, данная технология использует язык «С» с дополнительными расширениями. Рассмотрим подробнее, что означает это расширение. Прежде всего, стоит отметить, что файл с исходным кодом на «С» для CUDA имеет расширение cu. Компилятор называется nvcc.
Расширения, которые добавляются в «С», можно разделить на следующие пункты:
1.Спецификаторы функций, которые указывают, откуда вызывается функция и где будет выполняться.
2.Спецификаторы переменных, указывающие на тип памяти, который используется для данных переменных.
3.Директивы, использующиеся для вызова функции-ядра, задания иерархии нитей и для указания данных.
4.Встроенные переменные, которые содержат информацию о потоке.
5.Runtime, содержащий дополнительные типы данных.
6.Добавленные функции.
Рассмотрим спецификаторы, которые используются в технологии CUDA (таблица 2).



Таблица 2. CUDA спецификаторы

Спецификатор	Место выполнения
функции	Место вызова
функции
	device		Видеокарта	Видеокарта
	host		Центральный процессор	Центральный процессор
	global		Видеокарта	Центральный процессор

Некоторые из спецификаторов могут быть использованы вместе [59]. Так, например, вместе можно использовать  host  и  device . Данный факт означает, что их можно вызывать одновременно как с GPU, так и CPU, код для обоих вариантов будет сгенерирован автоматически.
  global  описывает ядро, поэтому эта функция возвращает тип void.
Также на спецификаторы, которые указывают выполнение на видеокарте, налагаются некоторые ограничения. Например, нельзя брать адреса функций со спецификатором  device . Не поддерживаются рекурсивные вызовы функции. Нельзя внутри функций объявлять переменные со спецификатором static. А также нельзя делать функции с переменным числом аргументов.
В таблице 3 представлены спецификаторы CUDA, которые применяются для задания размещения переменных в памяти видеокарты.

Таблица 3. Спецификаторы переменных в CUDA

Спецификатор	Находится	Доступно	Вид доступа
	device		Видеокарта	Видеокарта	Только чтение
	constant		Видеокарта	Видеокарта и центральный процессор	Чтение для видеокарты и
запись для
центрального процессора
	shared		Видеокарта	Для блока потоков
видеокарты	Чтение и запись



На эти спецификаторы также накладывается ряд соответствующих ограничений. К полям структуры данные спецификаторы не применимы. Область их видимости – файл, поэтому их нельзя объявлять как extern.
Также стоить учесть, что переменные со спецификатором  shared не могут быть инициализированы при создании.
Добавленных переменных немного, большая часть из них были описаны выше, но для целостности укажем все их здесь.
1.blockIdx – переменная типа uint3, обозначающая индекс блока в сетке.
2.threadIdx – переменная типа uint3 – индекс потока в блоке.
3.gridDim – переменная типа dim3 – размер сетки.
4.blockDim – переменная типа dim3 – размер блока.
5.warpSize – переменная типа int – размер варпа.
Директива, добавленная для вызова функции-ядра, имеет следующую конструкцию:
NameKernel<<<DimGrids,DimBlocks,Nsize,Stream>>>( arguments); NameKernel – это имя функции, для которой указан спецификатор global.
В трёх угловых скобках указаны переменные, определяющие конфигурацию ядра. Первые два аргумента обязательны, вторые можно опустить. Аргумент DimGrids имеет тип dim3 и задаёт размеры и размерность сетки в блоках. Следующий аргумент задаёт размер и размерность блока в потоках.
Последние два аргумента не являются обязательными. Первый из них, Nsize, задает размер памяти, которую нужно дополнительно выделить для каждого блока при вызове ядра. В переменной указывается поток, в котором будет вызвана функция. В скобках вместо arguments может быть набор данных для функции-ядра, с которыми она будет работать. Эта технология поддерживает функции из стандартной математической библиотеки «С». Для многих функций доступны варианты с двойной и одинарной точностью. Перечислять их все не



имеет смысла, так как они указаны в документации, доступной на официальном сайте или по следующей ссылке [60].



Глава 5. Результаты тестовых расчетов

Используя разработанную программу (см. Приложение) для численного решения внутренней краевой задачи для уравнения Пуассона проведен ряд тестовых расчетов. В расчетах вычисляются локальные максимальные абсолютные  и относительные ошибки . Результаты тестов показывают, что разработанная численная схема обладает вторым порядком аппроксимации (см. табл. 4,7, 10, 13, 16, 19, 22, 25). Для всех тестов проведено качественное сопоставление аналитических решений с численным (см. рис. 7–33), которое показывает хорошее соответствие. В табл. 5, 8, 11, 14, 17, 20, 23, 26 проведено сравнение алгебраического многосеточного метода (АММ) с классическим итерационными методами, при решении дискретного аналога уравнения Пуассона на различных расчетных сетках. Сравнение проведено по количеству итераций, необходимого для достижения целевого значения евклидовой нормы невязки равной 10-10. Анализ этих результатов показывает, что АММ обладает превосходной скоростью сходимости. В табл. 6, 9, 12, 15, 18, 21, 24 проведено полное профилирование этапов работы алгебраического многосеточного метода на графическом ускорителе. Можно сделать вывод, что превалирующее время работы алгебраического многосеточного метода занимает предварительная настройка его параметров. Таким образом, полное превосходство алгебраического многосеточного метода раскрывается при решении на довольно больших СЛАУ.
Тест 1

 = {(, ): 0 <  < 1, 0 <  < 1 }:

 = 8 sin(2) sin(2);

Граничные условия:

D: T(, ) = 0,



Аналитическое решение:

(, ) = sin(2) sin(2).


Таблица 4. Максимальные абсолютные и относительные ошибки для теста 1

Сетка
  	абсT	отн, %
12  12	3,36  102	3,36
22  22	8,06  103	0,83
42  42	2,05  103	0,21
82  82	5,13  104	5,23  102


Таблица 5. Сравнение скорости сходимости методов решения СЛАУ для
теста 1




Сетка
  	
Алгебраический многосеточный метод	Метод Гаусса- Зейделя	Метод переменн ых направле
ний	Стабилизированн ый метод бисопряженных градиентов
	Кол-во уровней
V-цикла	Кол-во итераций	Кол-во итераций	Кол-во итераций	Кол-во итераций
12  12	1	1	198	56	8
22  22	1	1	708	190	16
42  42	1	1	2496	665	35
82  82	2	8	8637	2311	78



Таблица 6. Время решения СЛАУ на графическом ускорителе алгебраическим
многосеточным методом для теста 1



Сетка
  	

Общее время
решения СЛАУ, с	Временные затраты на выполнение этапов метода в процентах от общего времени
		Формирование матриц
коэффициентов СЛАУ, %	Настрой ка парамет ров решател я, %	Решение СЛАУ, %
12  12	0,179	0,01	96,53	1,31
22  22	0,183	0,02	98,39	1,25
42  42	0,197	0,04	98,14	1,5
82  82	0,236	0,12	91,86	7,75


Рис. 7. Распределение численного решения  в расчетной области для теста 1.
Расчетная сетка: 8282





Рис. 8. Распределение аналитического решения  в расчетной области для теста 1. Расчетная сетка: 8282
Рис. 9. Распределение абсолютной ошибки абсT в расчетной области для теста 1. Расчетная сетка: 82  82




Рис. 10. Распределение относительной ошибки отн в расчетной области для теста 1. Расчетная сетка: 82  82



Тест 2
 = {(, ): 0 <  < 1, 0 <  < 1 }:

 = 2((1  62)2(1  2) + (1  62)2(1  2));

Граничные условия:
D: T(, ) = 0,
Аналитическое решение:
(, ) = (2  4)(4  2).


Таблица 7. Максимальные абсолютные и относительные ошибки для теста 2

Сетка
  	
12  12	2,58  103
22  22	7,14  104
42  42	1,87  104
82  82	4,78  105



Таблица 8. Сравнение скорости сходимости методов решения СЛАУ для
теста 2




Сетка
  	
Алгебраический многосеточный метод	Метод Гаусса- Зейделя	Метод переменн ых направле ний	Стабилизированн ый метод бисопряженных градиентов
	Кол-во уровней
V-цикла	Кол-во итераций	Кол-во итераций	Кол-во итераций	Кол-во итераций
12  12	1	1	202	55	24
22  22	1	1	778	199	48
42  42	1	1	2995	754	90
82  82	2	8	11519	2884	180

Таблица 9. Время решения СЛАУ на графическом ускорителе алгебраическим
многосеточным методом для теста 2




Сетка
  	

Общее время решения
СЛАУ, с	Временные затраты на выполнение этапов метода
в процентах от общего времени
		Формирование матриц
коэффициентов СЛАУ, %	Настрой ка парамет ров решател
я, %	Решение СЛАУ, %
12  12	0,167	0,01	98,27	1,34
22  22	0,186	0,01	98,41	1,25
42  42	0,176	0,01	98,05	1,7
82  82	0,214	0,06	91,91	7,8





Рис. 11. Распределение численного решения T в расчетной области для теста 2.
Расчетная сетка: 82  82

Рис. 12. Распределение аналитического решения  в расчетной области для теста 2. Расчетная сетка: 82  82




Рис. 13. Распределение абсолютной ошибки  в расчетной области для теста 2.
Расчетная сетка: 82  82



Тест 3
 = {(, ): 0 <  < 1, 0 <  < 1 }:
 = 2(  1)(  2 +  + 2);
Граничные условия:
D: T(, ) = 0,
Аналитическое решение:
(, ) =  (  1)(  1).
Таблица 10. Максимальные абсолютные и относительные ошибки для теста 3

Сетка
  		, %
12  12	1,86  103	15,6
22  22	5,06  104	8,56
42  42	1,32  104	4,56
82  82	3,36  105	2,36
Таблица 11. Сравнение скорости сходимости методов решения СЛАУ для
теста 3




Сетка
  	
Алгебраический многосеточный метод	Метод Гаусса- Зейделя	Метод переменн ых направле
ний	Стабилизированн ый метод бисопряженных градиентов
	Кол-во уровней
V-цикла	Кол-во итераций	Кол-во итераций	Кол-во итераций	Кол-во итераций
12  12	1	1	205	56	23
22  22	1	1	795	204	48
42  42	1	1	3071	773	87
82  82	2	8	11838	2964	183



Таблица 12. Время решения СЛАУ на графическом ускорителе алгебраическим многосеточным методом для теста 3



Сетка
  	
Общее время
решения СЛАУ, с	Временные затраты на выполнение этапов метода в процентах от общего времени
		Формирование матриц
коэффициентов СЛАУ, %	Настройка параметро в решателя,
%	Решение СЛАУ,
%
12  12	0,168	0,01	98,25	1,37
22  22	0,162	0,01	98,22	1,42
42  42	0,162	0,01	98,07	1,69
82  82	0,200	0,11	90,48	9,08



















Рис. 14. Распределение численного решения T в расчетной области для теста 3.
Расчетная сетка: 82  82




Рис. 15. Распределение аналитического решения  в расчетной области для теста 3. Расчетная сетка: 82  82
Рис. 16. Распределение абсолютной ошибки  в расчетной области для теста 3.
Расчетная сетка: 82  82




Рис. 17. Распределение относительной ошибки  в расчетной области для теста 3. Расчетная сетка: 82  82



Тест 4
 = {(, ): 0 <  < 1, 0 <  < 1 }:

 = 2cos( ) + 42 sin(2);

Граничные условия:
T(0, ) = 1  sin(2),	T(1, ) = 1  sin(2); T(, 0) = cos( ),	T(, 1) = cos( ).
Аналитическое решение:
(, ) = cos( )  sin(2).


Таблица 13. Максимальные абсолютные и относительные ошибки для теста 4

Сетка
  	
12  12	3,26  102
22  22	8,04  103
42  42	2,01  103
82  82	5,04  104



Таблица 14. Сравнение скорости сходимости методов решения СЛАУ для
теста 4




Сетка
  	
Алгебраический многосеточный метод	Метод Гаусса- Зейделя	Метод переменн ых направле
ний	Стабилизированн ый метод бисопряженных градиентов
	Кол-во уровней
V-цикла	Кол-во итераций	Кол-во итераций	Кол-во итераций	Кол-во итераций
12  12	1	1	172	56	16
22  22	1	1	683	184	34
42  42	1	1	2570	536	67
82  82	2	7	9487	2311	128

Таблица 15. Время решения СЛАУ на графическом ускорителе алгебраическим многосеточным методом для теста 4




Сетка
  	

Общее время
решения СЛАУ, с	Временные затраты на выполнение этапов метода в
процентах от общего времени
		Формирование матриц
коэффициентов СЛАУ, %	Настрой ка парамет ров решател
я, %	Решение СЛАУ, %
12  12	0,195	0,01	98,41	1,27
22  22	0,190	0,01	98,32	1,34
42  42	0,170	0,01	97,94	1,8
82  82	0,231	0,05	92,63	7,02





Рис. 18. Распределение численного решения T в расчетной области для теста 4.
Расчетная сетка: 82  82

Рис. 19. Распределение аналитического решения  в расчетной области для теста 4. Расчетная сетка: 82  82




Рис. 20. Распределение абсолютной ошибки  в расчетной области для теста 4.
Расчетная сетка: 82  82



Тест 5
 = {(, ): 0 <  < 1, 0 <  < 1 }:

 = 82cos(4 )[cos(4)  sin(4)] 

162[sin(4) cos(2)2 + sin(2)2 cos(4)].

Граничные условия:
T(0, ) = 0,	T(1, ) = 0;
T(, 0) = T(, 1) = sin(2)2 + sin(4).
Аналитическое решение:
(, ) = sin(2)2 cos(4) + sin(4) cos(2)2.


Таблица 16. Максимальные абсолютные и относительные ошибки для теста 5

Сетка
  	
12  12	2,24  101
22  22	5,89  102
42  42	1,48  102
82  82	3,72  103



Таблица 17. Сравнение скорости сходимости методов решения СЛАУ для
теста 5




Сетка
  	
Алгебраический многосеточный метод	Метод Гаусса- Зейделя	Метод переменн ых направле
ний	Стабилизированн ый метод бисопряженных градиентов
	Кол-во уровней
V-цикла	Кол-во итераций	Кол-во итераций	Кол-во итераций	Кол-во итераций
12  12	1	1	202	54	17
22  22	1	1	793	203	38
42  42	1	1	3059	770	76
82  82	2	7	11764	2946	147

Таблица 18. Время решения СЛАУ на графическом ускорителе алгебраическим многосеточным методом для теста 5




Сетка
  	

Общее время
решения СЛАУ, с	Временные затраты на выполнение этапов метода в
процентах от общего времени
		Формирование матриц
коэффициентов СЛАУ, %	Настрой ка парамет ров решател
я, %	Решение СЛАУ, %
12  12	0,178	0,01	98,36	1,29
22  22	0,183	0,01	98,11	1,52
42  42	0,175	0,02	98,02	1,72
82  82	0,203	0,06	91,74	7,88





Рис. 21. Распределение численного решения T в расчетной области для теста 5.
Расчетная сетка: 82  82

Рис. 22. Распределение аналитического решения  в расчетной области для теста 5. Расчетная сетка: 82  82




Рис. 23. Распределение абсолютной ошибки  в расчетной области для теста 5.
Расчетная сетка: 82  82





 = {(, ): 0 <  < 1, 0 <  <  }:

 =  sin .

Граничные условия:

Тест 6



|=0

|

= 0,	|


= ,	|


=1

= sin ;

= 0.


 =0

Аналитическое решение:
(, ) =  sin .

=



Таблица 19. Максимальные абсолютные и относительные ошибки для теста 6

Сетка
  		, %
12  32	2,09  104	0,20
22  62	5,24  105	0,11
42  122	1,31  105	5,87  102
82  242	3,29  106	3,00  102



Таблица 20. Сравнение скорости сходимости методов решения СЛАУ для
теста 6




Сетка
  	
Алгебраический многосеточный метод	Метод Гаусса- Зейделя	Метод переменн ых направле
ний	Стабилизированн ый метод бисопряженных градиентов
	Кол-во уровней
V-цикла	Кол-во итераций	Кол-во итераций	Кол-во итераций	Кол-во итераций
12  32	1	1	1402	358	61
22  62	1	1	5605	1410	125
42  122	2	8	22014	5509	243
82  242	3	9	85658	21398	508

Таблица 21. Время решения СЛАУ на графическом ускорителе алгебраическим многосеточным методом для теста 6




Сетка
  	

Общее время
решения СЛАУ, с	Временные затраты на выполнение этапов метода в
процентах от общего времени
		Формирование матриц
коэффициентов СЛАУ, %	Настрой ка парамет ров решател
я, %	Решение СЛАУ, %
12  32	0,189	0,01	98,38	1,28
22  62	0,165	0,03	97,95	1,58
42  122	0,202	0,05	91,73	7,90
82  242	0,219	0,16	91,12	8,45





Рис. 24. Распределение численного решения T в расчетной области для теста 6.
Расчетная сетка: 82  242

Рис. 25. Распределение аналитического решения  в расчетной области для теста 6. Расчетная сетка: 82  242




Рис. 26. Распределение абсолютной ошибки  в расчетной области для теста 6.
Расчетная сетка: 82  242


Рис. 27. Распределение относительной ошибки  в расчетной области для теста 6. Расчетная сетка: 82  242



Тест 7
 = {(, , ): 0 <  < 1, 0 <  < 1, 0 <  < 1 }:

 = 2cos( ) + 42 sin(2)  42 cos(2);

Граничные условия:
T(0, , ) = 1  sin(2) + cos(2); T(1, , ) = 1  sin(2) + cos(2); T(, 0, ) = cos( ) + cos(2);
T(, 1, ) = cos( ) + cos(2);
T(, , 0) = T(, , 1) = cos( )  sin(2) + 1;
Аналитическое решение:
(, ) = cos( )  sin(2) + cos(2).


Таблица 22. Максимальные абсолютные и относительные ошибки для теста 7

Сетка
    	абс
12  12  12	5,55  102
22  22  22	1,38  102
42  42  42	3,43  103
82  82  82	8,57  104
162  162  162	2,14  104



Таблица 23. Сравнение скорости сходимости методов решения СЛАУ для
теста 7




Сетка
    	
Алгебраический многосеточный метод	Метод Гаусса- Зейделя	Метод переменн ых направле
ний	Стабилизированн ый метод бисопряженных градиентов
	Кол-во уровней V-
цикла	Кол-во итерац ий	Кол-во итераций	Кол-во итераций	Кол-во итераций
12  12  12	1	1	217	50	28
22  22  22	2	7	829	186	56
42  42  42	3	8	3154	703	107
82  82  82	4	9	11948	2657	213
162  162  162	4	10	-	-	418
Таблица 24. Время решения СЛАУ на графическом ускорителе алгебраическим многосеточным методом для теста 7




Сетка
    	

Общее время
решения СЛАУ, с	Временные затраты на выполнение этапов
метода в процентах от общего времени
		Формировани е матриц
коэффициент ов
СЛАУ, %	Настрой ка парамет ров решател
я, %	Решение СЛАУ, %
12  12  12	0,214	0,02	98,16	1,54
22  22  22	0,376	0,06	87,90	11,88
42  42  42	0,539	0,38	88,88	10,61
82  82  82	0,837	1,20	91,84	6,88
162  162  162	6,450	1,58	90,86	7,55





Рис. 28. Изоповерхности численного решения T для теста 7.
Расчетная сетка: 162  162  162

Рис. 29. Изоповерхности аналитического решения  для теста 7.
Расчетная сетка: 162  162  162






Рис. 30. Изоповерхности абсолютной ошибки абс для теста 7. Расчетная сетка: 162  162  162



Тест 8
 = {(, , ): 0 <  < 1, 0 <  < 1, 0 <  < 1 }:

 = 0.

Граничные условия:


|



=0

= 0,	|



=1

= 2;



|
 =0

= 0,	|
 =1

= 2;



|



=0

= 0,	|=1

= 2 + 2  2.

Аналитическое решение:
(, ) = 2 + 2  22.


Таблица 25. Максимальные абсолютные ошибки для теста 8

Сетка
    	абс
12  12  12	5,00  103
22  22  22	1,25  103
42  42  42	3,12  104
82  82  82	7,81  105
162  162  162	1,95  105



Таблица 26. Сравнение скорости сходимости методов решения СЛАУ для
теста 8




Сетка
    	
Алгебраический многосеточный метод	Метод Гаусса- Зейделя	Метод переменн ых направле
ний	Стабилизированн ый метод бисопряженных градиентов
	Кол-во уровней V-цикла	Кол- во итера
ций	Кол-во итераци й	Кол-во итераций	Кол-во итераций
12  12  12	1	1	2091	468	46
22  22  22	2	7	8349	1858	97
42  42  42	3	9	32314	7184	194
82  82  82	4	10	-	-	391
162  162  162	4	9	-	-	812
Таблица 27. Время решения СЛАУ на графическом ускорителе алгебраическим многосеточным методом для теста 8




Сетка
    	

Общее время
решения СЛАУ, с	Временные затраты на выполнение этапов
метода в процентах от общего времени
		Формировани е матриц
коэффициент ов
СЛАУ, %	Настрой ка парамет ров решател
я, %	Решение СЛАУ, %
12  12  12	0,192	0,02	97,65	2,10
22  22  22	0,361	0,05	86,77	13,04
42  42  42	0,367	0,51	90,90	8,39
82  82  82	0,688	1,59	90,40	7,90
162  162  162	4,164	1,90	90,38	7,70





Рис. 31. Изоповерхности численного решения T для теста 8.
Расчетная сетка: 162  162  162

Рис. 32. Изоповерхности аналитического решения  для теста 8.
Расчетная сетка: 162  162  162




Рис. 33. Изоповерхности абсолютной ошибки абс для теста 8. Расчетная сетка: 162  162  162



ЗАКЛЮЧЕНИЕ

1.Изучен метод контрольного объема для численного решения уравнения Пуассона и алгебраический многосеточный метод для решения систем линейных алгебраических уравнений.
2.Изучены основные особенности архитектуры современных графических ускорителей и их параллельные технологии программирования.
3.Исследованы существующие программные библиотеки для графических ускорителей, которые реализуют алгебраический многосеточный метод.
4.Разработана вычислительная программа для численного решения дискретного аналога уравнения Пуассона на графических ускорителях с использованием выбранной библиотеки и технологии параллельного программирования.
5.Проведены тестовые расчеты разработанной программы на задачах с аналитическим решением.



Список литературы

1.Федоренко	Р.П.	Релаксационный	метод	решения	разностных эллиптических уравнений // ЖВМ и МФ. 1961. T.1, №5. C.922–927
2.Федоренко Р.П. Скорость сходимости одного итерационного метода // ЖВМ и МФ. 1964. T.4, №3. C.227–235.
3.Brandt A. Multi-level adaptive solutions to boundary value problems // Math. Comp. 1977. V. 31. P. 333–390.
4.Brandt A. Guide to multigrid development // Lecture Notes in Mathematics. Vol. 960. Heidelberg: Springer, 1982. 220–312.
5.Wesseling P. An introduction to multigrid methods. Chichester: Wiley, 1992
6.Бахвалов Н.С. О сходимости одного релаксационного метода при естественных ограничениях на эллиптический оператор // ЖВМ и МФ. 1966. T.6, №5. C.861-883.
7.Астраханцев Г.П. Об одном релаксационном методе // ЖВМ и МФ. 1971. Т.11. №2. С.439-448.
8.Brandt A. Multi-level adaptive technique (MLAT) for fast numerical solution to boundary value problems // Proc. 3rd Int. Conf. on Numerical Methods in Fluid Mechanics. / H. Cabannes and R. Temam (eds) / Lecture Notes in Physics. V. 18. — Berlin: Springer, 1973. — P. 82–89.
9.Hackbusch W. Ein iteratives Verfahren zur schnellen Auflosung elliptischer Randwertprobleme, Report 76-12, (1976), Mathematisches Institut der Universitat zu Koln.
10.Hackbusch W. , Trottenberg U. Multigrid Methods, Lecture Notes in Mathematics, 960, Springer, 1982.
11.Hackbusch W. Multi-grid Methods and Applications. Berlin, Heidelberg: Springer, 1985.
12.Шайдуров В.В. Многосеточные методы конечных элементов. М.: Наука, Гл. ред. физ.-мат. лит., 1989. 288 с.



13.Жуков В.Т. , Новикова Н.Д., Феодоритова О.Б. // Многосеточный метод для эллиптических уравнений с анизотропными разрывными коэффициентами, Ж. вычисл. матем. и матем. физ., 55:7 (2015), 1168– 1182
14.Ольшанский М.А. Лекции и упражнения по многосеточным методам. М:. ФИЗМАТЛИТ, 2005. 168 с.
15.Мартыненко С.И. Универсальная многосеточная технология. – М.: ИПМ им. М.В. Келдыша, 2013. – 243 с.
16.Trottenberg U., Oosterlee C., Schuller A., Multigrid, Academic Press, 2001.
17.Thekale A., Gradl T., Klamroth K., Rude U. Optimizing the number of multigrid cycles in the full multigrid algorithm, Numer. Linear Algebra Appl., 17 (2010), 199-210.
18.Brandt A. Algebraic multigrid theory: the symmetric case, Appl. Math. Comput., 19 (1986), 23-56.
19.Falgout R.D. An introduction to algebraic multigrid, Comput. Sci. Eng., 8 (2006), 24-33
20.Волков, К. Н., Дерюгин Ю. Н., Емельянов В. Н., Козелков А. С., Тетерина И. В. Алгебраический многосеточный метод в задачах вычислительной физики // Выч. мет. программирование, 15:2 (2014), С. 183–200.
21.K. Stuben, A review of algebraic multigrid, J. Comput. Appl. Math., 128 (2001), 281-309
22.Q. Chang, Y.-S. Wong, H. Fu, On the algebraic multigrid, J. Comput. Phys., 125 (1996), 279-292
23.K. Watanabe, H. Igarashi, T. Honma, Comparison of geometric and algebraic multigrid methods in edge-based finite element analysis, IEEE Trans.Magn., 41 (2005), 1672-1675.
24.C.-T. Wu, H.C. Elman, Analysis and comparison of geometric and algebraic multigrid for convection-diffusion equations, SIAM J. Sci. Comp., 28 (2006), 2208-2228.



25.U. Langer, D. Pusch, Comparison of geometrical and algebraic multigrid preconditioners for data-sparse boundary element matrices, Lect. Notes Comput. Sci., 3743 (2006), 130-137
26.F.O. Campos, R.S. Oliveira, R.W. Santos, Performance comparison of parallel geometric and algebraic multigrid preconditioners for the bidomain equations, Lect. Notes Comput. Sci., 3991 (2006), 76-83.
27.F.J. Gaspar, J.L. Gracia, F.J. Lisbona, C. Rodrigo, Efficient geometric multigrid implementation for triangular grids, J. Comput. Appl. Math., 234 (2010), 1027-1035.
28.P. Wesseling, P.Sonneveld, Numerical experiments with a multiple grid and a preconditioned Lanczos type method, in Approximation Methods for Navier- Stokes problems R. Rautmann, ed., Lecture Notes in Mathematics, 771, Springer, 1980, 543-562.
29.X.-F. Wang, Calculation Fluid Dynamics, ShangHai Transportation University, 1992.
30.Stuben K. Algebraic Multigrid (AMG): An Introduction with Applications,
GMD Report 53, GMD, St. Augustin, Germany, 1999.
31.H. Kim, J. Xu, and L. Zikatanov, A multigrid method based on graph matching for convection diffusion equations, Numer. Linear Algebra Appl., 10 (2003),
pp. 181–195.
32.A. C. Muresan and Y. Notay, Analysis of aggregation-based multigrid, SIAM
J. Sci. Comput., 30 (2008), pp. 1082–1103.
33.Y. Notay, An aggregation-based algebraic multigrid method, Electron. Trans. Numer. Anal., 37 (2010), pp. 123–146.
34.P. Van’ek, M. Brezina, and J. Mandel, Convergence of algebraic multigrid based on smoothed aggregation, Numer. Math., 88 (2001), pp. 559–579.
35.P. Van’ek, J. Mandel, and M. Brezina, Algebraic multigrid by smoothed aggregation for second and fourth order elliptic problems, Computing, 56 (1996), pp. 179–196.



36.R. D. Falgout, An introduction to algebraic multigrid, Comput. Sci. Eng., 8 (2006), pp. 24–33.
37.M. Adams, M. Brezina, J. Hu, and R. Tuminaro, Parallel multigrid smoothing: Polynomial versus Gauss-Seidel, J. Comput. Phys., 188 (2003), pp. 593–610.
38.H. De Sterck, U. M. Yang, and J. J. Heys, Reducing complexity in parallel algebraic multigrid preconditioners, SIAM J. Matrix Anal. Appl., 27 (2006),
pp. 1019–1039.
39.R. S. Tuminaro and C. Tong, Parallel smoothed aggregation multigrid: Aggregation strategies on massively parallel machines, in Proceedings of the ACM/IEEE 2000 Conference on Supercomputing, 2000.
40.BootCMatchG: An adaptive Algebraic MultiGrid linear solver for GPU: [электронный	ресурс].	URL: https://www.softwareimpacts.com/article/S2665-9638(20)30032-4/pdf.
41.P.S. Vassilevski, Multilevel Block Factorization Preconditioners: Matrix- Based Analysis and Algorithms for Solving Finite Element Equations, Springer, New York, USA, 2008.
42.AmgX:	A	Library		for	GPU	Accelerated	Algebraic	Multigrid		and Preconditioned	Iterative		Methods:		[сайт].	URL: https://www.researchgate.net/publication/283330199_AmgX_A_Library_for_ GPU_Accelerated_Algebraic_Multigrid_and_Preconditioned_Iterative_Meth ods.
43.M. Bernaschi, P. D’Ambra, D. Pasquini, AMG based on compatible weighted matching for GPUs, Parallel Comput. 92 (102599) (2020) 1–13, http://dx.doi.org/10.1016/j.parco.2019.102599.
44.P. D’Ambra, P.S. Vassilevski, Adaptive AMG with coarsening based on compatible weighted matching, Comput. Vis. Sci. 16 (2) (2013) 59–76, http://dx.doi.org/10.1007/s00791-014-0224-9.



45.P. D’Ambra, S. Filippone, P.S. Vassilevski, BootCMatch: a software package for bootstrap AMG based on graph weighted matching, ACM Trans. Math. Software 44 (4) (2018) 39:1–39:25, http://dx.doi.org/10.1145/3190647.
46.Efficient AMG on Heterogeneous Systems: [электронный ресурс ]. URL: https://www.scai.fraunhofer.de/content/dam/scai/de/documents/AllgemeineD okumentensammlung/SchnelleLoeser/SAMG/Efficient_AMG_draft.pdf.
47.Официальная LAMA – development of fast and scalable software: [сайт].
URL: http://www.libama.org
48.Библиотека XAMG для решения систем уравнений со многими правыми частями:	[электронный	ресурс].	URL: https://cfd.imamod.ru/FILES/2020/abstracts/xamg.pdf.
49.Исходный код библиотеки XAMG под лицензией GPLv3: [сайт]. URL: https://gitlab.com/xamg/xamg.
50.An improvement to the OpenMP version of BoomerAMG: [электронный ресурс].	URL:
https://www.researchgate.net/publication/264935700_An_improvement_to_th e_OpenMP_version_of_BoomerAMG.
51.Официальная	документация	BoomerAMG:	[сайт].	URL: https://hypre.readthedocs.io/en/latest/solvers-boomeramg.html.
52.Патанкар С. Численные методы решения задач теплообмена и динамики жидкости: Пер. с англ. / С. Патанкар. – М.: Энергоатомиздат, 1984. – 152с.
53.Гореликов А.В. Практикум на ЭВМ для студентов старших курсов специальности «прикладная математика и информатика»: Учеб. пособие
/ А.В. Гореликов, А.В. Ряховский; Сургут. гос. ун-т. – Сургут: Изд-во СурГУ, 2010. – 32с.
54.Versteeg H.K., Malalasekera W. An Introduction to Computational Fluid Dynamics: / H.K. Versteeg, W. Malalasekera, Bell & Bain Limited, Glasgow, 2007. – 503c.



55.Лекции по алгебраическому многосеточному методу Терехова К.М.: [электронный ресурс]. URL: https://dodo.inm.ras.ru/terekhov/lect1/05- 06/main.pdf.
56.Nvidia Volta: новая вычислительная архитектура: [сайт]. URL: https://www.ixbt.com/video4/nvidia-volta.shtml
57.Nvidia	Tesla	V100	GPU	architecture:	[электронный	ресурс].	URL: https://images.nvidia.com/content/volta-architecture/pdf/volta-architecture- whitepaper.pdf.
58.NVIDIA: [сайт]. URL: https://www.nvidia.com.
59.Боресков, А.В., Харламов, А.А. Основы работы с технологией CUDA
[Текст] // А.В. Боресков, А.А. Харламов. – М.: ДМК-Пресс, 2019. – 232с.
60.Официальная	CUDA	RUNTIME	API:	[сайт].	[2019].	URL:
https://docs.nvidia.com/cuda/cuda-math-
api/group		CUDA	MATH	INTRINSIC	SIMD.html#group	CUDA	 MATH	INTRINSIC	SIMD_1gb29295ac0d7b95d3a48a92a2b34e0b44.
61.Официальная	документация	AMGCL.	URL: https://amgcl.readthedocs.io/en/latest/.



Приложение
MODULE VAR IMPLICIT NONE
INTEGER, PARAMETER :: L1 = 82, M1 = 82, N1 = 82
REAL(8), PARAMETER :: PI = 3.1415926535897932384626433832795 INTEGER I, L2, J, M2, K, N2
REAL(8) DX, XL, XLR, YL, YLR, ZL, ZLR, delT, delT1, RET
REAL(8), DIMENSION (:), ALLOCATABLE :: X, Y, Z, XU, YV, ZW, PT, QT REAL(8), DIMENSION (:,:,:), ALLOCATABLE :: T, GAMI, GAMJ, GAMK, CON, APS, AIM, AIP, AJM, AJP, AKM, AKP, AP
END MODULE VAR

MODULE USER CONTAINS

REAL(8) FUNCTION FAN(X, Y, Z) IMPLICIT NONE
REAL(8), PARAMETER :: PI = 3.1415926535897932384626433832795 REAL(8) X, Y, Z
FAN = X**2 + Y**2 - 2.0_8 * Z**2 END FUNCTION FAN
SUBROUTINE START USE VAR IMPLICIT NONE

XL = 0.0_8; XLR = 1.0_8 YL = 0.0_8; YLR = 1.0_8 ZL = 0.0_8; ZLR = 1.0_8
CALL GRID1(L1, L2, XL, XLR, XU, X) CALL GRID1(M1, M2, YL, YLR, YV, Y) CALL GRID1(N1, N2, ZL, ZLR, ZW, Z)

DO K = 1, N1 DO J = 1, M1
DO I = 1, L1
T(I, J, K) = 0.0_8 ENDDO
ENDDO ENDDO

DO J = 2, M2 DO I = 2, L2
T(I, J, N1) = X(I)**2 + Y(J)**2 - 2.0_8 ENDDO
ENDDO
END SUBROUTINE START

SUBROUTINE GAMSOR USE VAR IMPLICIT NONE




DO K = 2, N2 DO J = 2, M2
DO I = 2, L2
CON(I, J, K) = 0.0_8
APS(I, J, K) = 0.0_8 ENDDO
ENDDO ENDDO

DO K = 2, N1 DO J = 2, M1
DO I = 2, L1
GAMI(I, J, K) = 1.0_8 GAMJ(I, J, K) = 1.0_8 GAMK(I, J, K) = 1.0_8
ENDDO ENDDO
ENDDO
DO K = 2, N2 DO J = 2, M2
GAMI(2, J, K) = 0.0_8 GAMI(L1, J, K) = 0.0_8
ENDDO ENDDO
DO K = 2, N2 DO I = 2, L2
GAMJ(I, 2, K) = 0.0_8 GAMJ(I, M1, K) = 0.0_8
ENDDO ENDDO
DO J = 2, M2 DO I = 2, L2
GAMK(I, J, 2) = 0.0_8 ENDDO
ENDDO
DO K = 2, N2 DO J = 2, M2
CON(L2, J, K) = CON(L2, J, K) + &
2.0_8 * ( YV(J + 1) - YV(J) )*( ZW(K + 1) - ZW(K)
)
ENDDO ENDDO

DO K = 2, N2 DO I = 2, L2
CON(I, M2, K) = CON(I, M2, K) + &
2.0_8 * ( XU(I + 1) - XU(I) )* ( ZW(K + 1) - ZW(K)
)
ENDDO ENDDO




END SUBROUTINE GAMSOR

SUBROUTINE OUTPUT USE VAR

DO K = 2, N2 DO J = 2, M2
DO I = 2, L2
RET = FAN(X(I), Y(J), Z(K))
delT = DMAX1(delT, DABS(T(I, J, K) - RET))
delT1 = DMAX1(delT1, 100.0_8 * DABS( ( T(I, J, K) - RET ) / RET)) ENDDO
ENDDO ENDDO
WRITE(*,'(1P2E15.6)') delT, delT1 END SUBROUTINE OUTPUT
SUBROUTINE ALLFILE USE VAR

OPEN(UNIT=3,FILE='ALL.DAT',STATUS='UNKNOWN')

WRITE(3,*)'VARIABLES = "X","Y","Z","T","Ta","delT"'
WRITE(3,*)'ZONE I=',L1 - 2,', J=',M1 - 2,', K=',N1 - 2,', F=POINT'
DO K = 2, N2 DO J = 2, M2
DO I = 2, L2
RET = FAN(X(I), Y(J), Z(K))
WRITE(3,'(1P6E15.6)') X(I), Y(J), Z(K), T(I, J, K), & RET, DABS(T(I, J, K) - RET)
ENDDO ENDDO

ENDFILE 3 CLOSE(3)
END SUBROUTINE ALLFILE END MODULE USER
module BiCGStab implicit none contains
function SpMV(M, IROW, ICOL, v) result(u) implicit none
real(8), intent(in) :: M(:), v(:)
integer, intent(in) :: IROW(:), ICOL(:) real(8), dimension(1 : size(v, dim = 1)) :: u integer :: nz, n, i, k
nz = size(M, dim = 1)



n = size(v, dim = 1) do i = 1, n
u(i) = 0.0_8 enddo
do k = 1, nz
u(IROW(k)) = u(IROW(k)) + M(k) * v(ICOL(k))
enddo
return
end function SpMV

function DotProduct(u, v) result(res) implicit none
real(8), intent(in) :: u(:), v(:)
real(8), dimension(1 : size(u, dim = 1)) :: w real(8) :: res
integer :: n, i
n = size(u, dim = 1) do i = 1, n
w(i) = u(i) * v(i) enddo
res = 0.0_8 do i = 1, n
res = res + w(i) enddo

return
end function DotProduct

function SumVectors(a, u, b, v) result(w) implicit none
real(8), intent(in) :: u(:), v(:), a, b real(8), dimension(1 : size(u, dim = 1)) :: w integer :: n, i
n = size(u, dim = 1) do i = 1, n
w(i) = a * u(i) + b * v(i) enddo
return
end function SumVectors


function solve(A, IROW, ICOL, b) result(x) implicit none
real(8), intent(in) :: A(:), b(:)
integer, intent(in) :: IROW(:), ICOL(:) real(8), dimension(1 : size(b, dim = 1)) :: x
real(8), dimension(1 : size(b, dim = 1)) :: r, rs, v, p, s, t real(8), parameter :: e = 1d-10
real(8) :: rho, rho_prev real(8) :: alpha, omega, beta
real(8) :: norm_r, norm_b, c1, c2 integer :: it = 0, err

x = 0.0_8



r = b - SpMV(A, IROW, ICOL, x)
rs = r
rho = 1.0_8 alpha = 1.0_8 omega = 1.0_8 v = 0.0_8
p = 0.0_8
norm_r = sqrt(DotProduct(r, r)) norm_b = sqrt(DotProduct(r, r)) do while(norm_r .GT. e * norm_b)
rho_prev = rho
rho = DotProduct(rs, r)
beta = (rho / rho_prev) * (alpha / omega) p = SumVectors(1.0_8, r, 1.0_8, &
SumVectors(beta, p, -beta * omega, v)) v = SpMV(A, IROW, ICOL, p)
alpha = rho / DotProduct(rs, v)
s = SumVectors(1.0_8, r, -alpha, v)
t = SpMV(A, IROW, ICOL, s)
omega = DotProduct(t, s) / DotProduct(t, t)
x = SumVectors(1.0_8, x, 1.0_8, SumVectors(alpha, p, omega, s)) r = SumVectors(1.0_8, s, -omega, t)
norm_r = sqrt(DotProduct(r, r)) norm_b = sqrt(DotProduct(b, b)) it = it + 1
end do
print *, "BiCGStab ITER :", it return
end function solve end module BiCGStab

PROGRAM COND3 USE VAR
USE USER

CALL ALLOC_MEMORY

CALL START CALL GAMSOR CALL DIF
CALL START
CALL ADISolver CALL OUTPUT

CALL START
CALL BiCGStabSolver CALL OUTPUT

CALL START
CALL GSSolver CALL OUTPUT
CALL START
CALL AMGSolver



CALL OUTPUT CALL ALLFILE
CALL DEALLOC_MEMORY END PROGRAM COND3
SUBROUTINE ALLOC_MEMORY USE VAR
IMPLICIT NONE INTEGER :: IERR
ALLOCATE(X(L1), Y(M1), Z(N1), XU(L1), YV(M1), ZW(N1), PT(L1), QT(L1), T(L1, M1, N1), GAMI(L1, M1, N1), &
GAMJ(L1, M1, N1), GAMK(L1, M1, N1), &
CON(L1, M1, N1), APS(L1, M1, N1), AIP(L1, M1, N1), AIM(L1, M1, N1), AJM(L1, M1, N1), &
AJP(L1, M1, N1), AKM(L1, M1, N1), &
AKP(L1, M1, N1), AP(L1, M1, N1), STAT = IERR) END SUBROUTINE ALLOC_MEMORY
SUBROUTINE DEALLOC_MEMORY USE VAR
IMPLICIT NONE INTEGER :: IERR

DEALLOCATE(X, Y, Z, XU, YV, ZW, PT, QT, T, GAMI, GAMJ, GAMK, CON, APS, AIP, AIM, AJM, AJP, &
AKM, AKP, AP, STAT = IERR) END SUBROUTINE DEALLOC_MEMORY
SUBROUTINE GRID1(L1, L2, XL, XLR, XU, X) INTEGER L1, L2, I
REAL(8) XL, XLR, XU(L1), X(L1), DX L2 = L1-1
DX = XLR / DBLE(L1 - 2) XU(2) = XL

DO I = 3, L1
XU(I) = XU(I - 1) + DX ENDDO
X(1) = XU(2)

DO I=2,L2
X(I) = 0.5_8 * (XU(I+1) + XU(I)) ENDDO
X(L1) = XU(L1)

END SUBROUTINE GRID1




SUBROUTINE DIF USE VAR

DO K = 2, N2 DO J = 2, M2
DO I = 2, L2
AIM(I, J, K) = GAMI(I, J, K) * ( ( YV(J + 1) - YV(J) ) *&
( ZW(K + 1) - ZW(K) ) / ( X(I) - X(I - 1) ) )
AIP(I, J, K) = GAMI(I + 1, J, K) * ( ( YV(J + 1) - YV(J) ) * &
( ZW(K + 1) - ZW(K)) / ( X(I + 1) - X(I) ) )

AJM(I, J, K) = GAMJ(I, J, K) * ( ( XU(I + 1) - XU(I) ) * &
( ZW(K + 1) - ZW(K) ) / ( Y(J) - Y(J - 1) ) )
AJP(I, J, K) = GAMJ(I, J + 1, K) * ( ( XU(I + 1) - XU(I) ) * &
( ZW(K + 1) - ZW(K) ) / ( Y(J + 1) - Y(J) ) )

AKM(I, J, K) = GAMK(I, J, K) * ( ( XU(I + 1) - XU(I) ) *&
( YV(J + 1) - YV(J) ) / ( Z(K) - Z(K - 1) ) )
AKP(I, J, K) = GAMK(I, J, K + 1) * ( ( XU(I + 1) - XU(I) ) *&
( YV(J + 1) - YV(J) ) / ( Z(K + 1) - Z(K) ) )
ENDDO ENDDO
ENDDO

DO K = 2, N2 DO J = 2, M2
DO I = 2, L2
AP(I, J, K) = - APS(I, J, K) + AIM(I, J, K) + AIP(I, J, K) + &
AJM(I, J, K) + AJP(I, J, K) + AKM(I, J, K) + AKP(I, J,
K)
ENDDO ENDDO
ENDDO
END SUBROUTINE DIF

SUBROUTINE BiCGStabSolver USE VAR
use BiCGStab implicit none
integer, parameter :: n = (L1 - 2) * (M1 - 2) * (N1 - 2)
integer, parameter :: nz = (L1 - 2) * (M1 - 2) * (N1 - 2) + & !AP
(L1 - 2) * (M1 - 3) * (N1 - 2) + & !AJM
(L1 - 2) * (M1 - 3) * (N1 - 2) + & !AJP
(L1 - 3) * (M1 - 2) * (N1 - 2) + & !AIM
(L1 - 3) * (M1 - 2) * (N1 - 2) + & !AIP
(L1 - 2) * (M1 - 2) * (N1 - 3) + & !AKM
(L1 - 2) * (M1 - 2) * (N1 - 3)	!AKP
real(8), dimension(1 : nz) :: A integer, dimension(1 : nz) :: IROW, ICOL real(8), dimension(1 : n) :: numSol, b integer :: idx, INZ
INZ = 1
idx = 1



DO K = 2, N2 DO J = 2, M2
DO I = 2, L2
b(idx) = 0.0_8

IF(K .NE. 2) THEN
A(INZ) = - AKM(I, J, K) IROW(INZ) = idx
ICOL(INZ) = idx - (L1 - 2) * (M1 - 2) INZ = INZ + 1
ELSE
b(idx) = b(idx) + AKM(I, J, K) * T(I, J, K - 1) ENDIF
IF(J .NE. 2) THEN
A(INZ) = - AJM(I, J, K) IROW(INZ) = idx
ICOL(INZ) = idx - (L1 - 2) INZ = INZ + 1
ELSE
b(idx) = b(idx) + AJM(I, J, K) * T(I, J - 1, K) ENDIF

IF(I .NE. 2) THEN
A(INZ) = - AIM(I, J, K) IROW(INZ) = idx ICOL(INZ) = idx - 1 INZ = INZ + 1
ELSE
b(idx) = b(idx) + AIM(I, J, K) * T(I - 1, J, K) ENDIF

A(INZ) = AP(I, J, K) IROW(INZ) = idx ICOL(INZ) = idx
INZ = INZ + 1

b(idx) = b(idx) + CON(I, J, K)
IF(I .NE. L2) THEN
A(INZ) = - AIP(I, J, K) IROW(INZ) = idx ICOL(INZ) = idx + 1 INZ = INZ + 1
ELSE
b(idx) = b(idx) + AIP(I, J, K) * T(I + 1, J, K) ENDIF

IF(J .NE. M2) THEN
A(INZ) = - AJP(I, J, K) IROW(INZ) = idx
ICOL(INZ) = idx + (L1 - 2) INZ = INZ + 1
ELSE
b(idx) = b(idx) + AJP(I, J, K) * T(I, J + 1, K)



ENDIF
IF(K .NE. N2) THEN
A(INZ) = - AKP(I, J, K) IROW(INZ) = idx
ICOL(INZ) = idx + (L1 - 2) * (M1 - 2) INZ = INZ + 1
ELSE
b(idx) = b(idx) + AKP(I, J, K) * T(I, J, K + 1) ENDIF

idx = idx + 1 ENDDO
ENDDO ENDDO
numSol = solve(A, IROW, ICOL, b)

DO K = 2, N2 DO J = 2, M2
DO I = 2, L2
T(I, J, K) = numSol((i - 1) + (j - 2) * (L1 - 2) + &
(k - 2) * (L1 - 2) * (M1 - 2) )
ENDDO ENDDO
ENDDO
END SUBROUTINE BiCGStabSolver
subroutine AMGSolver
use, intrinsic :: iso_c_binding use amgcl
use var implicit none
integer, parameter :: numRows = (L1 - 2) * (M1 - 2) * (N1 - 2) integer, parameter :: numNZ = (L1 - 2) * (M1 - 2) * (N1 - 2) + & !AP
(L1 - 2) * (M1 - 3) * (N1 - 2) + & !AJM
(L1 - 2) * (M1 - 3) * (N1 - 2) + & !AJP
(L1 - 3) * (M1 - 2) * (N1 - 2) + & !AIM
(L1 - 3) * (M1 - 2) * (N1 - 2) + & !AIP
(L1 - 2) * (M1 - 2) * (N1 - 3) + & !AKM
(L1 - 2) * (M1 - 2) * (N1 - 3)	!AKP
real(c_float) :: tol integer :: iRow, iNZ, iGPU
integer(c_int), allocatable :: ptr(:), col(:)
real(c_double), allocatable :: val(:), rhs(:), vecUnknowns(:) integer(c_size_t) :: prof, sol, params
type(conv_info) :: cnv

iGPU = 0
prof = amgcl_profile_create();

call amgcl_profile_tic(prof, "assemble") allocate(ptr(numRows + 1)) allocate(col(numNZ))



allocate(val(numNZ)) allocate(rhs(numRows)) allocate(vecUnknowns(numRows))
vecUnknowns = 0.0_8

iNZ = 0
iRow = 1
ptr(iRow) = iNZ + 1

do k = 2, N1 - 1 do j = 2, M1 - 1
do i = 2, L1 - 1 rhs(iRow) = 0.0_8
if(k .ne. 2) then iNZ = iNZ + 1
col(iNZ) = iRow - (L1 - 2) * (M1 - 2)
val(iNZ) = - akm(i, j, k) else
rhs(iRow) = rhs(iRow) + akm(i, j, k) * T(i, j, k - 1) endif

if(j .ne. 2) then iNZ = iNZ + 1
col(iNZ) = iRow - (L1 - 2) val(iNZ) = - ajm(i, j, k)
else
rhs(iRow) = rhs(iRow) + ajm(i, j, k) * T(i, j - 1, k) endif

if(i .ne. 2) then iNZ = iNZ + 1
col(iNZ) = iRow - 1 val(iNZ) = - aim(i, j, k)
else
rhs(iRow) = rhs(iRow) + aim(i, j, k) * T(i - 1, j, k) endif
iNZ = iNZ + 1
col(iNZ) = iRow val(iNZ) = ap(i, j, k)
rhs(iRow) = rhs(iRow) + con(i, j, k)

if(i .ne. (L1 - 1)) then iNZ = iNZ + 1
col(iNZ) = iRow + 1 val(iNZ) = - aip(i, j, k)
else
rhs(irow) = rhs(irow) + aip(i, j, k) * T(i + 1, j, k) endif
if(j .ne. (M1 - 1)) then iNZ = iNZ + 1



col(iNZ) = iRow + (L1 - 2) val(iNZ) = - ajp(i, j, k)
else
rhs(irow) = rhs(irow) + ajp(i, j, k) * T(i, j + 1, k) endif

if(k .ne. (N1 - 1)) then iNZ = iNZ + 1
col(iNZ) = iRow + (L1 - 2) * (M1 - 2)
val(iNZ) = - akp(i, j, k) else
rhs(irow) = rhs(irow) + akp(i, j, k) * T(i, j, k + 1) endif
iRow = iRow + 1 ptr(iRow) = iNZ + 1
enddo enddo
enddo
call amgcl_profile_toc(prof, "assemble")

tol = 1e-10
params = amgcl_params_create()
call amgcl_params_sets(params, "solver.type", "bicgstab") call amgcl_params_setf(params, "solver.tol", tol)
call amgcl_params_sets(params, "precond.relax.type", "spai0")
call amgcl_profile_tic(prof, "setup")
sol = amgcl_solver_create(numRows, ptr, col, val, iGPU, params) call amgcl_profile_toc(prof, "setup")
call amgcl_solver_report(sol)
call amgcl_profile_tic(prof, "solve")
cnv = amgcl_solver_solve(sol, rhs, vecUnknowns) call amgcl_profile_toc(prof, "solve")
write(*,"('Iterations: ', I3, ', residual: ', E13.6)") cnv%iterations, cnv%residual
call amgcl_profile_report(prof)

call amgcl_solver_destroy(sol) call amgcl_params_destroy(params) call amgcl_profile_destroy(prof)

do k = 2, N1 -1 do j = 2, M1 - 1
do i = 2, L1 - 1
T(i, j, k) = vecUnknowns((i - 1) + (j - 2) * (L1 - 2) + (k - 2)
* (L1 - 2) * (M1 - 2))
enddo enddo
enddo

deallocate(ptr, col, val, rhs, vecUnknowns)




end subroutine AMGSolver


SUBROUTINE GSSolver USE VAR
IMPLICIT NONE
REAL(8) :: sum_sq, resT INTEGER :: IT

resT = 1.0_8 IT = 0

DO WHILE (resT > 1.d-10)
DO K = 2, N2 DO J = 2, M2
DO I = 2, L2
T(I, J, K) = ( AIM(I, J, K) * T(I - 1, J, K) + &
AIP(I, J, K) * T(I + 1, J, K) + &
AJM(I, J, K) * T(I, J - 1, K) + &
AJP(I, J, K) * T(I, J + 1, K) + &
AKM(I, J, K) * T(I, J, K - 1) + &
AKP(I, J, K) * T(I, J, K + 1) + &
CON(I, J, K) ) / AP(I, J, K)
ENDDO ENDDO
ENDDO

sum_sq = 0.0_8

DO K = 2, N2 DO J = 2, M2
DO I = 2, L2
sum_sq = sum_sq + &
( AP(I, J, K) * T(I, J, K) - ( AIM(I, J, K) * T(I - 1, J,

K)+&

+ &

+ &


AIP(I, J, K) * T(I + 1, J, K) + &
AJM(I, J, K) * T(I, J - 1, K) + AJP(I, J, K) * T(I, J + 1, K)
AKM(I, J, K) * T(I, J, K - 1) + AKP(I, J, K) * T(I, J, K + 1)

CON(I, J, K) ) )**2
ENDDO ENDDO

ENDDO
resT = DSQRT(sum_sq) IT = IT + 1
ENDDO

WRITE(*, *) 'GS ITER = ', IT END SUBROUTINE GSSolver



SUBROUTINE ADISolver USE VAR
IMPLICIT NONE
REAL(8) :: sum_sq, resT, DENOM INTEGER :: IT

resT = 1.0_8 IT = 0
DO WHILE (resT > 1.d-10)

DO K = 2, N2 DO J = 2, M2
PT(1) = 0.0_8 QT(1) = T(1, J, K)
DO I = 2, L2
DENOM = AP(I, J, K) - PT(I - 1) * AIM(I, J, K) PT(I) = AIP(I, J, K) / DENOM
QT(I) = ( CON(I, J, K) + AJM(I, J, K) * T(I, J - 1, K) + & AJP(I, J, K) * T(I, J + 1, K) + &
AKM(I, J, K) * T(I, J, K - 1) + AKP(I, J, K) * &
T(I, J, K + 1) + AIM(I, J, K) * QT(I - 1) ) / DENOM
ENDDO

DO I = L2, 2, -1
T(I, J, K) = T(I + 1, J, K) * PT(I) + QT(I) ENDDO

ENDDO ENDDO

DO K = 2, N2 DO I = 2, L2
PT(1) = 0.0_8 QT(1) = T(I, 1, K)

DO J = 2, M2
DENOM = AP(I, J, K) - PT(J - 1) * AJM(I, J, K) PT(J) = AJP(I, J, K) / DENOM
QT(J) = ( CON(I, J, K) + AIM(I, J, K) * T(I - 1, J, K) + & AIP(I, J, K) * T(I + 1, J, K) + &
AKM(I, J, K) * T(I, J, K - 1) + &
AKP(I, J, K) * T(I, J, K + 1) + &
AJM(I, J, K) * QT(J - 1) ) / DENOM
ENDDO
DO J = M2, 2, -1
T(I, J, K) = T(I, J + 1, K) * PT(J) + QT(J) ENDDO

ENDDO ENDDO

DO J = 2, M2



DO I = 2, L2 PT(1) = 0.0_8
QT(1) = T(I, J, 1)

DO K = 2, N2
DENOM = AP(I, J, K) - PT(K - 1) * AKM(I, J, K) PT(K) = AKP(I, J, K) / DENOM
QT(K) = ( CON(I, J, K) + AIM(I, J, K) * T(I - 1, J, K) +& AIP(I, J, K) * T(I + 1, J, K) + &
AJM(I, J, K) * T(I, J - 1, K) + &
AJP(I, J, K) * T(I, J + 1, K) + &
AKM(I, J, K) * QT(K - 1) ) / DENOM
ENDDO
DO K = N2, 2, -1
T(I, J, K) = T(I, J, K + 1) * PT(K) + QT(K) ENDDO

ENDDO ENDDO
sum_sq = 0.0_8

DO K = 2, N2 DO J = 2, M2
DO I = 2, L2
sum_sq = sum_sq + &
( AP(I, J, K) * T(I, J, K) - &
( AIM(I, J, K) * T(I - 1, J, K) + AIP(I, J, K) * T(I + 1, J, K) + &
AJM(I, J, K) * T(I, J - 1, K) + AJP(I, J, K) * T(I, J + 1, K) + &
AKM(I, J, K) * T(I, J, K - 1) + AKP(I, J, K) * T(I, J, K + 1) + & CON(I, J, K) ) )**2
ENDDO ENDDO
ENDDO

resT = DSQRT(sum_sq) IT = IT + 1
ENDDO
WRITE(*, *) 'ADI ITER = ', IT END SUBROUTINE ADISolver

module amgcl
use iso_c_binding private
public c_size_t, c_int, c_double, c_char, conv_info, & amgcl_profile_create, amgcl_profile_destroy, & amgcl_profile_tic, amgcl_profile_toc, amgcl_profile_report, & amgcl_params_create, amgcl_params_destroy, &
amgcl_params_seti,	amgcl_params_setf,	amgcl_params_sets, amgcl_params_read_json, &



amgcl_solver_create,	amgcl_solver_solve,	amgcl_solver_report, amgcl_solver_destroy, &
amgcl_schur_pc_create,	amgcl_schur_pc_solve, amgcl_schur_pc_report, amgcl_schur_pc_destroy

type, bind(C) :: conv_info
integer (c_int)	:: iterations real	(c_double) :: residual
end type

interface
integer(c_size_t) &
function	amgcl_profile_create()	bind	(C, name="amgcl_profile_create")
use iso_c_binding end function

subroutine	amgcl_profile_tic_c(prof,	name)	bind	(C, name="amgcl_profile_tic")
use iso_c_binding
integer	(c_size_t), intent(in), value :: prof character (c_char),	intent(in)	:: name(*)
end subroutine

subroutine	amgcl_profile_toc_c(prof,	name)	bind	(C, name="amgcl_profile_toc")
use iso_c_binding
integer	(c_size_t), intent(in), value :: prof character (c_char),	intent(in)	:: name(*)
end subroutine

subroutine	amgcl_profile_report(prof)	bind	(C, name="amgcl_profile_report")
use iso_c_binding
integer	(c_size_t), intent(in), value :: prof end subroutine

subroutine	amgcl_profile_destroy(prof)	bind	(C, name="amgcl_profile_destroy")
use iso_c_binding
integer	(c_size_t), intent(in), value :: prof end subroutine

integer(c_size_t) &
function	amgcl_params_create()	bind	(C, name="amgcl_params_create")
use iso_c_binding end function

subroutine	amgcl_params_seti_c(prm,	name,	val)	bind	(C, name="amgcl_params_seti")
use iso_c_binding
integer	(c_size_t), intent(in), value :: prm character (c_char),	intent(in)	:: name(*)



integer	(c_int),	intent(in), value :: val end subroutine

subroutine	amgcl_params_setf_c(prm,	name,	val)	bind	(C, name="amgcl_params_setf")
use iso_c_binding
integer	(c_size_t), intent(in), value :: prm character (c_char),	intent(in)	:: name(*) real	(c_float), intent(in), value :: val
end subroutine

subroutine	amgcl_params_sets_c(prm,	name,	val)	bind	(C, name="amgcl_params_sets")
use iso_c_binding
integer	(c_size_t), intent(in), value :: prm character (c_char),	intent(in)	:: name(*) character (c_char),	intent(in)	:: val(*)
end subroutine

subroutine	amgcl_params_read_json_c(prm,	fname)	bind	(C, name="amgcl_params_read_json")
use iso_c_binding
integer	(c_size_t), intent(in), value :: prm character (c_char),	intent(in)	:: fname(*)
end subroutine

subroutine	amgcl_params_destroy(prm)	bind(C, name="amgcl_params_destroy")
use iso_c_binding
integer (c_size_t), intent(in), value :: prm end subroutine

integer(c_size_t) &
function amgcl_solver_create (n, ptr, col, val, devnum, prm) bind (C, name="amgcl_solver_create")
use iso_c_binding
integer (c_int),	intent(in), value :: n integer (c_int),	intent(in)	:: ptr(*) integer (c_int),	intent(in)	:: col(*) real	(c_double), intent(in)	:: val(*) integer (c_int),	intent(in), value :: devnum integer (c_size_t), intent(in), value :: prm
end function

type(conv_info) &
function amgcl_solver_solve(solver, rhs, x) bind (C, name="amgcl_solver_solve")
use iso_c_binding
integer (c_size_t), intent(in), value :: solver real  (c_double), intent(in)   :: rhs(*) real  (c_double), intent(inout)   :: x(*)
type, bind(C) :: conv_info
integer (c_int)	:: iterations; real	(c_double) :: residual



end type end function

subroutine	amgcl_solver_report(solver)	bind(C, name="amgcl_solver_report")
use iso_c_binding
integer (c_size_t), intent(in), value :: solver end subroutine
subroutine	amgcl_solver_destroy(solver)	bind(C, name="amgcl_solver_destroy")
use iso_c_binding
integer (c_size_t), intent(in), value :: solver end subroutine
integer(c_size_t) &
function amgcl_schur_pc_create (n, ptr, col, val, pressure_vars, devnum, prm) bind (C, name="amgcl_schur_pc_create")
use iso_c_binding
integer (c_int),	intent(in), value :: n integer (c_int),	intent(in)	:: ptr(*) integer (c_int),	intent(in)	:: col(*) real	(c_double), intent(in)	:: val(*)
integer (c_int),	intent(in), value :: pressure_vars integer (c_int),	intent(in), value :: devnum integer (c_size_t), intent(in), value :: prm
end function
type(conv_info) &
function amgcl_schur_pc_solve(solver, rhs, x) bind (C, name="amgcl_schur_pc_solve")
use iso_c_binding
integer (c_size_t), intent(in), value :: solver real  (c_double), intent(in)   :: rhs(*) real  (c_double), intent(inout)   :: x(*)
type, bind(C) :: conv_info
integer (c_int)	:: iterations; real	(c_double) :: residual
end type end function

subroutine	amgcl_schur_pc_report(solver)	bind(C, name="amgcl_schur_pc_report")
use iso_c_binding
integer (c_size_t), intent(in), value :: solver end subroutine

subroutine	amgcl_schur_pc_destroy(solver)	bind(C, name="amgcl_schur_pc_destroy")
use iso_c_binding
integer (c_size_t), intent(in), value :: solver end subroutine
end interface



contains
subroutine amgcl_profile_tic(prof, name) use iso_c_binding
integer	(c_size_t), intent(in), value :: prof character (len=*),	intent(in)	:: name

call amgcl_profile_tic_c(prof, name // c_null_char) end subroutine

subroutine amgcl_profile_toc(prof, name) use iso_c_binding
integer	(c_size_t), intent(in), value :: prof character (len=*),	intent(in)	:: name
call amgcl_profile_toc_c(prof, name // c_null_char) end subroutine

subroutine amgcl_params_seti(prm, name, val) use iso_c_binding
integer	(c_size_t), intent(in), value :: prm character (len=*),	intent(in)	:: name integer	(c_int),	intent(in), value :: val
call amgcl_params_seti_c(prm, name // c_null_char, val) end subroutine
subroutine amgcl_params_setf(prm, name, val) use iso_c_binding
integer	(c_size_t), intent(in), value :: prm character (len=*),	intent(in)	:: name real	(c_float), intent(in), value :: val
call amgcl_params_setf_c(prm, name // c_null_char, val) end subroutine

subroutine amgcl_params_sets(prm, name, val) use iso_c_binding
integer	(c_size_t), intent(in), value :: prm character (len=*),	intent(in)	:: name character (len=*),	intent(in)	:: val

call amgcl_params_sets_c(prm, name // c_null_char, val // c_null_char)
end subroutine
subroutine amgcl_params_read_json(prm, fname) use iso_c_binding
integer	(c_size_t), intent(in), value :: prm character (len=*),	intent(in)	:: fname

call amgcl_params_read_json_c(prm, fname // c_null_char) end subroutine

end module