Бюджетное учреждение высшего образования Ханты-Мансийского автономного округа – Югры
«СУРГУТСКИЙ ГОСУДАРСТВЕННЫЙ УНИВЕРСИТЕТ»
Политехнический институт

Кафедра прикладной математики


КУЧЕРЯВАЯ МАРГАРИТА ИГОРЕВНА

Оптимизация скорости построения изображений методом Монте-Карло

БАКАЛАВРСКАЯ РАБОТА
по направлению 01.03.02 «Прикладная математика и информатика» направленность (профиль) «Прикладная математика и информатика»





Научный руководитель: к.ф.-м.н. Быковских Д.А.

(подпись) Допущено к защите:
	20	 Зав. Кафедрой ПМ,
доцент, к.ф.-м.н. Гореликов А.В.

(подпись) Студент гр. № 601-01
Кучерявая Маргарита Игоревна


(подпись)


Сургут 2024 г.

Содержание
Введение	3
1.Обзорная глава	7
1.1.История развития компьютерной графики	7
1.2.Понятие рендеринга	12
1.3.Физически-корректный рендеринг или PBR	15
1.4.Описание метода Монте-Карло	20
1.5.Метод трассировки пути	22
2.Построение изображений методом Монте-Карло	24
2.1.Математическая модель освещения Кука-Торренса	24
2.1.1.Двулучевая функция распределения отражений или BRDF. 25
2.2.Метод Монте-Карло	31
2.2.1.Правило трех сигм	32
2.2.2.Метод трассировки пути	35
2.2.3.Тонмаппинг и гамма-коррекция	37
3.Реализация программы построения изображений	39
3.1.Графические библиотеки и спецификации OpenGL	39
3.1.1.Вычислительный шейдер	41
3.1.2.Графический конвейер	42
3.1.3.Интсрументы разработки OpenGL	44
3.2.Структура программы	46
3.3.Моделирование и анализ результатов	50
Заключение.	56
Список литературы	57
Приложение	61

Введение
Актуальность
Развитие компьютерной графики в современном мире не останавливается ни на секунду. Этот процесс тесно связан с постоянным развитием вычислительной техники и методов: с каждым годом появляются новые подходы и программные решения, которые делают графику более реалистичной, красочной и выразительной.
Существенным фактором в развитии компьютерной графики является разработка и развитие методов моделирования. Они позволяют создавать трехмерные модели и персонажей с высокой степенью детализации и реалистичности.
Другим направлением развития является рост вычислительной мощности аппаратного обеспечения при относительно небольшой стоимости. С увеличением вычислительной мощности процессоров и графических карт, возможности рендеринга расширяются, позволяя использовать более продвинутые техники обработки изображений с гораздо большей эффективностью, чем это было возможно ранее. Это приводит к существенному повышению качества получаемых изображений.
Компьютерная обработка имеет множество возможностей, включая как растровую графику, которая работает с пикселями изображения или цифровыми значениями, так и векторную графику, которая использует математические уравнения для создания чётких и масштабируемых форм и линий.
Трассировка пути имитирует распространение света в сцене, создавая реалистичные световые эффекты, в то время как процедурная генерация использует математические правила для создания сложных объектов из простых компонентов.

Все это и многое другое позволяет создавать множество изображений, имеющих специализированное назначение в различных отраслях человеческой деятельности: от индустрии развлечений (видеоигры, фильмы, фотографии и т.д.), до профессиональной научной деятельности (медицинские изображения, моделирование потоков жидкости и газов, анализ электрических и магнитных полей и т.д.).
Использование физически корректного рендеринга (англ. Physically Based Rendering, PBR) — современный подход к созданию реалистичных материалов и моделей освещения. PBR-техники позволяют достигать высокого уровня фотореализма, имитируя световые и материальные свойства объектов с учетом их характеристик, таких как металличность, шероховатость, прозрачность и других.
Использование PBR-техник позволяет достичь более точного и реалистичного визуального отображения материалов, а также может увеличить скорость рендеринга благодаря хранению данных в специальных текстурах или материалах, что позволяет графическому процессору (англ. Graphics Processing Unit, GPU) быстрее обрабатывать информацию. Также PBR-техники могут быть оптимизированы для параллельных вычислений и использования возможностей современных GPU, что способствует увеличению скорости рендеринга.
Трассировка пути является широко используемым методом рендеринга, который появился в 1960-х годах [35]. Не смотря на то, что трассировка пути является ресурсоемким методом построения реалистичного изображения, в связи с ростом мощности графических устройств (видеокарт), этот метод сейчас набирает большую популярность, в частности в играх из-за реалистичности и детализации изображения.

Важным аспектом в компьютерной графике при построении изображения с помощью метода трассировки пути является скорость сходимости каждой компоненты пикселя изображения. Чем быстрее алгоритм, основанный на этом методе, сходится в зависимости от условий (сцены), тем меньше времени требуется для создания итогового изображения.
Этот аспект важен при использовании PBR-техник, поскольку учитывается большое количество информации о физических свойствах материалов. За счет огромного количества ядер графические процессоры могут быстро и точно вычислять взаимодействие света с этими материалами для каждого пикселя. Это помогает сократить время, необходимое для создания реалистичного изображения.
Учитывая скорость сходимости алгоритма рендеринга для каждого пикселя во время создания изображения, можно эффективно распределить вычислительные ресурсы. После достижения заданной точности, ресурсы можно перенаправить на обработку пикселей, требующих дополнительных расчетов. Этот процесс оптимизации позволяет уменьшить общее время рендеринга за счет эффективного использования вычислительных ресурсов. Благодаря этой стратегии, графический процессор может работать более результативно, обеспечивая быстрое создание изображений даже в сложных сценах.
Все вместе, использование трассировки пути и оптимизация скорости сходимости в каждом пикселе играют важную роль в создании изображений в реальном времени и открывают новые возможности для создания неповторимых визуальных впечатлений в различных сферах применения компьютерной графики.

Цель и задачи

Цели работы: разработка и реализация в виде программы построения изображений методом Монте-Карло с применением графической библиотеки MESA; проведение вычислительных экспериментов и оптимизация скорости построения изображений за счёт балансировки вычислительной нагрузки.
Задачи:

1.Изучить, описать и реализовать модель освещения Кука-Торренса с применением PBR-техник и метод трассировки пути, основанный на ММК, в виде программы, использующей графическую библиотеку MESA, основанную на спецификации OpenGL.
2.Построить тестовую сцену из простейших трехмерных объектов (поверхностей 1-го и 2-го порядка).
3.Выполнить оптимизацию программного кода, связанную с дополнительным введением статической оценки относительной погрешности компонент пикселей изображений.
4.Провести сравнительный анализ скорости построения изображений ММК с помощью разработанной программы с включённой и отключённой оптимизацией.

1.Обзорная глава
1.1.История развития компьютерной графики

В 1970-е годы, когда компьютерная графика только начала развиваться, основные проблемы были связаны в первую очередь с разработкой эффективных алгоритмов визуализации и с точными геометрическими представлениями. Когда один Мбайт оперативной памяти имел высокую стоимость, а вычислительные возможности компьютера выполнять миллион операций с плавающей точкой в секунду стоили сотни тысяч долларов, создание фотореалистичных изображений за приемлемое время было существенно сложной задачей [3].
С увеличением производительности и вычислительной мощности компьютеров, а также уменьшением их стоимости, стало возможным использовать более требовательные к вычислениям подходы к рендерингу, что в свою очередь сделало физически корректный рендеринг возможным для современных задач. Рендеринг продолжает использовать все доступные ему вычислительные возможности.
Физически корректные подходы к рендерингу стали серьезно рассматриваться исследователями графики в 1980-х годах. В статье Уиттеда (Whitted’s) (1980 г.) была представлена идея использования трассировки лучей для глобальных эффектов освещения, открывающая возможности для точного моделирования распределения света в сценах. Рендеринг изображений, созданный с помощью такого подхода, сильно отличался от всех созданных ранее, что вызвало рост интересов в области научных направлений [3].
Другим заметным достижением в сфере физического рендеринга была модель Кука и Торренса, разработанная в начале 1980-х годов, которая позволила применять в графике модели отражения с микро гранями [19].

Среди прочего, они показали, что такой способ моделирования отражений, делает возможным визуализировать степень металличности и шероховатости поверхности, что ранее представляло собой сложную задачу.
В то время многие смотрели на их работу со скептицизмом; применяемый метод Монте-Карло для построения изображений приводит к появлению артефактов, особенно при использовании относительно небольшого количества выборок. Это могло привести к неудовлетворительным результатам, особенно для сложных сцен с большим количеством отражений. В то время вычислительные мощности были ограничены, и метод Монте-Карло требовал большого количества расчетов для достижения точных результатов. Это означало, что рендеринг изображений с использованием этой модели мог занять много времени, поэтому часто использовались альтернативные методы рендеринга, например, модель Фонга.
Вскоре после этого Каджия (1986 г.) представил трассировку пути; он изложил строгую формулировку проблемы рендеринга в виде интегрального уравнения переноса света и показал, как использовать метод Монте-Карло для его численного решения [19]. Его исследовательский проект требовал огромных вычислительных ресурсов на тот момент: для визуализации пиксельного изображения двух сфер с использованием трассировки пути потребовалось 7 часов вычислений на компьютере IBM.
После работы Торренса и Кука большая часть исследований в Корнелльском университете касалась физически корректных подходов. В результате были приведены веские аргументы в пользу физически точной визуализации, основанной на измерениях материальных свойств объектов реального мира и глубоком понимании зрительной системы человека.

Решающим шагом в физически-корректном рендеринге стала работа Вича в 1997 г., описанная в его диссертации [4]. Он разработал ключевые теоретические основы применения метода Монте-Карло в рендеринге, а также разработал и модифицировал новые методы и алгоритмы, такие как выборка с множественной значимостью и двунаправленная трассировка пути (англ. Metropolis Light Transport), что значительно повысило эффективность физически корректного рендеринга.
В дальнейшем активно начала развиваться компьютерная графика в кинопроизводстве и анимации. Так в 1997 г. Blue Sky Studios в самом начале своей истории внедрила физический конвейер.
В данном контексте физический конвейер означает использование физического подхода к созданию изображений. Вместо традиционных методов, которые могут применять эмпирическую модель освещения, физический конвейер стремится достичь более реалистичных результатов путем применения фундаментальных законов физики для моделирования света, материи и его взаимодействий. Процесс работы с физическим конвейером обычно состоит из моделирования (создания трехмерных моделей объектов и сцены), освещения (распределение источников света), материалов (цвет, текстура, ...), расчет перемещения света (трассировка пути).
Фотореализм рекламы, которую они сделали в 1997 году, привлек внимание многих, а их короткометражный фильм, показанный в 1998 году, стал ранним примером глобального освещения, используемого в производстве.
После короткометражки еще один переломный момент наступил в 2001 году, когда Маркос Фахардо пришел в SIGGRAPH с ранней версией своего рендера Arnold. Он продемонстрировал изображения, которые не только

имели сложную геометрию, текстуры и глобальное освещение, но и были визуализированы за десятки минут. Хотя эти сцены не были такими сложными, как те, которые использовались в кинопроизводстве того времени, его результаты показали множество творческих возможностей построения глобального освещения в сложных сценах.
Одна из основных причин того, что физически корректные подходы к рендерингу оказались успешными в производстве, заключается в том, что они в конечном итоге повышают качество изображения.
Основными факторами служат [3]:

1.Используемые алгоритмы. Ключевой характеристикой алгоритмов является количество выборок на пиксель, что существенно влияет на процесс создания изображения. Алгоритмы трассировки пути эффективны как для постепенного уточнения изображения, так и для быстрого оценивания его качества, даже если используется лишь несколько выборок на пиксель. В отличие от алгоритмов на основе растеризации, которые могут создавать изображения быстро, но не обладают тем же уровнем детализации и реализма, который может быть достигнут с использованием алгоритмов трассировки пути. [9]
2.Применение физически корректных моделей отражения сильно упростило процесс проектирования материалов поверхности. В прошлом, когда использовались модели отражения, не сохраняющие энергию света, объект мог быть настроен для отображения в идеальном освещении, однако, при перемещении его в другое окружение, результат выглядел неправдоподобно из-за некорректно установленных параметров отражения на его поверхности. Это происходило из-за того, что количество отраженной световой энергии было слишком малым или, наоборот, слишком велико из-за произвольно установленных значений свойств поверхности.

3.Качество теней, получаемых при использовании трассировки пути, выросло. Этот метод автоматически создает тени путем моделирования лучей света, в то время как растеризация, в сравнении, требует более сложных техник: алгоритмы теневых объемов, методы размытия теней и техники освещения. Каждая из этих техник имеет свои преимущества и ограничения, и выбор конкретной зависит от требований проекта и доступных ресурсов. При использовании трассировки пути тени получаются автоматически. Более того, физически-корректные методы приносят дополнительные эффекты, такие как отраженное освещение и мягкость теней, которые создаются естественным образом, а не при помощи дополнительных алгоритмов и ручной настройки эффектов освещения сцены.
Увеличение вычислительной мощности и прогресс в разработке методов и алгоритмов привели к значительным улучшениям в области рендеринга. Теперь рендеринг в реальном времени не ограничивается лишь индустрией развлечений, но и в профессиональных приложениях для визуализации и виртуальной реальности. Рендеринг в реальном времени теперь используется для создания интерактивных визуализаций, которые могут быть немедленно изменены или обновлены в ответ на действия пользователя.

1.2.Понятие рендеринга

На самом высоком уровне абстракции, рендеринг представляет собой процесс перевода 3D-сцены в плоское изображение. Он включает в себя алгоритмы для создания изображения, геометрического моделирования, текстурирования и другие аспекты компьютерной графики, которые должны передать свои результаты через процесс рендеринга, чтобы стать видимыми в окончательном изображении.
Рендеринг стал повсеместным; от киноиндустрии до видеоигр и не только, он открыл новые возможности для творческого самовыражения, развлечений и визуализации [20].
Потребность в визуализации данных у человечества столетиями росла, начиная с простых наскальных рисунков и до современных технологий (см. рис. 1).
В зарождающиеся годы компьютерной графики исследователи сосредотачивались на решении фундаментальных проблем, таких как определение видимых объектов с определенного ракурса. Постепенно, с нахождением эффективных решений для этих задач и продвижением в других областях графики, стали появляться более реалистичные и детализированные описания сцен.



Рис. 1. Древняя наскальная живопись XII тыс. до н.э.

Рендеринг можно разделить на несколько этапов, каждый из которыхимеет свои особенности и методы:
1.Визуализация геометрии: на этом этапе трехмерные модели преобразуются в двумерные изображения. Это включает в себя определение положения объектов в пространстве, их формы и размеров.
2.Текстурирование: после определения геометрии объектов на них накладываются	текстуры,	чтобы	придать	им	более	реалистичный	вид. Текстуры могут включать цвета, узоры и даже имитацию материалов, таких как кожа, металл, ткань.
3.Освещение: этот этап включает в себя расчет освещения сцены, что влияет на то, как объекты будут выглядеть. Освещение может быть прямым или рассеянным, и его характеристики зависят от источников света и их взаимодействия с объектами и текстурами.

4.Теневое моделирование: тени добавляют глубину и реалистичность изображению. Они могут быть мягкими или резкими, в зависимости от расстояния и интенсивности источника света.
5.Отражение и преломление: для создания реалистичных изображений воды, стекла и других прозрачных или отражающих материалов используются алгоритмы, имитирующие отражение и преломление света.
6.Постобработка: после создания основного изображения, оно может быть дополнительно обработано для улучшения визуальных эффектов. Это может включать коррекцию цвета, добавление размытия для имитации движения, или создание эффектов глубины резкости.
Рендеринг требует значительных вычислительных ресурсов, особенно для создания высококачественных изображений. Актуальные технологии, такие как трассировка пути и растеризация, позволяют создавать изображения с высокой степенью реализма, но каждая из этих технологий имеет свои преимущества и недостатки.
Современный рендеринг объединяет идеи из различных дисциплин, таких как физика, астрофизика, астрономия, биология, психология и прикладная математика. Это позволяет создавать визуализации, которые не только красочно отображают окружающий мир, но и способствуют более глубокому пониманию сложных явлений. Рендеринг выходит за рамки простой визуализации и становится мощным инструментом для научных исследований в самых разных областях знаний.

1.3.Физически-корректный рендеринг или PBR

Техники, основанные на физической-корректности, пытаются отображать реальность. Они используют принципы из физики для моделирования взаимодействия света и материи. Хотя физически- корректный метод может казаться наиболее очевидным методом для рендеринга, он был широко внедрен в практику только в последние 10 лет или около того.
PBR был придуман с учетом трех основных целей:

1.законченности;

2.иллюстративности;

3.физической обоснованности [4].

Законченность подразумевает, что в системе не должно быть ключевых функций, которые есть в высококачественных коммерческих системах рендеринга. В частности это значит, что важные практические вопросы, такие как сглаживание (antialiasing), надежность (robustness), числовая точность и способность эффективно визуализировать (render) сложные сцены, должны быть тщательно рассмотрены. Важно учитывать эти проблемы с самого начала, с момента проектирования системы, так как эти функции могут иметь незначительные последствия для всех компонентов системы и их может быть достаточно сложно модифицировать в систему на дальнейших этапах внедрения.
Вторая цель (иллюстративность), подразумевает, что необходимо выбрать алгоритм, структуру данных и технику рендеринга, учитывая читабельность и ясность. Эта цель также требует, чтобы система была достаточно маленькая для понимания одного человека. Для понимания базовой структуры системы не обязательно разбираться во всей специфике

реализации. Это позволяет глубже вникнуть в интересующие части и пропускать остальное, не теряя при этом как вся система в целом сочетается друг с другом.
Основа физически-корректного рендеринга — математическое описание и аппроксимация законов физики. PBR был придуман для использования правильных физических единиц и концепций для вычисляемых величин и реализуемых им алгоритмов. PBR может создать изображение, которое является физически корректным, оно будет точно отображать освещение, которое было в реальной версии сцены. Одно преимущество решения использовать физическую основу это то, что она дает конкретный стандарт программы: для простых сцен, где ожидаемый результат может быть вычислен в закрытой форме, если PBR не вычисляет тот же результат, становится ясно, что должна быть ошибка в реализации. Получается, что этот физически корректный подход к рендерингу важен, потому что он строгий. Когда неясно, как следует выполнять то или иное вычисление, физика дает ответ, гарантирующий непротиворечивый результат. Тут и выполняется третья цель — физическая-обоснованность.
Важным аспектом PBR является принцип энергетической сохранности, который гарантирует, что количество света, отраженного от поверхности, не может превышать количество падающего света. PBR эффективно работает с различными типами источников света, например, точечные или направленные, а также может учитывать цвет видимого излучения и интенсивность распределения света. В зависимости от поверхности, от ее состояния (отражает ли оно, как зеркало, или имеет шероховатость, есть ли капли грязи/воды/кофе на поверхности) на сетчатку глаза попадает уже видоизмененный отраженный луч. Причем, луч — это не совсем правильно, так как уже известно, что свет — это еще и волна. Суть остается неизменной
— то, как мы видим объекты, выстраивается из того, как свет отражается от

поверхности. И стандарт PBR описывает то, какие параметры должны учитываться, чтобы свет выглядел максимально кинематографично [28].


Рис. 2. Виды отражения лучей света.

Эффективности был дан меньший уровень приоритета, чем трем вышеперечисленным целям. Поскольку системы рендеринга часто работают в течение многих минут или часов в процессе создания изображения, эффективность явно важна. Однако мы в основном ограничились алгоритмической эффективностью, а не низкоуровневой оптимизацией кода. Иногда очевидные микро оптимизации отходят на второй план относительно понятного и хорошо организованного кода.
Написание хорошего средства визуализации — это нечто большее, чем объединение набора быстрых алгоритмов. Необходимо сделать систему одновременно гибкой и надежной — а это довольно сложная задача. Производительность системы должна плавно уменьшаться по мере добавления к ней большего количества геометрии, источников света или при изменении любой другой оси сложности. К числовой стабильности следует относиться осторожно, а алгоритмы, которые не теряют впустую точность чисел с плавающей запятой, имеют решающее значение.
Ранее, для создания реалистичных изображений с использованием методов, основанных на физических принципах, требовались часы и даже дни вычислений. Однако благодаря ряду технологических прорывов, сегодня

можно наблюдать фотореалистичные сцены, рендеринг которых происходит в реальном времени. Несколько ключевых факторов, которые сделали это возможным:
1.Улучшение аппаратного обеспечения. Современные GPU обладают огромной вычислительной мощностью и специализированными архитектурами, что позволяет им обрабатывать сложные алгоритмы рендеринга в реальном времени.
2.Оптимизация алгоритмов. Алгоритмы рендеринга были значительно оптимизированы, чтобы уменьшить количество необходимых вычислений без потери качества изображения.
3.Применение приближённых методов. Вместо точного вычисления световых взаимодействий используются приближённые методы, которые достаточно близки к реальности, но требуют гораздо меньше ресурсов.
4.Использование умных шейдеров. Современные шейдеры могут динамически адаптироваться к условиям сцены, оптимизируя процесс рендеринга и улучшая производительность.
Использование данных, полученных из реального мира, в методе физически-корректного рендеринга играет центральную роль при создании правдоподобных визуальных эффектов.
Процесс включает следующие шаги:

1.Сбор данных: сначала происходит сбор данных о реальных материалах. Это может быть выполнено с помощью фотометрических и спектрометрических измерений, которые предоставляют информацию о свойствах отражения и преломления материалов.

2.Создание карт текстур: используя собранные данные, создаются карты текстур, которые имитируют различные физические свойства поверхности, такие как шероховатость, металличность, нормали и альбедо.
3.Калибровка: данные калибруются, чтобы соответствовать стандартам PBR, что обеспечивает использование правильных физических единиц и значений в рендеринге.
4.Применение в шейдерах: текстуры затем используются в шейдерах, которые управляют тем, как свет взаимодействует с материалами в виртуальной сцене. Шейдеры учитывают функцию BRDF (англ. Bidirectional Reflectance Distribution Function), освещение и другие факторы для создания реалистичного изображения.
5.Тестирование и корректировка: после применения текстур проводится тестирование сцены. Это позволяет оценить, насколько точно текстуры и шейдеры воспроизводят реальные материалы, и при необходимости вносить корректировки.
Этот процесс помогает создавать визуальные эффекты, которые не только выглядят реалистично, но и физически корректны, обеспечивая высокий уровень детализации в компьютерной графике.

1.4.Описание метода Монте-Карло

Самая первая работа, связанная с использованием вероятностного метода была опубликована А. Холлом в 1873 году. Суть работы состояла в экспериментальном определении числа  путем бросания иглы на лист линованной бумаги. Идея эксперимента возникла у Ж.Л.Л. Бюффона для вычисления числа  в 1777 году [1].
На самом деле общепринятого определения методов Монте-Карло не существует. Можно сказать, что методы Монте-Карло — это численные методы решения математических задач при помощи моделирования случайных величин и статистической оценки полученных характеристик. Этот метод был упомянут впервые в 1949 г., хоть теоретически он был известен и раньше, его связывают с именами Дж. Неймана, С. Улама, Н. Метрополиса, Г. Кана и Э. Ферми. [2]. Методы Монте-Карло основаны на законе больших чисел и центральной предельной теореме, которые гарантируют, что при достаточно большом числе испытаний среднее значение случайной выборки будет приближаться к математическому ожиданию.
Метод Монте-Карло используется во многих сферах деятельности: для расчета задач физики, радиотехники, математической статистике, теории массового обслуживания, химии, биологии, экономики (оптимизация, сетевое планирование и т.д.), аэродинамики и т.д. Метод Монте-Карло также оказал значительное влияние на развитие искусственного интеллекта и машинного обучения, где он используется для обучения моделей и оценки неопределенностей.
Моделировать случайные величины вручную — крайне трудоемкий процесс, который не всегда возможно выполнить точно. В современных условиях алгоритмы, основанные на методе Монте-Карло, легко описываемы

и легко реализуемы с использованием компьютерных программ и вычислительных мощностей. Это делает метод доступным для широкого круга исследователей и инженеров, стимулируя его активное применение в различных областях науки и техники. С течением времени были разработаны различные вариации и улучшения метода Монте-Карло, такие как методы Марковских цепей, выборка по важности и методы уменьшения дисперсии, которые повышают эффективность и точность вычислений.
Некоторые приложения компьютерной графики стремятся создать визуально реалистичные изображения компьютерных моделей, решая уравнения переноса света. Процесс решения уравнений большой размерности может включать как явные, так и неявные методы. Часто применяется метод Монте-Карло, особенно с акцентом на выборку по важности, что предпочтительнее стратификации. Во многих случаях достаточно приближенных решений, что позволяет сократить размерность задачи. В таких ситуациях важно эффективное распределение выборок, для чего часто используется метод квази-Монте-Карло. Однако вопрос о том, какие схемы выборки являются наилучшими для задач компьютерной графики с меньшей размерностью, и что подразумевается под "лучшим" в данном случае, остается объектом дальнейших исследований.
Именно благодаря этим преимуществам метод Монте-Карло широко применяется в компьютерной графике и показывает хорошие результаты. Также стоит упомянуть еще одно преимущество — возможность итеративного накопления вычислений и представления промежуточных результатов во время рендеринга, что находит применение в некоторых приложениях трассировки пути.

1.5.Метод трассировки пути

Изначально был разработан метод трассировки лучей (англ. Ray Tracing), который позволял создавать изображения с реалистичными отражениями и тенями, отслеживая путь лучей света в обратном направлении от камеры к источникам света. Этот метод был впервые описан в работах Артура Аппеля в 1960-х годах и с тех пор претерпел значительные улучшения [13].
Трассировка пути (англ. Path Tracing) — это более продвинутый алгоритм рендеринга, основанный на методе Монте-Карло, который позволяет реалистично моделировать освещение сцены и ее объектов путем визуализации физически точных отражений, преломлений, теней и непрямого освещения.
Трассировка пути создает изображения компьютерной графики, отслеживая путь света от камеры обзора (которая определяет наш взгляд на сцену), через плоскость 2D-просмотра (плоскость пикселей), наружу в 3D- сцену и обратно к источникам света.
Основные преимущества трассировки пути:

1.Реализм: трассировка пути позволяет создавать изображения, близкие к фотографическому качеству, благодаря точному моделированию световых взаимодействий.
2.Универсальность: этот метод подходит для рендеринга различных типов сцен, от внутренних интерьеров до сложных наружных ландшафтов.
3.Простота: в отличие от других методов (рейкастинг, растеризация, трассировка конусов, ...), трассировка пути не требует сложных настроек и трюков для моделирования сложных световых эффектов.

Недостатки трассировки пути:

1.Вычислительная сложность: для достижения высокого качества изображения требуются значительные вычислительные ресурсы, особенно для сложных сцен.
2.Шум: из-за стохастической природы алгоритма, особенно при низком количестве лучей, могут появляться видимые артефакты в виде шума на изображении.
Алгоритм трассировки пути на компьютере отслеживает путь бесконечно малых лучей света через сцену до тех пор, пока они не пересекают поверхность. Этот подход является простым методом для нахождения первого видимого объекта, который виден с любого конкретного местоположения и направления. Он является основой для многих других алгоритмов рендеринга.

2.Построение изображений методом Монте-Карло
2.1.Математическая модель освещения Кука-Торренса

Модель освещения Кука-Торренса — это физически обоснованная модель, используемая для имитации взаимодействия света с материалами в компьютерной графике. Уравнение, представляющее модель освещения Кука-Торренса для описания взаимодействия света с поверхностью, имеет вид:
(, ) =  + 	(, , )(, )( • ),	(1)

где  — отраженная облучённость, p — точка соприкосновения света и поверхности, o — угол, под которым наблюдатель видит отраженный свет,
 — функция BRDF (см. раздел 2.1.1. Функция BRDF),  — направление падающего света на точку p, n — нормаль к поверхности в точке p,  — излучение,  — это множество всех направлений , из которых падающий свет достигает точки p.
Интегральная форма представляет собой уравнение отражения, которое вычисляет сумму отраженной энергетической яркости для всех возможных направлений падающего света. Энергетическая яркость — это радиометрическая величина количества света в области, которая зависит от угла падающего света [13].

2.1.1.Двулучевая функция распределения отражений или BRDF

В уравнении отражения используется функция BRDF (англ. Bidirectional Reflectance Distribution Function), известная как двулучевая функция распределения отражений, которая масштабирует значение входящего излучения на основе свойств материала поверхности. Общее количество отраженного света не может превышать количество падающего света. Это важный принцип, обеспечивающий физическую корректность визуализации.
BRDF — это функция, которая описывает, как свет взаимодействует с поверхностью и отражается от нее. Она учитывает следующие факторы:
1.Направление падающего света : угол, под которым свет попадает на поверхность.
2.Направление наблюдателя : угол, под которым наблюдатель видит отраженный свет.
3.Нормаль к поверхности n: направление, перпендикулярное поверхности в точке падения света p.
4.Шероховатость поверхности a: параметр, характеризующий, насколько поверхность гладкая или шероховатая (см. рис.3)




Рис. 3. Сфера с разными значениями параметра шероховатости.

Функция отражения света BRDF аппроксимирует, как каждый отдельный луч света, падающий на поверхность, вносит вклад в конечный отраженный свет.
1.Для гладких поверхностей: если поверхность похожа на зеркало, BRDF присваивает значение 0 для всех входящих лучей света, кроме того, который отражается под тем же углом, что и луч, направленный к наблюдателю. Этому лучу функция присваивает значение 1.
2.Для шероховатых поверхностей: BRDF будет возвращать различные значения для разных входящих лучей света в зависимости от их углов падения и отражения, а также от шероховатости поверхности.
3.Для полупрозрачных поверхностей: функция также может учитывать, как свет проникает в поверхность, а затем отражается от нее. Это важно для моделирования материалов, таких как стекло, пластик и ткани.
Почти все графические конвейеры реального времени используют BRDF Кука-Торренса (Cook-Torrance). Эта функция широко используется по нескольким причинам:
1.Физическая корректность: эта модель основана на физических принципах, что позволяет создавать реалистичные изображения, соответствующие реальному световому поведению.
2.Адаптивность: Модель позволяет динамически адаптироваться к различным условиям освещения и материалам, сохраняя при этом высокую производительность.
3.Оптимизация вычислений: Модель разработана таким образом, что позволяет аппроксимировать сложные физические процессы, не требуя при этом чрезмерных вычислительных ресурсов.

4.Управляемость: параметры модели, такие как шероховатость и металличность, могут быть легко настроены, что дает разработчикам контроль над визуальным стилем.
5.Масштабируемость: BRDF Кука-Торренса может быть масштабирована для работы на различных устройствах и платформах, от мощных игровых ПК до мобильных устройств.
6.Преимущества кэширования: Некоторые параметры и результаты вычислений могут быть закэшированы и повторно использованы, что снижает общую нагрузку на процессор.
Эти причины делают BRDF Кука-Торренса предпочтительным выбором для многих разработчиков, стремящихся достичь баланса между реализмом и производительностью.
BRDF Кука-Торренса содержит диффузную (левую) и зеркальную (правую) части:
 =  + ,	(2)

где  — преломленная доля входящей световой энергии,  — отраженная,
 — диффузная часть (Ламбертово рассеяние):



=  ,	(3)


где c — альбедо или цвет поверхности (диффузная текстура поверхности).

 — зеркальная часть Кука-Торренса [13]:




= 		,	(4)
4( • )( • )

Диффузная компонента BRDF играет ключевую роль в определении того, как свет рассеивается при взаимодействии с поверхностью. Более сложные модели диффузного рассеяния учитывают множество факторов,

включая микроструктуру поверхности и эффекты само затенения. Эти модели обеспечивают более точное воспроизведение реального вида материалов, но также требуют значительных вычислительных ресурсов для оценки.
В зеркальной части Кука-Торренса:

D (Normal Distribution Function, NDF) — это функция нормального распределения, аппроксимирующая распределение микрограней на поверхности и влияет на зеркальное отражение..
F(Fresnel Equation) — уравнение Френеля описывает коэффициент поверхностного отражения при разных углах.
G(Geometry Function) — функция геометрии описывает свойство самозатенения микрограней, что влияет на видимость отраженного света.
Функция нормального распределения D статистически аппроксимирует долю площади поверхности микрограней, которые точно выровнены с медианным вектором h. Чем выше параметр шероховатости, тем шире распределение микрограней вокруг медианного вектора.
Есть большое количество функций нормального распределения. В работе использована NDF Trowbridge-Reitz GGX — это конкретная функция нормального распределения, которая часто используется для моделирования шероховатых поверхностей. Она обеспечивает реалистичное распределение микрограней и учитывает такие факторы, как самозатенение и межтеневой эффект.




(, , ) =	2
2(( • )2+1)2

,	(5)


где h — медианный вектор,  — значение шероховатости поверхности.

В отличие от GGX, NDF Блинна-Фонга и Бекмана имеют свои ограничения. Блинн-Фонг был разработан для быстрого вычисления и хорошо работает для гладких поверхностей, но не всегда идеален для шероховатых материалов. NDF Бекмана более физически корректен по сравнению с Блинна-Фонга, но может создавать нереалистично острые блики на шероховатых поверхностях.
Использование GGX в современном рендеринге позволяет достичь более высокого уровня реализма, особенно при визуализации сложных материалов и освещения.
Уравнения Френеля описывают, как свет отражается и преломляется на границе между двумя средами с разными показателями преломления. Они зависят от угла, под которым свет падает на поверхность.
Когда свет падает на поверхность, уравнения Френеля дают нам долю света, которая отражается, в зависимости от угла падения. Из этого отношения отражения и закона сохранения энергии мы можем непосредственно вычислить долю света, которая преломляется.
Уравнение Френеля является достаточно сложным, но его можно упростить с помощью приближения Френеля-Шлика:
(, , ) =  + ( • )5,	(6)
где h — медианный вектор,   — базовая отражательная способность поверхности.
Особенности уравнения Френеля:

1.Приближение Френеля-Шлика действительно только для диэлектриков или неметаллических поверхностей. Используется предварительно вычисленные значения для поверхностей при нормальном падении (с углом 0

градусов) и интерполируется это значение на основе угла обзора в соответствии с приближением Френеля-Шлика, так что можно использовать одно и то же уравнение как для металлов (но нужно подкрашивать металлическую поверхность), так и для неметаллов.
2.Значение базовой отражательной способности ищется в больших базах данных, и она приблизительно одинакова для большинства диэлектрических материалов.
Функция геометрии статистически аппроксимирует долю площади поверхности, где микроскопические неровности перекрывают друг друга, блокируя прохождение света (см. рис.4).


Рис. 4.Схема работы функции геометрии.

Функция геометрии представляет собой комбинацию приближения GGX и Шлика-Бекмана (Schlick-Beckmann), и известна как Schlick-GGX:




(, , ) =	 • 
( •)+

,	(7)


где k — функция геометрии для прямого освещения:
 = (+1)2,	(8)
8
BRDF играет важную роль в компьютерной графике и визуализации, так как она позволяет реалистично моделировать отражение света от различных поверхностей.

2.2.Метод Монте-Карло

Метод Монте-Карло — это набор методов в математике для исследования случайных процессов. Суть метода заключается в использовании данных случайных событий для получения приближенных результатов других вычислений. Хотя эти результаты не являются идеальными и не обладают математической точностью, они достаточно близки к реальным значениям для проведения полноценного анализа. Иногда использование метода МонтеКарло более эффективно и быстрее, чем вычисление всего по точным математическим формулам.
Метод Монте-Карло не может гарантировать точную оценку скорости сходимости с использованием случайно сгенерированных выборок. Вместо этого он предоставляет лишь вероятностную оценку этой скорости. Однако этот алгоритм довольно универсален и относительно прост, чтобы его можно было применить практически к любой функции, используя последовательность псевдослучайных чисел, основанных на равномерном законе распределения. Более того, можно разработать специальные псевдослучайные последовательности, основанные на других законах распределения, чтобы ускорить скорость сходимости в зависимости от интегрируемой функции.

Ошибка вычислений, как правило, пропорциональна v, где D —

некоторая постоянная, а N — число испытаний. Отсюда видно, чтобы уменьшить ошибку нужно увеличить N или уменьшить D. При сложности аппроксимирующей формулы достижение высокой точности становится затруднительным, поэтому метод Монте-Карло часто используют в задачах, где допустима точность в пределах 5  10% [8].

2.2.1.Правило трех сигм

Доверительный интервал (µ  3, µ + 3), в котором находится истинное значение µ случайной величины, распределенной по нормальному закону, с заданной вероятностью P, определяется по следующим формулам:
 {|  |  3 }  0.9973,	(9)
v
 = 1 	 ,	(10)


2 =	1






=1

(



 )2,	(11)


1

=1	

 =  ,	(12)
v

где µ — математическое ожидание, N — число независимых испытаний, 
—неизвестные случайные величины, полученные в результате испытаний, 
—несмещенная оценка дисперсии,  — стандартное отклонение случайной величины относительно её среднего значения.
Таким образом, можно увидеть, что случайная величина не отклонится от математического ожидания µ по абсолютной величине больше, чем на 3 с вероятностью 0.9973 [36].
Необходимо преобразовать формулу (11) для более удобного расчета:

 = v 1    (  )2 =
1	=1	

= v 1    ( )2 	1	(	 )2,	(13)


1

=1	


(1)

=1  


На основе этих данных рассчитывается значение , которое отражает степень вариативности цветов в пикселе.

Это правило можно использовать для оценки дискретной формы уравнения отраженной облучённости из-за того, что:
1.Центральная предельная теорема. Если есть большое количество независимых и одинаково распределенных случайных величин, их сумма будет стремиться к нормальному распределению, независимо от формы исходного распределения. В контексте расчетной формулы уравнения рендеринга, если рассматривается сумма большого количества независимых световых вкладов, результат будет приближаться к нормальному распределению.
2.Стандартное отклонение и дисперсия. При численном моделировании освещения часто имеется дело с выборками, которые имеют некоторую вариативность. Стандартное отклонение этих выборок может дать оценку разброса значений вокруг среднего. Используя правило трех сигм, можно оценить, какие значения являются "обычными" для данной сцены освещения, и какие являются выбросами.
3.Упрощение вычислений. Вместо вычисления точного распределения всех возможных значений освещенности, можно использовать правило трех сигм для быстрой оценки вероятности того, что реальное значение будет находиться в определенном диапазоне. Это особенно полезно при работе с большими объемами данных или в реальном времени, где вычислительные ресурсы ограничены.
4.Оценка вероятностей. Правило трех сигм позволяет оценить вероятность того, что значение освещенности будет лежать вне трех стандартных отклонений от среднего, что является маловероятным событием. Это может помочь в выявлении аномальных значений или в оценке качества моделирования.

Чтобы построить сцену нужно понять, какие объекты там могут вообще присутствовать. Принимаются во внимание следующие характеристики:
1.Отражательная способность — какое количество света отражает каждый объект.
2.Шероховатость поверхности — насколько сильно лучи рассеиваются при столкновении с объектом.
3.Излучение энергии — количество и длина волны света, которую излучает объект.
4.Прозрачность	—	отношение	пропущенного	сквозь	объект	света	к отраженному.
Этих параметров достаточно, чтобы смоделировать источники света, зеркальные и стеклянные поверхности, а также диффузные материалы.

2.2.2.Метод трассировки пути

В контексте трассировки пути метод Монте-Карло для аппроксимации непрерывных интегралов используется расчетную формулу:
 (,  ) =   + 1 	 (,  ,  ) (,  )( •  ),	(14)

	

	

=1  

				

Также следует упомянуть, что генерируются рандомные лучи и на выходе получается усредненное значение, создавая тем самым реалистичное изображение сцены.


Рис. 5. Схема траектории движения луча в методе трассировки пути.

Принцип работы трассировки пути заключается в следующем: от наблюдателя испускается луч света и ищется точка его пересечения с

объектом. Такой луч называется первичным. Когда этот луч встречает поверхность объекта, он может быть отражен, преломлен или поглощен в зависимости от материала объекта. Если материал имеет отражающие свойства, из точки испускается отраженный луч и для него вся процедура трассировки рекурсивно повторяется. Если материал имеет преломляющие свойства, то добавляется луч преломления. Все эти взаимодействия объединяются для получения окончательного цвета и освещения пикселя, который затем отображается на экране (см. рис. 5).

2.2.3.Тонмаппинг и гамма-коррекция

Тонмаппинг (англ. Tonemapping) — это метод обработки изображений, который позволяет адаптировать изображения с высоким динамическим диапазоном (англ. High Dynamic Range, HDR) для отображения на устройствах с ограниченным динамическим диапазоном (англ. Low Dynamic Range, LDR), таких как стандартные мониторы и телевизоры. Тонмаппинг сжимает диапазон яркости изображения, сохраняя при этом важные детали и контраст. Это делается для того, чтобы изображение выглядело более естественно и соответствовало ограничениям устройства отображения.




=    ,	(15)
1+

где  — это яркость отображаемого изображения (LDR),  — яркость исходного изображения (HDR).
Гамма-коррекция (англ. Gamma-Correction) — это процесс, который используется для коррекции яркости изображения в соответствии с нелинейными характеристиками мониторов. Гамма-коррекция учитывает, что человеческий глаз воспринимает свет нелинейно, и поэтому яркость пикселей на экране должна быть скорректирована так, чтобы соответствовать этому восприятию.
Формула гамма-коррекции может быть представлена как:

 =  •   ,	(16)

где  — исходное значение пикселя,  — скорректированное значение, 
— гамма-коэффициент, а A — масштабирующий коэффициент.

Оба эти процесса играют ключевую роль в достижении визуальной реалистичности и улучшении визуального восприятия изображений в компьютерной графике.

Разработанный программный код использует гамма-коррекцию и тонмаппинг в фрагментном шейдере, а именно в блоке условного оператора, где проверяется значение переменной, отвечающей за нажатие кнопки. Так, если значение равняется 0, то:
1.Происходит нормализация цветов с учетом альфа-канала.

2.Применяется тонмаппинг для сжатия диапазона цветов.

3.Выполняется гамма-коррекция с коэффициентом  = 2.2, что является стандартным для коррекции на многих дисплеях.
Иначе, если значение переменной равняется 1, то:

1.Используется логарифмический тонмаппинг для отображения глубины тонов.
2.Фрагменту присваивается красный цвет, интенсивность которого зависит от логарифмического значения, отражающего глубину тонов.

3.Реализация программы построения изображений
3.1.Графические библиотеки и спецификация OpenGL

Для построения полученной модели была использована графическая библиотека MESA, основанная на спецификация OpenGL.
MESA — это свободная программная библиотека, которая предоставляет реализацию графического API OpenGL и других связанных с ним интерфейсов с открытым исходным кодом. MESA ориентирована на обеспечение высокой производительности при работе с 3D-графикой, в том числе за счёт использования аппаратного ускорения работы с графикой, поддерживаемого графическими процессорами. MESA была создана Брайаном Полом в августе 1993 года.
OpenGL (англ. Open Graphics Library) — это кроссплатформенный API (англ. Application Programming Interface, интерфейс программирования приложений) для разработки двух- и трехмерной компьютерной графики. OpenGL был разработан Silicon Graphics Inc. (SGI) в 1992 году.
Существует несколько ключевых характеристик спецификации OpenGL [33]:
1.Кроссплатформенность: OpenGL работает на разных операционных системах, включая Windows, macOS, Linux и мобильные платформы.
2.Высокая производительность: API OpenGL поддерживает широкий спектр графических примитивов и алгоритмов. В них входит растеризация, шейдерные обработки, текстурирование и многое другое, что позволяет создавать сложные и реалистичные изображения. Которые содержат различные графические эффекты и при этом эффективно задействуют вычислительные ресурсы графических устройств.

3.Расширяемость: OpenGL можно расширить с помощью сторонних библиотек, таких как GLSL (шейдерный язык) и GLUT (библиотека утилит), для добавления дополнительных функций.
OpenGL работает путем отправки данных и команд непосредственно на графическое устройство. Эти данные описывают геометрию, текстуры и другие графические элементы, которые должны быть отрисованы на экране. Данные, такие как вершины, текстуры и цвета, перемещаются в видеопамять графической карты. Графический процессор использует серию обработчиков в графическом конвейере для преобразования исходных данных в пиксели на экране. Эти обработчики включают в себя различные шейдеры. После обработки данных в конвейере, графический процессор выполняет растеризацию, преобразуя геометрию в пиксели, а также внедряет текстуры и освещение. Затем графический процессор выполняет эти команды, используя подготовленные данные, и выводит изображение на экран.

3.1.1.Вычислительный шейдер

Шейдеры — это небольшие программы, которые работают на графическом устройстве и выполняют различные задачи по обработке графики (см. рис.6). Шейдеры программируются на C подобном языке GLSL [33].
GLSL (англ. OpenGL Shading Language) — это шейдерный язык, используемый в OpenGL для программирования графического конвейера. GLSL был введен в качестве части спецификации OpenGL 2.0 в 2004 году. Этот язык программирования был разработан ARB (англ. OpenGL Architecture Review Board) для создания шейдеров, которые напрямую управляют графическим конвейером в OpenGL. Это было значительным шагом вперед в развитии компьютерной графики, так как до этого шейдеры обычно писались на низкоуровневых ассемблероподобных языках.
Шейдеры GLSL компилируются в машинный код, который может быть выполнен на графическом процессоре. Когда объект отрисовывается в OpenGL, шейдеры вызываются для обработки вершин и фрагментов объекта. Это позволяет разработчикам точно контролировать аспекты рендеринга, такие как освещение, текстурирование и цветовые эффекты.
Вычислительный шейдер (Compute Shader) обычно подключается до стадии растеризации и работает независимо от основного графического конвейера. Он не связан с конкретными этапами обработки вершин или фрагментов, что позволяет ему обрабатывать данные в более общем и гибком
формате. Могут использоваться для задач, требующих высокой параллельной обработки, таких как физическое моделирование или обработка изображений [35]. В работе вычислительный шейдер используется для основных расчетов связанных с построением изображений.

3.1.2.Графический конвейер

Графический конвейер (конвейер рендеринга) — это комплексная система, которая преобразует трехмерные данные сцены в двумерное изображение на экране. Он состоит из нескольких последовательных этапов (см. рис.6):
1.Стадия вершин (Vertex fetch). На этом этапе вершины обрабатываются вершинными шейдерами. Каждая вершина может быть трансформирована, освещена, и к ней могут быть применены другие эффекты. Результатом является список вершин с их атрибутами, готовых к следующим шагам.
2.Стадия растеризации (Rasterization). На этом этапе трехмерные примитивы (такие как треугольники) преобразуются в двумерные фрагменты для отображения на экране. Этот процесс включает в себя интерполяцию атрибутов вершин, таких как цвет и текстурные координаты.
3.Стадия фрагментов (Fragment Processing). Фрагментный (пиксельный) шейдер обрабатывает каждый фрагмент (потенциальный пиксель), применяя текстуры, освещение и другие эффекты для определения его окончательного цвета и других атрибутов[34].
4.Стадия тестирования и смешивания (Tests and Blending). На этом этапе выполняются различные тесты, такие как тест глубины и тест трафарета, чтобы определить, должен ли фрагмент быть отображен на экране. Также может быть применено смешивание цветов для создания эффектов прозрачности и перекрытия.
5.Вывод на экран (Frame Buffer Operations). После всех тестов и смешивания окончательные пиксели записываются в буфер кадра, который затем выводится на экран.



Рис. 6. Упрощенная схема стандартной модели графического конвейера.

Этот конвейер позволяет графическим системам эффективно обрабатывать большие объемы данных и создавать сложные изображения с высокой степенью детализации и реализма. Конвейер рендеринга является основой для создания трехмерной графики в реальном времени и используется в играх, симуляциях и других приложениях, требующих высокопроизводительной визуализации.

3.1.3.Инструменты разработки OpenGL

GLFW (англ. Graphics Library Framework) — это библиотека управления окнами, предназначенная для использования с OpenGL. Она была создана в начале 2000-х годов. Основателем и первоначальным разработчиком GLFW является Маркус Гейнсон. Библиотека GLFW обеспечивает простой API для создания окон, контекстов и поверхностей для рендеринга, а также для получения ввода от клавиатуры, мыши и других устройств.
Вот некоторые ключевые особенности функции GLFW:

1.Портативность: библиотека работает на многих операционных системах, включая Windows, macOS и различные дистрибутивы Linux.
2.Простота использования: у GLFW хорошо написанная документация и множество примеров кода, которые облегчают начало работы и понимание того, как использовать библиотеку.
3.Управление окнами: можно легко создавать и управлять окнами, а также настраивать их свойства, такие как размер и положение.
4.Обработка ввода: GLFW предоставляет функции для обработки ввода от клавиатуры, мыши, джойстика и других устройств.
5.Контексты рендеринга: поддерживает создание контекстов OpenGL и OpenGL ES различных версий, включая управление версиями и профилями контекстов.
6.Мониторы и видеорежимы: GLFW позволяет получать информацию о мониторах и видеорежимах, а также создавать полноэкранные окна.
GLFW часто используется в сочетании с GLEW (англ. OpenGL Extension Wrangler Library). GLEW — это кроссплатформенная библиотека,

которая помогает управлять расширениями OpenGL, предоставляя механизмы для проверки доступности расширений и доступа к функциям расширений. GLEW была разработана Миланом Икитсом и Марсело Магальянесом, а также Левом Пиндером. Она впервые была представлена публике в 2002 году и с тех пор активно поддерживается и обновляется сообществом. GLEW автоматически проверяет, какие расширения поддерживаются на текущем оборудовании и загружает соответствующие функции.

3.2.Структура программы

Исходный код программы написан на языках С++ и GLSL, также для сборки программы используется сборщик проектов CMake. Эта программа является набором алгоритмов для создания изображений в реальном времени с использованием метода трассировки пути и модели освещения Кука- Торренса.
Структура программы включает в себя:

1.Заголовочный файл (scene.hpp): он определяет базовый класс Scene, который содержит общие методы и переменные для всех сцен.
2.Исходный файл (scene.cpp): реализует базовый класс Scene и предоставляет общие функции для инициализации, отрисовки и очистки сцены.
3.Заголовочный файл (path_tracing.hpp): определяет класс PathTracing, который является производным от класса Scene и реализует трассировку пути в режиме реального времени.
4.Исходный файл (path_tracing.cpp): реализует класс PathTracing и предоставляет методы для инициализации ресурсов, обновления сцены, отрисовки изображения и отображения текста.
5.Вычислительный шейдер (path_tracing_cs.glsl). Инициализирует сцену: создаются геометрические объекты (сферы, плоскости, коробки) и их материалы, которые будут использоваться для трассировки пути. Генерирует случайные числа. Функции Hash и Noise используются для создания псевдослучайных чисел, необходимых для реализации стохастических эффектов, таких как мягкие тени и отражения. Функция TracePath рекурсивно трассирует лучи через сцену, отражая их от объектов и собирая информацию о цвете и освещении. Функция BDRFcontribution вычисляет

вклад отраженного света в каждой точке пересечения с использованием модели освещения Кука-Торренса. Основная функция: main запускается для каждого текселя изображения. Она инициализирует сцену, вычисляет направление первичного луча, собирает цвета от трассировки пути и считает стандартное отклонение цвета по правилу трех сигм.
6.Вершинный шейдер (render_vs.glsl): его основная задача — передать текстурные координаты TexCoords и установить позицию вершины glPosition для дальнейшего использования в графическом конвейере.
7.Фрагментный шейдер (render_fs.glsl): получает цвет текселя из текстуры imageTexture и параметры пикселя из pixelParametersTexture. При нажатии кнопки, происходит коррекция цвета, согласно прописанным условиям.
8.Вершинный шейдер (text_vs.glsl). Этот шейдер помогает отображать объекты с текстурами. Он берет координаты объекта и его текстуры, объединяет их, и использует специальную матрицу, чтобы все выглядело правильно и с перспективой, когда это отображается на экране.
9.Фрагментный шейдер (text_fs.glsl). Этот шейдер используется для рендеринга текста с использованием текстур, где цвет текста textColor может быть динамически изменен с помощью uniform-переменной, а альфа-канал текстуры определяет, какие части текста будут видимыми.
10.Исходный файл (main.cpp) создает экземпляр класса PathTracing и запускает основной цикл отрисовки.
11.Сборщик проекта(CMakeList.txt). Он автоматически настраивает среду разработки, учитывая особенности операционной системы и доступные библиотеки. Скрипт упрощает компиляцию исходного кода, подключение необходимых библиотек и копирование ресурсов, таких как шейдеры и шрифты, в нужные места.

Основные особенности класса PathTracing:

1.инициализация шейдеров и текстуры для трассировки пути;

2.построение изображения из исходной сцены с помощью метода трассировки пути и модели освещения Кука-Торренса, используя вычислительный шейдер;
3.отрисовка результата трассировки пути на экран с использованием вершинного и фрагментного шейдеров;
4.отображение текста с использованием вершинного и фрагментного шейдеров;
5.управление камерой и обновление сцены;

6.создание	и	сохранение	скриншота	изображения	при	определенном количестве кадров.
В	функции	RenderLoop	основного	цикла	отрисовки	происходит следующее:
1.очистка буферов кадра и глубины;

2.обновление времени;

3.выполнение трассировки пути на графическом процессоре;

4.отрисовка данных из текстур на экран;

5.отображение текста в сцене.

GLSL описывает структуры данных, используемые для определения материалов, лучей, информации о пересечении, плоскостей, параллелепипедов и сфер в сцене трассировки пути. В материалах учитываются такие параметры как:

1.цвет альбедо, отражающий базовый цвет материала;

2.вектор излучения, указывающий на цвет, который материал излучает самостоятельно;
3.шероховатость поверхности, влияющая на рассеивание отраженного света;

4.степень зеркального отражения;

5.металличность, определяющая, насколько материал похож на металл.

В коде присутствуют три сферы, каждая из которых имеет свой уникальный материал:
1.Источник света. Материал этой сферы имеет высокий уровень излучения, что делает её ярким источником света в сцене.
2.Диффузная сфера: У материал этой сферы поверхность имеет высокую интенсивность красного цвета, низкую интенсивность зелёного и очень низкую интенсивность синего, что придаёт ей красноватый оттенок и делает поверхность матовой. За это отвечает параметр альбедо.
3.Металлическая сфера. Материал сферы имеет максимальные параметры металличности и зеркального отражения, что делает её поверхность зеркальной и блестящей.
Таким образом, при запуске программы на выходе получается итоговый результат. Программа реализует алгоритм трассировки пути для генерирования реалистичных изображений. Позволяет пользователю перемещаться в трехмерном пространстве с помощью мыши и клавиатуры. Отображает текст на экране, содержащий информацию о количестве кадров в секунду.

3.3.Моделирование и анализ результатов

В рамках проведенной серии вычислительных экспериментов были получены изображения с использованием метода трассировки пути, основанного на спецификации OpenGL. Каждый луч представляет собой одну итерацию расчета освещения для пикселя. Количество отражений одного луча было установлено равным восьми. Это значение влияет на количество отражений или преломлений луча, прежде чем он прекратит свой расчет. В динамической сцене пользователь может перемещаться, наблюдая за изменениями в реальном времени, тогда как в статичном режиме качество изображения будет улучшаться постепенно с каждым новым кадром.

Рис. 7. Изображение получено при помощи трассировки пути с количеством итераций = 1 (слева) и количеством итераций = 10000 (справа).

 
Рис. 8. Изображение получено при помощи трассировки пути с количеством итераций = 1 (слева) и количеством итераций = 10000 (справа).
В контексте шейдеров и графического программирования, нажатие клавиши может быть использовано для изменения визуального отображения объекта в окне приложения. Конкретно, активация клавиши ’C’ вызывает обновление изображения на экране.
Для вычисления стандартного отклонения цветовых значений пикселей в контексте правила трех сигм по формуле (15), используется функция calculateStdDev. Она анализирует выборку лучей, прошедших через пиксель, что важно для алгоритмов трассировки пути. Стандартное отклонение служит индикатором однородности цветов в выборке и влияет на шум и визуальное качество рендеринга.
В процессе расчета учитываются следующие параметры:

1.Количество лучей, прошедших через пиксель.

2.Сумма цветов, полученная от всех лучей.

3.Сумма квадратов цветов, необходимая для вычисления дисперсии.

4.Дисперсия цветов, указывающая на разброс значений относительно среднего.
Также была введена функция skip_pixel, которая определяет, следует ли прекратить расчеты для конкретного пикселя. Это решение принимается на основе стандартного отклонения и количества уже проверенных лучей. Если стандартное отклонение ниже порогового значения или количество проверенных лучей превышает заданный шаг, пиксель исключается из дальнейших расчетов и окрашивается в зеленый цвет. Это позволяет оптимизировать процесс трассировки пути, экономя время на обработку пикселей, которые уже достаточно точно оценены.

Рис. 9. Результат погрешности статистической оценки с количеством итераций
= 1000 (слева) и количеством итераций = 4000 (справа).

 
Рис. 10. Результат погрешности статистической оценки с количеством итераций = 7000 (слева) и количеством итераций = 10000 (справа).




Рис. 11. График зависимости скорости построения изображения без оптимизации и с введенной опимизацией от 0 до 10000 итераций.

 
Рис. 12. Результат погрешности статистической оценки с количеством итераций = 1000 (слева) и количеством итераций = 4000 (справа).

Рис. 13. Результат погрешности статистической оценки с количеством итераций = 7000 (слева) и количеством итераций = 10000 (справа).



Рис. 14. График зависимости скорости построения изображения без оптимизации и с введенной опимизацией от 0 до 10000 итераций.
Код применяет современные методы трассировки пути и физически точного рендеринга для генерации реалистичных изображений в режиме реального времени. В его функционал входит создание псевдослучайных последовательностей, определение точек пересечения с разнообразными геометрическими объектами и вычисление освещенности, исходя из физических характеристик материалов. В результате проведённого сравнения было продемонстрировано, что реализованная оптимизация, связанная с дополнительным введением статической оценки относительной погрешности компонент пикселей, способствует ускорению процесса генерации изображений.

Заключение

1.Изучены, описаны и реализованы модель освещения Кука-Торренса с применением PBR-техник и метод трассировки пути, основанный на ММК, в
виде	программы,	использующей	графическую	библиотеку	MESA, основанную на спецификации OpenGL.
2.Построена	тестовая	сцена	из	простейших	трехмерных	объектов (поверхностей 1-го и 2-го порядка).
3.Выполнена оптимизация программного кода, связанная с дополнительным

введением	статической	оценки	относительной	погрешности	компонент пикселей изображений.
4.Проведен сравнительный анализ скорости построения изображений ММК

с	помощью	разработанной	программы	с	включённой	и	отключённой оптимизацией.

Список литературы

1)И.М. Соболь. Численные методы Монте-Карло. М.,1973г. (дата обращения 16.03.2024)

2)А.В. Войтишек. Основы метода Монте-Карло. 2010г. (дата обращения 02.03.2024)

3)История физически-корректного рендеринга: [Электронный ресурс]. URL: https://www.pbr-book.org/3ed-2018/Introduction/A_Brief_History_of
_Physically_Based_Renderingsec:pbr-history (дата обращения 21.11.2023)

4)Physically Based Rendering: [Электронный ресурс]. URL: https://www.pbrbook.org/3ed-2018/Preface (дата обращения 21.11.2023)

5)PBR-текстуры:	[Электронный	ресурс].	URL: https://habr.com/ru/articles/458696/ (дата обращения 28.11.2023)

6)Ray	Tracing:	[Электронный	ресурс].	URL: https://developer.nvidia.com/discover/ray-tracing (дата обращения 28.11.2023)

7)Численные методы Монте-Карло: [Электронный ресурс]. URL: http://mipt.jinr.ru/xdocs/sobol.pdf (дата обращения 29.11.2023)

8)Метод Монте-Карло и его точность: [Электронный ресурс]. URL https://habr.com/ru/articles/274975/ (дата обращения 29.11.2023)

9)Multidimensional Adaptive Sampling and Reconstruction for Ray Tracing: [Электронный	ресурс].	URL: http://graphics.ucsd.edu/~henrik/papers/multidimensional_adaptive
_sampling/multidimensional_adaptive_sampling.pdf	(дата	обращения 29.11.2023)

10)Метод Монте-Карло в рендеринге: [Электронный ресурс]. URL: http://luthuli.cs.uiuc.edu/7Edaf/courses/Rendering/Papers-2/shirley96monte-1. pdf (дата обращения 29.11.2023)

11)Преимущества использования PBR-текстур: [Электронный ресурс]. URL: https://www.a23d.co/blog/benefits-of-using-pbr-textures/ (дата обращения 29.11.2023)

12)Использование PBR-текстур: [Электронный ресурс]. URL: https://www.lotpixel.com/blog/benefits-of-using-pbr-textures (дата обращения 29.11.2023)

13)PBR или Физически-корректный рендеринг: [Электронный ресурс]. URL: https://habr.com/ru/articles/426123/ (дата обращения 29.11.2023)

14)Метод Монте-Карло: [Электронный ресурс]. URL: https://math.ru/lib/plm/46 (дата обращения 29.11.2023)

15)Что такое Ray Tracing или трассировка лучей: [Электронный ресурс]. URL: https://club.dns-shop.ru/blog/t-99-videokartyi/30460-chto-takoe-ray-tracing
-ili-trassirovka-luchei-chto-daet-i-kak-rabo/ (дата обращения 29.11.2023)

16)Трассировка пути: [Электронный ресурс]. URL: https://habr.com/ru/articles/713246/ (дата обращения 29.11.2023)

17)Физически-корректный рендеринг: [Электронный ресурс]. URL: https://rikspieringhs.nl/PhysicalBasedRendering (дата обращения 01.12.2023)

18)История компьютерной графики: [Электронный ресурс]. URL: http:// learnwebgl.brown37.net/the_big_picture/webgl_history.html (дата обращения 01.12.2023)

19)The Computer Graphics Book Of Knowledge: [Электронный ресурс]. URL: https://www.cs.cmu.edu/ ph/nyit/masson/history.htm (дата обращения 01.12.2023)

20)Рендеринг	в	компьютерной	графике:	[Электронный	ресурс].	URL: https://allsoft.ru/news-soft/rendering-v-kompyuternoy-grafike-chto-eto-i- kakispolzuetsya/ (дата обращения 01.12.2023)

21)Что такое PBR-текстуры: [Электронный ресурс]. URL: https://skillbox.ru/media/gamedev/chto-takoe-pbrtekstury/ (дата обращения 01.12.2023)

22)PBR	materials:	[Электронный	ресурс].	URL: https://learn.microsoft.com/enus/azure/remote-rendering/overview/features/pbr- materials (дата обращения 01.12.2023)

23)Everything About PBR Textures And A Little More: [Электронный ресурс]. URL: https://www.artstation.com/blogs/luismesquita/PwEm/everything-aboutpbr- textures-and-a-little-more-part-1 (дата обращения 01.12.2023)

24)Everything you need to know about physically based rendering: [Электронный ресурс]. URL: https://www.adobe.com/products/substance3d/ discover/pbr.html( дата обращения 01.12.2023)

25)Applications of Computer Graphics: [Электронный ресурс]. URL: https://www.geeksforgeeks.org/applications-of-computer-graphics/	(дата обращения 01.12.2023)

26)What are the various uses of computer graphics: [Электронный ресурс]. URL: https://www.quora.com/What-are-the-various-uses-of-computer-graphics (дата обращения 01.12.2023)

27)Виды компьютерной графики: [Электронный ресурс]. URL: https://ncrdo
.ru/center/blog/vidy-kompyuternoy-grafiki/ (дата обращения 01.12.2023)

28)PBR. Физически корректный рендер : [Электронный ресурс]. URL: https:
//cgitems.ru/articles/pbr-fizicheski-korrektnyy-render/	(дата	обращения 01.12.2023)

29)Blender 3D: [Электронный ресурс]. URL: https://media.contented.ru/glossary
/blender-3d/ (дата обращения 01.12.2023)

30)Основы LaTeX: [Электронный ресурс]. URL: https://habr.com/ru/companies
/ruvds/articles/574352/ (дата обращения 01.12.2023)

31)Пособие для LaTeX: [Электронный ресурс]. URL: https://www.sgu.ru/ sites/default/files/method_info/2017/practika2017.pdf (дата обращения 01.12.2023)

32)Что такое шейдеры, зачем они нужны: [Электронный ресурс]. URL: https://habr.com/ru/articles/677360/ ( дата обращения 01.12.2023)

33)Michael Manzke. Implementation of Monte Carlo path tracing algorithm based on OpenGL (дата обращения 09.05.2024)

34)Рендеринг 3D графики с помощью OpenGL: [Электронный ресурс]. URL: https://habr.com/ru/articles/467599/ (дата обращения 09.05.2024)

35)Shaders: [Электронный ресурс]. URL: https://habr.com/ru/articles/313380/ (дата обращения 11.05.2024)

36)Быковских Д.А. Моделирование течения газа Кнудсена в трехмерной области методом Монте-Карло (дата обращения 11.05.2024)

37)Ray Tracing vs Path Tracing: What is the Difference : [Электронный ресурс]. URL: https://hardwaretimes.com/ray-tracing-vs-path-tracing-what-is- thedifference/ (дата обращения 01.12.2023)

Приложение

Листинг кода
1 # ifndef SCENE_HPP
2 # define SCENE_HPP
3


4 # include " shader_program_impl . hpp "
5 # include <GL/ glew .h>
6 # include <GLFW / glfw3 .h>
7


8 # include <string >
9 # include  " glm / gtc / matrix_transform . hpp "
10 # include <glm / glm . hpp >
11 # include <png .h>
12 # include <filesystem >
13


14 class Scene {
15 protected:
16


17	// Holds all state information relevant to a character as loaded using
18	// Free Type
19	struct Character {
20	unsigned int Texture ID ; // ID handle of the glyph texture
21	glm :: ivec2  Size ;	// Size of glyph
22		glm :: ivec2 Bearing ;	// Offset from baseline to left / top of glyph
23		unsigned int Advance ;	// Horizontal offset to advance to next glyph
24	};

25	void Render Text ( std :: string text , float x, float y, float scale , glm :: vec3color );
26


27	GLFWwindow * window ;
28	static void Key Callback ( GLFWwindow * window , int key , int

scancode , intaction , int mode );
29	static void Mouse Callback ( GLFWwindow * window , double xpos , double	ypos );
30	static void Framebuffer Size Callback ( GLFWwindow * window , int width , int height );
31


32	void Save Image ( std :: string const & directory , std :: string const & name );
33	// Global variables
34	static  glm :: vec3  camera Pos ;
35	static	glm :: vec3  camera Front ;
36	static	glm :: vec3  camera Up ;

37	static	GLboolean clear Buffer ;
38		

39	static	float delta Time ;

40	static	float last Frame ;

41	static	float camera Speed ;
42	static	GLboolean is_moved ;
43		

44	// Init	ial viewing angle

45	static	float yaw ;

46	// Init	ial pitch angle

47	static	float pitch ;
48		

49	static	float lastX ;

50	static	float lastY ;

51	static	bool first Mouse ;

52	static	float mouse Sensitivity ;

53	static	float button_value ; // Button
54		
55 public:
56	int WIDTH , HEIGHT ;
57	Scene ( std :: string const & windowTitle , int width , int height );
58	virtual ~ Scene ();
59	void Render Loop ();
60	virtual  void  Clear Buffers ();
61


62	// Load models , textures , initialize shaders , etc .

63	virtual void Init Scene () {}
64	// Draw your scene
65	virtual void Render () {}
66 };

67 #endif

Листинг 1. Заголовочный файл (scene.hpp)

1 # include " scene . hpp "
2 # include " shader_program_impl . hpp "
3 # include <memory >
4 # include <string >
5 # include <filesystem >
6

7 glm :: vec3  Scene :: camera Pos = glm :: vec3 (0.0 f, 0.0 f, 3.0 f);
8 glm :: vec3  Scene :: camera Front = glm :: vec3 (0.0 f, 0.0 f,  -1.0 f);
9 glm :: vec3 Scene :: camera Up = glm :: vec3 (0.0 f, 1.0 f, 0.0 f);
10 GLboolean Scene :: clear Buffer = false ;
11


12 float Scene :: delta Time = 0.0 f;
13 float Scene :: last Frame = 0.0 f;
14 float Scene :: camera Speed = 0.05 f;
15


16 // Initial viewing angle
17 float Scene :: yaw = -90.0 f;
18 // Initial pitch angle
19 float Scene :: pitch = 0.0 f;
20


21 float Scene :: lastX = 400;
22 float Scene :: lastY = 300;
23 bool Scene :: first Mouse = true ;
24


25 float Scene :: mouse Sensitivity = 0.1 f;
26 float Scene :: button_value ; // Button
27

28 Scene :: Scene ( std :: string const & windowTitle , int width , int height )
29	: WIDTH ( width ), HEIGHT ( height ) {
30	# ifndef NDEBUG
31	std :: cout <<   PRETTY_FUNCTION   << std :: endl;
32	#endif

33	//	Init GLFW

34	if	(! glfw Init ())

35		exit ( EXIT_FAILURE );

36	//	Set all the required options for GLFW
37	glfw Window Hint ( GLFW_CONTEXT_VERSION_MAJOR ,	4);
38	glfw Window Hint ( GLFW_CONTEXT_VERSION_MINOR ,	4);
39	glfw Window Hint ( GLFW_OPENGL_PROFILE ,  GLFW_OPENGL_CORE_PROFILE );
40	glfw Window Hint ( GLFW_RESIZABLE , GL_FALSE );
41


42	// Create a GLFW window object that we can use for GLFW ’ s functions
43		window = glfw Create Window ( WIDTH , HEIGHT , window Title . c_str () , nullptr ,nullptr );
44	if (! window ) {
45	glfw Terminate ();
46	exit ( EXIT_FAILURE );
47	}

48	glfw Make Context Current ( window );
49


50	// Set the required callback functions
51	glfw Set Key Callback ( window , Key Callback );
52	glfw Set Framebuffer Size Callback ( window ,	Framebuffer Size Callback );
53	glfw Set Cursor Pos Callback ( window ,  Mouse Callback );
54	glfw Set Input Mode ( window , GLFW_CURSOR , GLFW_CURSOR_DISABLED );
55


56		// Set this to true so GLEW knows to use a modern approach to retrieving
57	// function pointers and extensions
58	glew Experimental = GL_TRUE ;
59	// Initialize GLEW to set up the Open GL Function pointers
60	if ( glew Init () != GLEW_OK ) {
61	glfw Terminate ();

62	exit ( EXIT_FAILURE );
63	}

64

65	// Define the viewport dimensions
66	gl Viewport (0 , 0 , WIDTH , HEIGHT );
67	// Turn off V- Sync
68	glfw Swap Interval (0) ;
69 }

70

71 Scene ::~ Scene () {
72	glfw Terminate ();
73	# ifndef NDEBUG
74	std :: cout <<   PRETTY_FUNCTION   << std :: endl;
75	#endif
76 }

77

78 void Scene :: Render Loop () {
79	// configure global Open GL state
80	gl Enable ( GL_DEPTH_TEST );
81	gl Depth Func ( GL_LESS );
82	gl Depth Mask ( GL_TRUE );
83	Init Scene ();
84	// Render loop
85	while (! glfw Window Should Close ( window )) {
86	// render
87	gl Clear Color (.5 f, .5 f, .5 f, 1.0 f);

88	gl Clear ( GL_COLOR_BUFFER_BIT	| GL_DEPTH_BUFFER_BIT );
89	if ( clear Buffer )

90	Clear Buffers ();

91	Render ();

92	glfw Swap Buffers ( window );
93	// Poll IO events ( keys pressed / released , mouse moved etc .)

94	glfw Poll Events ();

95	}
96 }	
97

98 void Scene :: Clear Buffers () { clear Buffer = false ; }
99


100 void Scene :: Framebuffer Size Callback ( GLFWwindow * window , int width , int height ) {
101	gl Viewport (0 , 0 , width , height );
102 }

103


104 GLboolean Scene :: is_moved = false ;
105


106 void Scene :: Key Callback ( GLFWwindow * window , int key , int scancode
, int action , int mode ) {
107	// Is called whenever a key is pressed / released via GLFW
108	if ( key == GLFW_KEY_ESCAPE && action == GLFW_PRESS ) {
109	glfw Set Window Should Close ( window , GL_TRUE );
110	}

111


112	if ( glfw Get Key ( window , GLFW_KEY_W ) == GLFW_PRESS ) {
113	camera Pos += camera Speed * camera Front ;
114	clear Buffer = true ;
115	}

116	if ( glfw Get Key ( window , GLFW_KEY_S ) == GLFW_PRESS ) {
117	camera Pos -= camera Speed * camera Front ;
118	clear Buffer = true ;
119	}

120	if ( glfw Get Key ( window , GLFW_KEY_A ) == GLFW_PRESS ) {
121		camera Pos -= glm :: normalize ( glm :: cross ( cameraFront , camera Up )) *camera Speed ;
122	clear Buffer = true ;
123	}

124	if ( glfw Get Key ( window , GLFW_KEY_D ) == GLFW_PRESS ) {

125	camera Pos += glm :: normalize ( glm :: cross ( cameraFront , camera Up ))
* camera Speed ;
126	clear Buffer = true ;
127	}

128

129	if ( key == GLFW_KEY_C && action == GLFW_PRESS ) {
130	button_value = 0.0 f;
131	}

132	if ( key == GLFW_KEY_C && action == GLFW_RELEASE ) {
133	button_value = 1.0 f;
134	}

135 }

136


137 void Scene :: Mouse Callback ( GLFWwindow * window , double xpos , double ypos )
{
138	if ( first Mouse ) {
139	lastX = xpos ;
140	lastY = ypos ;
141	first Mouse = false ;
142	}

143


144	float xoffset = xpos - lastX ;
145	// Invert to make the pitch angle correct
146	float yoffset = lastY - ypos ;
147	lastX = xpos ;
148	lastY = ypos ;
149


150	xoffset *= mouse Sensitivity ;
151	yoffset *= mouse Sensitivity ;
152


153	yaw += xoffset ;
154	pitch += yoffset ;
155


156	// Limit the pitch angle from -89 to 89 degrees
157	if ( pitch > 89.0 f)
158	pitch = 89.0 f;
159	if ( pitch < -89.0 f)
160	pitch = -89.0 f;

161	

162	// Calculate the new camera direction vector

163	glm :: vec3  front ;

164	front . x = cos ( glm :: radians ( yaw )) * cos ( glm :: radians ( pitch ));

165	front . y = sin ( glm :: radians ( pitch ));
166	front . z = sin ( glm :: radians ( yaw )) * cos ( glm :: radians ( pitch ));

167	camera Front = glm :: normalize ( front );

168	clear Buffer = true ;
169	}

170				

171	char	const	* PIC_FILE_NAME_FORMAT =	". png ";

172	char	const	* TXT_ERR_FILE_CREATING	= " TXT_ERR_FILE_CREATING ";

173	char	const	* TXT_ERR_CREATE_OBJECT	= " TXT_ERR_CREATE_OBJECT ";
174				

176		void Scene :: : Save Image ( std :: string	const & directory , std :: string const & name){
177	std :: filesystem :: path	image Path ( directory );
178	image Path . append ( name  + PIC_FILE_NAME_FORMAT );
179	image Path = std :: filesystem :: absolute ( image Path );
180


181	FILE * fp = fopen ( image Path . c_str () , " wb");
182

183	if	(! fp) {

184		std :: cout  << image Path  << std :: endl ;

185		std :: cout  << TXT_ERR_FILE_CREATING  << std :: endl ;

186		exit (1) ;

187	}	
188		

189	png_structp png_ptr = png_create_write_struct (




190	PNG_LIBPNG_VER_STRING ,NULL , NULL , NULL );
if (! png_ptr ) {

191	std :: cout  << TXT_ERR_CREATE_OBJECT  << std :: endl ;

192	fclose(fp);

193	exit(1);

194	}

195


196	png_infop png_info ;

197	if (!( png_info = png_create_info_struct ( png_ptr )) ||

198	setjmp ( png_jmpbuf ( png_ptr ))) {

199	std :: cout  << TXT_ERR_CREATE_OBJECT  << std :: endl ;

200	png_destroy_write_struct (& png_ptr , NULL );
201	fclose(fp);

202	exit(1);

203	}
204	

205	png_init_io ( png_ptr , fp);
206		png_set_IHDR ( png_ptr , png_info , WIDTH , HEIGHT , 8 ,PNG_COLOR_TYPE_RGB_ALPHA ,
207	PNG_INTERLACE_NONE ,	PNG_COMPRESSION_TYPE_BASE ,
208	PNG_FILTER_TYPE_DEFAULT );
209


210	png_set_compression_level ( png_ptr , 9);
211


212	// rgba = 4 bytes
213	std :: unique_ptr < GLubyte [] > pixels ( new GLubyte [4 * WIDTH * HEIGHT ]);
214	gl Pixel Storei ( GL_UNPACK_ALIGNMENT , 1);
215	gl Read Pixels (0 , 0 , WIDTH , HEIGHT , GL_RGBA , GL_UNSIGNED_BYTE ,
pixels . get());
216


217	unsigned  char * rows [ HEIGHT ];
218	for ( int i = 0; i < HEIGHT ; ++i) {
219	rows [ HEIGHT - i - 1] = pixels . get () + ( i * WIDTH * 4);
220	}

221	png_set_rows ( png_ptr , png_info , rows );
222	png_write_png ( png_ptr , png_info , PNG_TRANSFORM_IDENTITY , NULL );
223	png_write_end ( png_ptr , png_info );
224


225	png_destroy_write_struct (& png_ptr , NULL );
226	fclose(fp);

227


228	# ifndef NDEBUG
229	std :: cout << " Image " << image Path << " is saved " << std :: endl ;
230	#endif
231 }



Листинг 2. Исходный файл (scene.cpp)

1 # version 430 core
2


3 layout ( local_size_x = 10 , local_size_y = 10 , local_size_z = 1) in;
4


5 layout ( rgba32f , binding =0) uniform  image2D  image Texture ;
6 layout ( rgba32f , binding =1) uniform image2D pixel Parameters Texture ;
7


8 layout ( location = 0) uniform float t;
9

10 uniform vec2 texture_size ;
11


12 // Position , Direction and up vectors of camera
13 uniform vec3 u Position ;
14 uniform vec3 u Direction ;
15 uniform vec3 uUp ;
16 uniform float uFOV = 1. 5708 f;
17


18 uniform float epsilon ;
19 uniform float step_check ;
20


21 // For random numbers
22 float uTime = t;
23 const uint MAX_DEPTH = 4;
24 const float PI = 3 . 1415926535 f;
25

26 const uint PLANE_COUNT = 5;
27 const uint SPHERE_COUNT = 3;
28 const uint BOX_COUNT = 1;
29

30 str	uct Mat	erial {

31	vec3 a	lbedo ;

32	vec3 e	mission ;

33	float	roughness ;

34	float	specular ;

35	float	metalness ;
36 };		


37


38 struct Ray {
39	vec3  orig;
40	vec3  dir;
41 };

42


43 struct Hit Record {
44	vec3 p;
45	vec3 normal ;
46	float t;
47	Material material ;
48 };

49


50 struct Plane {
51	vec3 p;
52	vec3 n;
53	Material material ;
54 };

55


56 struct Box
57 {

58	vec3	position ;

59	vec3	half Size ;

60	mat3	rotation ;

61	Mater	ial material ;
62 };		

63


64 struct Sphere
65 {

66	vec3 position ;
67	float radius ;
68	Material material ;
69 };

70


71 Sphere spheres [ SPHERE_COUNT ];
72 Plane planes [ PLANE_COUNT ];
73 Box boxes [ BOX_COUNT ];
74


75 void Initialize Scene ()
76 {

77	// Room material
78	Material room Surface ;
79	room Surface . albedo = vec3 (.8) ;
80	room Surface . emission  = vec3 (0.) ;
81	room Surface . roughness = 1.;
82	room Surface . specular = 0.;
83	room Surface . metalness = 0.;
84


85	// Floor
86	planes [0]  =  Plane ( vec3 (0. , -1 ,0.) , vec3 (0 ,1 ,0) , room Surface );
87	// Ceiling
88	planes [1]  =  Plane ( vec3 (0. ,1. ,0.) , vec3 (0. , -1. ,0.) , room Surface );
89	// Back wall
90	planes [2]  =  Plane ( vec3 (0 ,0 , -1) , vec3 (0 ,0 ,1.) , room Surface );
91	// Left wall ( red )
92	room Surface . albedo = vec3 (1. ,0 ,0);

93	planes [3]  =  Plane ( vec3 ( -1 ,0. ,0.) , vec3 (1. ,0. ,0.) , room Surface );
94	// Right wall ( green )
95	room Surface . albedo = vec3 (0. ,1. ,0) ;
96	planes [4]  =  Plane ( vec3 (1. ,0. ,0.) , vec3 ( -1. ,0 ,0.) , room Surface );
97


98	// Light Sphere
99	Material light Surface ;
100	light Surface . albedo  = vec3 (1 ,1 ,1.);
101	light Surface . emission  = vec3 ( 200.) ;
102	light Surface . roughness = .9;
103	light Surface . specular = .1;
104	light Surface . metalness = 0.;
105


106	spheres [0]. position  = vec3 (.5 ,.5 , -.5);
107	spheres [0]. radius = .25;
108	spheres [0]. material = light Surface ;
109


110	// Diffuse sphere
111	Material diffuse Surface ;
112	diffuse Surface . albedo  = vec3 (.9 ,.1 ,.10) ;
113	diffuse Surface . emission  = vec3 (0.) ;
114	diffuse Surface . roughness = .9;
115	diffuse Surface . specular = .1;
116	diffuse Surface . metalness = 0.;

117	

118	spheres [1]. position	=  vec3 ( -.5 ,.5 ,0.);

119	spheres [1]. radius =	.25;

120	spheres [1]. material	= diffuse Surface ;
121		

122	// Metal sphere	
123	Material metal Surface ;
124	metal Surface . albedo  = vec3 (.5 ,.5 ,.5) ;
125	metal Surface . emission  = vec3 (0.) ;
126	metal Surface . roughness = 1.;
127	metal Surface . specular = 1.;

128	metal Surface . metalness = 1.;

129	

130	spheres [2]. position	=  vec3 (.0 , -.35 ,0.) ;

131	spheres [2]. radius =	.25;

132	spheres [2]. material	= metal Surface ;
133		

134	// boxes
135	Material box Surface ;
136	box Surface . albedo = vec3 (.5 ,.5 ,.5) ;
137	box Surface . emission = vec3 (0.) ;
138	box Surface . roughness = 1.;
139	box Surface . specular = 1.;

140	box Surface . metalness = 1.;
141	

142	boxes [0]. position = vec3 (0. , -.8 ,0.);

143	boxes [0]. half Size  = vec3 (.5 ,.2 ,.5) ;
144	boxes [0]. rotation = mat3 (
145	1. ,0. ,0. ,

146	0. ,1. ,0. ,
147	0. ,0. ,1.
148	);

149	boxes [0]. material = box Surface ;
150 }

151


152 float Hash ( const float n){
( n) * 43758 . 54554213 ) ;







158	co *= fract ( uTime ++* 12 . 343 ) ;
159	return  Hash ( dot ( co. xy , vec2 (12.9898 , 78. 233) ));
160 }

161


162 vec3 random_in_unit_sphere ( float seed , vec2 coordinates ){

163	// Returns a random direction in unit sphere ( used in the BRDF )
164	float rand = Noise ( seed * coordinates );

165	float	phi = 2. * PI * rand ;
166	rand =	Noise ( seed * coordinates );

167	float	cos Theta = 2. * rand - 1.;

168	rand =	Noise ( seed * coordinates );

169	float	u = rand ;
170		

171	float	theta = acos ( cos Theta );

172	float	r = pow (u, 1./ 3.) ;
173		

174	float	x = r * sin ( theta ) * cos ( phi );

175	float y = r * sin ( theta ) * sin ( phi );
176	float z = r * cos ( theta );
177		

178	return vec3 (x, y, z);

179	}	
180		
181 // Creating the BRDF
182 // The Normal Distribution Function
183 float Distribution GGX ( vec3 N, vec3 H, float a){

184	//	N,	normal of the surface			
185	//	H,	halfway vector			
186	//	a,	surface roughness			
187						

188	//	We	are doing our approximations based on	the	Trowbridge - Reits	GGX :

189	flo	at	a2 = a * a;			

190	flo	at	NdotH = max ( dot (N, H), 0.) ;			

191	flo	at	Ndot H2 = NdotH * NdotH ;			
192						

193	flo	at	nom = a2 ;			

194	flo	at	denom = ( Ndot H2 * ( a2 -1.) + 1.) ;			

195	den	om	= PI * denom * denom ;			
196						
197	return nom / denom ;
198 }

199


200	// The Geometry Function	

201	float Geometry Schlick GGX ( float NdotV , float k){	

202	// Approximations based on Schlick - GGX :	

203	float nom = NdotV ;	

204	float denom = NdotV * (1. - k) + k;	
205		


206	return nom / denom ;	

207	}	

208		


209	float Geometry Smith ( vec3 N, vec3 V, vec3 L, float	k){

210	float NdotV = max ( dot (N, V), 0.) ;	

211	float NdotL = max ( dot (N, L), 0.) ;	

212	float ggx1 = Geometry Schlick GGX ( NdotV , k);	

213	float ggx2 = Geometry Schlick GGX ( NdotL , k);	

214	return ggx1 * ggx2 ;	

215	}	

216	

217	// Determining the reflection vector

218	float Fresnel Schlick ( float nIn , float nOut , vec3 direction , vec3 normal )

219	{

220	float R0 = (( nOut - nIn ) * ( nOut - nIn )) / (( nOut + nIn ) * (( nOut + nIn ));
221	float fresnel = R0 + (1. - R0 )* pow ((1. - abs ( dot ( direction , normal ))), 5.) ;
222	return fresnel ;
223 }

224

225 bool plane Intersection ( in Ray r, out Hit Record hit , float maxT ){
226	// Checks for intersections with the plane objects in the scene .
227	// Updates hit attribute with relevant information .
228	float minT = . 0001;
229	float current T = maxT ;
230	vec3  normal;
231	Material material ;
232


233	for ( int j = 0; j < planes . length (); ++j){	

234	vec3 p = planes [ j]. p;	

235	vec3 n = planes [ j]. n;	
236		


237	float t = dot (p- r. orig , n) / dot ( r. dir ,	n);

238	if( minT < t && t < current T ){	

239	current T = t;	

240	normal = n;	

241	material = planes [ j]. material ;	

242	}	

243	}	

244	if( current T < maxT ){

245		hit . t = current T ;

246		hit . material = material ;

247		hit . normal = normal ;

248		return  true ;

249	}	

250	else

251	return false ;

252	}	
253		

254	bool	sphere Intersection ( in Ray r, out Hit Record hit , float maxT ){

255	//	Function used to find intersection between the traced ray and
spheres .

256


257	float minT = . 0001;

258	float current T = maxT ;	

259	vec3 normal ;	

260	Material material ;	
261		

262	for ( int i = 0; i < spheres . length (); ++i){	

263	vec3 oc = r. orig - spheres [ i]. position ;//	Difference	ray
	origin andsphere ’ s center .		

264	float a = dot ( r. dir , r. dir );		

265	float b = 2.* dot ( oc , r. dir );		


266	float	c = dot ( oc , oc) - spheres [ i]. radius * spheres [ i]. radius ;

267	float	det = b* b - 4.* a* c;

268	float	denominator = (2.* a);
269		


270	
// Possible intersection

271	if( denominator != 0. && det >= 0.) {

272	float  t1 = (-b- sqrt ( det ))/ denominator ;

273	float  t2 = (- b+ sqrt ( det ))/ denominator ;

274	float t = min ( t1 , t2 );

275	if( minT < t && t < current T ){
276	current T = t;

277	normal = normalize ( r. orig +t * r. dir - spheres [ i].
	position );

278	material = spheres [ i]. material ;
279	}

280	}

281	}

282	if( current T != maxT ){

283	hit . t = current T ;

284	hit . material = material ;

285	hit . normal = normal ;
286	return  true;

287	}

288	else

289	return  false;

290	}
291	

292	// Determining the point of intersection with the box

293	bool box Intersection ( in Ray r, out Hit Record hit , float maxT ){

294	// Checks for intersections with the box objects in the scene .
295	// Updates hit attribute with relevant information .

296	float minT = . 0001;

297	float current T = maxT ;
298	vec3  normal;

299	Material material ;
300	for ( int j = 0; j < boxes . length (); ++j){

301	vec3	rd	= boxes [ j]. rotation	* r. dir ;

302	vec3	ro	= boxes [ j]. rotation	* ( r. orig - boxes [ j]. position );


303	vec3 m = vec3 (1.) / rd;


) 1.: -1. , ( rd.z <0.) 1.:
-1.) ;











312		if( minT < t && t < current T && tF > t){
313		mat3  txi = transpose ( boxes [ j]. rotation );
314					

315		if( t1 . x > t1 . y && t1 . x > t1 . z){

316			normal =	txi [0]* s. x;

317		}			

318		else if( t1 . y	> t1 . z){

319			normal	=	txi [1]* s. y;
320		}			

321		else	{		

322			normal	=	txi [2]* s. z;
323		}			

324		curr	ent T =	t	;

325		mate	rial =	p	lanes [ j]. material ;
326		}			

327	}				
328					

329	if( c	urrent T < maxT ){	

330		hit . t = current T ;

331		hit . material = material ;

332		hit . normal = normal ;

333		return  true ;		

334	}				

335	else				
336	return  false;

337 }

338


339 // Determine the point of intersection with any object
340 bool object Intersection ( in Ray r, out Hit Record hit , float maxT ){
341


342	Hit Record  hit Temp ;
343	hit.t=maxT;
344


345	bool  ray Intersected = false ;
346


347	// Plane intersection
348	if( plane Intersection (r,  hitTemp , hit . t)){
349	hit = hit Temp ;
350	ray Intersected  = true ;
351	}

352


353	// Sphere intersection
354	if( sphere Intersection (r, hitTemp , maxT )){
355	hit = hit Temp ;
356	ray Intersected = true ;
357	}



358

359	// Box intersection
emp , hit . t)){




364	return  ray Intersected ;
365 }

366


367 vec3  get Reflection ( Ray r, Hit Record hit , float seed , vec2  Tex Coord ){
368		// Calculating the reflection direction based on the specular attributeof the material .

369		vec3 diffuse Dir = normalize ( hit . normal + random_in_unit_sphere ( seed ,Tex Coord ));
370	vec3 specular Dir = reflect ( r. dir , hit . normal );
371


372	vec3 next Dir = mix ( diffuseDir , specularDir , hit . material . specular );
373	return  normalize ( next Dir );
374 }

375		

376	// The Fresnel Equation	

377	vec3 fresnel Schlick ( float	cosTheta , vec3 F0 ){

378	return F0 + (1. - F0 ) *	pow (1. - cosTheta , 5.) ;

379	}	
380		

381	vec3 BDRFcontribution ( Ray
vec3 Li){	firstRay , Ray secondRay , Hit Record firstHit ,
382	vec3 halfway = normalize (- first Ray . dir + first Hit . normal );
383	float cos Theta = dot ( second Ray . dir , first Hit . normal );
384


385	// The microfacet normals influence
386		float D = Distribution GGX ( first Hit . normal , halfway , first Hit . material .roughness );
387

388	// Remapping of roughness for IBL
389		float k = ( first Hit . material . roughness +1.) * ( first Hit . material .roughness +1.) / 8.;
390	// The surface overshadowing
391		float G = Geometry Smith ( first Hit . normal , - first Ray . dir , second Ray . dir , k);
392

393	// The reflectivity when looking at the surface at a 0 degrees angle
394	vec3 F0 = vec3 (.04) ;
395	// More reflectivity depending on metalness
396	F0 = mix ( F0 , first Hit . material . albedo , first Hit . material . metalness );
397

398


399	vec3  numerator =D* F* G;
400	float denominator =(4.* max ( dot ( second Ray . dir , first Hit . normal ) ,0.)*
max ( dot(- first Ray . dir , first Hit . normal ) ,0.));
401	vec3	specular = numerator / max ( denominator ,. 0001) ;
402


403	float NdotL = max ( dot ( halfway , first Hit . normal ), 0.) ;
404	return ((1. - first Hit . material . specular ) * ( first Hit . material . albedo
/ PI) +specular )* Li* NdotL ;//  / float ( SAMPLES );
405 }

406


407 // Dynamic level depth
408 vec3 Trace Path ( Ray primaryRay , float seed , vec2 Tex Coord ) {
409	const float maxT = 10 e10 ;
410	Hit Record  hits [ MAX_DEPTH ];
411	Ray  rays [ MAX_DEPTH ];

412	rays [0] = primary Ray ;

413	int i;
414	for ( i = 0; i < MAX_DEPTH - 1; ++i){

415	hits [ i]. t = maxT ;

416	if( object Intersection ( rays [ i], hits [ i], maxT )){

417	rays [ i +1]. orig  = rays [ i]. orig + hits [ i]. t * rays [ i]. dir ;

418	rays [ i +1]. dir = get Reflection ( rays [ i], hits [ i], seed , Tex Coord );
419	}

420	else break ;

421	}

422	for ( int k = i; k > 0; -- k){
423	hits [k -1]. material . emission += BDRFcontribution ( rays
424	[k -1] ,  rays [ k],  hits [k -1] ,  hits [ k]. material . emission );
425	}

426	return hits [0]. material . emission ;
427 }

428


429 vec3 Get Ray Direction ( vec2 texcoord , vec2 viewport Size , float fov , vec3 direction , vec3 up) {
430	vec2 tex Diff = .5 * vec2 (1. -2* texcoord .x, 2.* texcoord .y -1.) ;


431	vec2
1.)	angle Diff = tex Diff * vec2 ( viewport Size . x / viewport Size .y,

432	* tan (	fov *.5) ;
433		

434	vec3	ray Direction  = normalize ( vec3 ( angleDiff ,1. f));

435	vec3	right = normalize ( cross ( up , direction ));

436	mat3	view To World = mat3 ( right , up , direction );
437		

438	return view To World * ray Direction ;

439	}	
440		

441	float calculate Std Dev ( vec3 sum_color , vec3 color_sqr , float num Rays )	{

442	vec3 variance = color_sqr / ( num Rays - 1);	
443	vec3 m = ( sum_color * sum_color ) / ( num Rays * ( num Rays - 1));	

444	vec3 s = variance - m;	

445	vec3 final_s =	sqrt ( s) / num Rays ;	
446		

447	// Normalize final_s	

448	vec3 normalized_s = final_s / sqrt ( sum_color / num Rays );	
449	// Write the maximum component	
d_s . g),  normalized_s . b);





454	if ( final_s <= epsilon && count >= step_check )
455	return true ; // Skip pixel , stop calculation
456	else
457	return false ; // Continue the calculation in pixels

458	}	
459		

460	void	main(){

461		ivec2 texel Coord = ivec2 ( gl_Global Invocation ID . xy);

462		vec2 coordinates = texel Coord / texture_size ;

463		float seed = sin ( uTime );
464		

465	float rand = Noise ( seed * coordinates );
466	// Add jitter
467	vec2  random Jitter  =  vec2 ( Hash ( 91. 5* rand +15. 6* rand +15. 1* uTime
),  Hash(11. 6* rand +91. 1* rand +17. 8* uTime ));
468	// Used in the direction of the primary ray for a nicer sampling
469	vec2 pixel Size = (1./ texture_size );
470	vec2 jitter = vec2 ( pixel Size *( random Jitter -.5) );
471	coordinates += jitter ;
472


473	Initialize Scene ();
474	// Determining the direction of the beam
475		vec3 direction = Get Ray Direction ( coordinates , texture_size , uFOV ,uDirection , uUp );
476	vec4 total Color = image Load ( image Texture , texel Coord );
477		vec4 pixel Parameters = image Load ( pixel Parameters Texture , texel Coord );
478


479	if ( skip_pixel ( pixel Parameters .a,  total Color . a))
480	return;

481


482	Ray  r= Ray ( uPosition , direction );
483	total Color . a += 1. f;
484	vec3 sample Color = Trace Path (r, seed , coordinates );
485	total Color . rgb += sample Color ;
486


487	// Save image
488	image Store ( image Texture , texelCoord , total Color );
489


490		pixel Parameters . rgb += sample Color * sample Color ; // Sum of colorsquares
491	pixel Parameters . a = calculate Std Dev ( total Color . rgb , pixel Parameters . rgb ,total Color . a);
492	image Store ( pixel Parameters Texture , texelCoord , pixel Parameters );
493 }

Листинг 3. Вычислительный шейдер (path_tracing_cs.glsl)

1 # version 430 core
2 out vec4 Frag Color ;
3


4 in vec2 Tex Coords ;
5

6 uniform	float	epsilon ;
7 uniform	float	step_check ;
8 uniform	float	button_value ;

9


10 uniform sampler 2 D image Texture ;
11 uniform  sampler 2 D pixel Parameters Texture ;
12


13 void main ()
14 {

15	vec4 data = texture ( image Texture , Tex Coords );
16	vec4 pixel Parameters = texture ( pixel Parameters Texture , Tex Coords );

17	//	Change the render mode ( use ’ c’ key )

18	if	( button_value == 0.0) {

19		vec3 color = data . rgb / data . a;

20		color  = color /( color + vec3 (1.) );

21		color  = pow ( color , vec3 ( 1./ 2. 2 ) );

22		Frag Color = vec4 ( color , 1.0) ;
23		} else {

24		float eps = pixel Parameters . a;

25		if( eps < epsilon )

26		Frag Color = vec4 (0.0 , 1.0 , 0.0 , 1.0) ;
27		else {

28		float value = log ( eps / epsilon )/ log ( 10. 0) ;

29		Frag Color = vec4 ( value , 0.0 , 0.0 , 1.0) ;
30		}

31	}	

32 }


Листинг 4. Фрагментный шейдер (render_fs.glsl)


1 # include " scene . hpp "
2 # include " shader_program_impl . hpp "
3 # include <cmath >
4


5 # include <ft2build .h>
6 # include  FT_FREETYPE_H
7 # include <map >
8


9 # include <filesystem >
10


11 class Path Tracing : public Scene {

12	std :: unique_ptr < Make_Shader Program <1 >:: type >	compute SP ;

13	std :: unique_ptr < Make_Shader Program <2 >:: type >	render SP ;

14	std :: unique_ptr < Make_Shader Program <2 >:: type >	text SP ;
15	float t;	

16	double last Time ;	
17		

18	const float epsilon = 0.001;	

19	const float step_check = 100;	
20		

21	int frame Count = 0;	

22	double time At Frame = 0.0;	

23	bool has Reached Frame = false ;	
24		

25	unsigned int image Texture ;	

26	unsigned int pixel Parameters Texture ;	

27	unsigned int quad VAO ;	

28	unsigned int quad VBO ;	
29		

30	std :: map < GLchar , Character > Characters ;	

31	unsigned int VAO , VBO ;	

32


33 public:
34	Path Tracing ( std :: string const & windowTitle , int width , int
35	height ) : Scene ( windowTitle , width , height ), t (0) , last Time
36	(0) , quad VAO (0) {
37	camera Pos = glm :: vec3 (0. f, 0. f, 2. f);
38	camera Front = glm :: vec3 (0. f, 0. f, -1. f);
39	camera Up = glm :: vec3 (0. f, 1. f, 0. f);
40


41	# ifndef NDEBUG

42	std :: cout  << __PRETTY_FUNCTION   << std :: endl ;
43	# endif
44	}
45	
46	void Init Scene () override {
47	compute SP  =  std :: make_unique < Make_Shader Program <1 >:: type >(
48	Shader (" shaders / path_tracing_cs . glsl ", GL_COMPUTE_SHADER ));
49	render SP  = std :: make_unique < Make_Shader Program <2 >:: type >(
50	Shader (" shaders / render_vs . glsl ",  GL_VERTEX_SHADER ),
51	Shader (" shaders / render_fs . glsl ", GL_FRAGMENT_SHADER ));
52	
53	text SP = std :: make_unique < Make_Shader Program <2 >:: type >(
54	Shader (" shaders / text_vs . glsl ", GL_VERTEX_SHADER ),
55	Shader (" shaders / text_fs . glsl ", GL_FRAGMENT_SHADER ));
56	
57	init Quad ();
58	init Texture ();
59	gl Clear Color (1 , 1 , 1 , 1);
60	
61	gl Enable ( GL_BLEND );
62	gl Blend Func ( GL_SRC_ALPHA , GL_ONE_MINUS_SRC_ALPHA );
63	}
64	
65	void info () {
66	// Query limitations
67	int	max_compute_work_group_count [3];
68	int	max_compute_work_group_size [3];
69	int	max_compute_work_group_invocations ;
70	
71	for ( int idx = 0; idx < 3; idx ++) {
72	gl Get Integeri_v ( GL_MAX_COMPUTE_WORK_GROUP_COUNT ,
73	idx , & max_compute_work_group_count [ idx ]);
74	gl Get Integeri_v ( GL_MAX_COMPUTE_WORK_GROUP_SIZE ,
75	idx , & max_compute_work_group_size [ idx ]);
76	}

77	gl Get Integerv ( GL_MAX_COMPUTE_WORK_GROUP_INVOCATIONS ,  &
78	max_compute_work_group_invocations );
79	
80	std :: cout << " Open GL Limitations : " << std :: endl ;
81	std :: cout << " maximum number of work groups in X
82	dimension " << max_compute_work_group_count [0] << std :: endl ;
83	std :: cout << " maximum number of work groups in Y
84	dimension " << max_compute_work_group_count [1] << std :: endl ;
85	std :: cout << " maximum number of work groups in Z
86	dimension " << max_compute_work_group_count [2] << std :: endl ;
87	

88	std :: cout << " maximum size of a work group in X

89	dimension " << max_compute_work_group_size [0] << std :: endl ;
90	std :: cout << " maximum size of a work group in Y

91	dimension " << max_compute_work_group_size [1] <<

92	std :: endl ;

93	std :: cout << " maximum size of a work group in Z

94	dimension " << max_compute_work_group_size [2] <<
95	std :: endl ;
96	

97	std :: cout << " Number of invocations in a single local

98	work group that may " " be dispatched to a compute

99	shader " << max_compute_work_group_invocations  << std :: endl ;

100	}

101	

102	void init Texture () {

103	// Create image Texture for Open GL operation

104	{

105	gl Gen Textures (1 , & image Texture );

106	gl Active Texture ( GL_TEXTURE 0 );

107	gl Bind Texture ( GL_TEXTURE_2D , image Texture );
108	gl Tex Parameteri ( GL_TEXTURE_2D , GL_TEXTURE_WRAP_S , GL_CLAMP_TO_EDGE );

109	gl Tex Parameteri ( GL_TEXTURE_2D , GL_TEXTURE_WRAP_T , GL_CLAMP_TO_EDGE );

110	gl Tex Parameteri ( GL_TEXTURE_2D , GL_TEXTURE_MAG_FILTER , GL_LINEAR );

111	gl Tex Parameteri ( GL_TEXTURE_2D , GL_TEXTURE_MIN_FILTER , GL_LINEAR );

112	gl Tex Image 2 D ( GL_TEXTURE_2D , 0 , GL_RGBA32F , WIDTH ,

113	HEIGHT , 0 , GL_RGBA , GL_FLOAT , NULL );
114	

115	gl Bind Image Texture (0 , image Texture , 0 , GL_FALSE , 0 ,

116	GL_READ_WRITE , GL_RGBA 32 F );
117	


118		gl Active Texture ( GL_TEXTURE 0 );

119		gl Bind Texture ( GL_TEXTURE_2D , image Texture );

120		gl Clear Tex Image ( image Texture , 0 , GL_RGBA , GL_FLOAT , nullptr );
121	}	

122	//	Create texture for Open GL operation

123	{	

124		gl Gen Textures (1 , & pixel Parameters Texture );

125		gl Active Texture ( GL_TEXTURE 1 );

126		gl Bind Texture ( GL_TEXTURE_2D , pixel Parameters Texture );

127		gl Tex Parameteri ( GL_TEXTURE_2D , GL_TEXTURE_WRAP_S , GL_CLAMP_TO_EDGE );
128		gl Tex Parameteri ( GL_TEXTURE_2D , GL_TEXTURE_WRAP_T ,
GL_CLAMP_TO_EDGE );
129		gl Tex Parameteri ( GL_TEXTURE_2D , GL_TEXTURE_MAG_FILTER , GL_LINEAR );
130		gl Tex Parameteri ( GL_TEXTURE_2D , GL_TEXTURE_MIN_FILTER , GL_LINEAR );
131		gl Tex Image 2 D ( GL_TEXTURE_2D , 0 , GL_RGBA32F , WIDTH ,

132		HEIGHT , 0, GL_RGBA ,	GL_FLOAT , NULL );

133	

134		gl Bind Image Texture (1 , pixel Parameters Texture , 0 ,	

135		GL_FALSE , 0 , GL_READ_WRITE , GL_RGBA 32 F );	
136			

137		gl Active Texture ( GL_TEXTURE 1 );	

138		gl Bind Texture ( GL_TEXTURE_2D , pixel Parameters Texture );	

139		gl Clear Tex Image ( pixel Parameters Texture , 0 , GL_RGBA ,	
		GL_FLOAT ,nullptr );	
140	}		
141			

142	{		

143		// Free Type	

144		FT_Library ft;	

145



146		// All functions return a value different than 0 whenever error
// occurred	an

147	if ( FT_Init_Free Type (& ft)) {
148	std :: cout << " ERROR :: FREETYPE : Could not init
149	Free Type Library " << std :: endl ;
150	exit(1);
151	}

152


153	// Find path to font
154	std :: string  font_name  = std :: string (" fonts / Antonio - Bold . ttf ");
155	if ( font_name . empty ()) {
156	std :: cout << " ERROR :: FREETYPE : Failed to load
157	font_name " << std :: endl ;
158	exit(1);
159	}

160	// Load font as face
161	FT_Face  face;
162	if ( FT_New_Face ( ft , font_name . c_str () , 0 , & face )) {
163	std :: cout << " ERROR :: FREETYPE : Failed to load
164	font " << std :: endl ;
165	exit(1);
166	} else {
167	// Set size to load glyphs as
168	FT_Set_Pixel_Sizes ( face , 0 , 48) ;
169


170	// Disable byte - alignment  restriction
171	gl Pixel Storei ( GL_UNPACK_ALIGNMENT , 1);
172


173	// load first 128 characters of ASCII set
174	for ( unsigned char c = 0; c < 128; c ++) {
175	// Load character glyph
176	if ( FT_Load_Char ( face , c, FT_LOAD_RENDER )) {
177	std :: cout << " ERROR :: FREETYPE : Failed to
178	load Glyph " << std :: endl ;
179	continue;
180	}

181	// Generate texture
182	unsigned int texture ;
183	gl Gen Textures (1 , & texture );
184	gl Bind Texture ( GL_TEXTURE_2D ,  texture );

185		gl Tex Image 2D ( GL_TEXTURE_2D , 0 , GL_RED ,

186		face - >glyph - > bitmap . width , face - >glyph - > bitmap .

187		rows , 0 , GL_RED , GL_UNSIGNED_BYTE ,

188		face - >glyph - > bitmap . buffer );

189		// Set texture options

190		gl Tex Parameteri ( GL_TEXTURE_2D ,

191		GL_TEXTURE_WRAP_S , GL_CLAMP_TO_EDGE );

192		gl Tex Parameteri ( GL_TEXTURE_2D ,

193		GL_TEXTURE_WRAP_T , GL_CLAMP_TO_EDGE );

194		gl Tex Parameteri ( GL_TEXTURE_2D ,

195		GL_TEXTURE_MIN_FILTER , GL_LINEAR );

196		gl Tex Parameteri ( GL_TEXTURE_2D ,

197		GL_TEXTURE_MAG_FILTER , GL_LINEAR );

198		// Now store character for later use

199		Character character = {
200		texture,

201		glm :: ivec2 ( face - >glyph - > bitmap . width ,
202		face - >glyph - > bitmap . rows ),

203		glm :: ivec2 ( face - >glyph - > bitmap_left ,

204		face - >glyph - > bitmap_top ),

205		static_cast < unsigned int >

206		( face - >glyph - > advance . x)};

207		Characters . insert ( std :: pair <char , Character >

208		(c, character ));
209	}	

210	gl Bind Texture ( GL_TEXTURE_2D , 2);
211	}

212	// Destroy Free Type once we ’ re finished

213	FT_Done_Face ( face );

214	FT_Done_Free Type ( ft);
215	

216	// Configure VAO / VBO for texture quads

217	gl Gen Vertex Arrays (1 , & VAO );

218	gl Gen Buffers (1 , & VBO );				

219	gl Bind Vertex Array ( VAO );				

220	gl Bind Buffer ( GL_ARRAY_BUFFER , VBO );			

221	gl Buffer Data ( GL_ARRAY_BUFFER , sizeof ( float ) * 6	*	4 ,	

222	NULL , GL_DYNAMIC_DRAW );				

223	gl Enable Vertex Attrib Array (0) ;				

224	gl Vertex Attrib Pointer (0 , 4 , GL_FLOAT , GL_FALSE ,	4	*	

225	sizeof ( float ), 0);				

226	gl Bind Buffer ( GL_ARRAY_BUFFER , 0);			

227	gl Bind Vertex Array (0) ;				

228	}				

229	}				
230					

231	void update ( float t_) {				

232	t += t_;				

233	}				
234					

235	void Clear Buffers () override {				

236	Scene :: Clear Buffers ();				

237	t = 0;				
238					

239	gl Clear Tex Image ( image Texture ,	0 , GL_RGBA , GL_FLOAT ,	nullptr );

240	gl Clear Tex Image ( image Texture ,	0 , GL_RGBA , GL_FLOAT ,	nullptr );

241	}		
242			

243	void Render () override {

244	double current Time = glfw Get Time ();

245	double delta Time = current Time - last Time ;

246	last Time = current Time ;

247	update (1) ;

248	frame Count ++;

249	// Render image to quad

250	gl Clear ( GL_COLOR_BUFFER_BIT	| GL_DEPTH_BUFFER_BIT );
251	

252	computeSP - > use ();

253	computeSP - > set Value (" t", glUniform1f , t);
254	computeSP - > set Value (" texture_size ",  glUniform2f ,

255	static_cast <float >( WIDTH ), static_cast <float >( HEIGHT ));
256		computeSP - > set Value (" u Position ", gl Uniform3fv , 1 , & camera Pos[0]) ;
257		computeSP - > set Value (" u Direction ", gl Uniform3fv , 1 , & camera Front [0]) ;
258	computeSP - > set Value (" uUp ", gl Uniform3fv , 1 , & camera Up [0]) ;
259


260	computeSP - > set Value (" button_value ",  glUniform1f ,
261	Scene :: button_value );// Button
262	computeSP - > set Value (" epsilon ",  glUniform1f , epsilon );// Button
263	computeSP - > set Value (" step_check ",  glUniform1f , step_check );
264


265	gl Dispatch Compute (( unsigned int ) WIDTH / 10 , ( unsigned
266	int ) HEIGHT / 10 , 1);
267	// Make sure writing to image has finished before read
268	gl Memory Barrier ( GL_SHADER_IMAGE_ACCESS_BARRIER_BIT );
269


270	renderSP - > use ();
271	renderSP - > set Value (" image Texture ", glUniform1i , 0);
272	renderSP - > set Value (" pixel Parameters Texture ",  glUniform1i , 1);
273	renderSP - > set Value (" texture_width ",  glUniform1f ,
274	static_cast <float >( WIDTH ));
275	renderSP - > set Value (" texture_height ",  glUniform1f ,
276	static_cast <float >( HEIGHT ));
277


278	renderSP - > set Value (" button_value ",  glUniform1f ,
279	Scene :: button_value );// Button
280	renderSP - > set Value (" epsilon ", glUniform1f , epsilon );
281


282	// Render Quad
283	gl Bind Vertex Array ( quad VAO );
284	gl Draw Arrays ( GL_TRIANGLE_STRIP , 0 , 4);
285	gl Bind Vertex Array (0) ;
286	

287	// Text SP

288	Render Text (" Path  Tracing ", 25.0 f, 25.0 f, 1.0 f,		

289	glm :: vec3 (0. f, 1. f, 0. f));		

290	Render Text (( std :: string (" Frame Count : ") +		

291	std :: to_string ( static_cast <int >( t))  + std :: string ("		

292	FPS : ") + std :: to_string ( static_cast <int >( round (1.0 /		

293	delta Time )))). c_str () , 5. f, HEIGHT - 25. f,		

294	0.5 f, glm :: vec3 (0. f, 0. f, 1. f));		
295			

296	if ( t == 1) has Reached Frame = false ; // For mouse move	

297	if (( static_cast <int >( t) % 10000 == 0) && ! has Reached Frame )	{

298	// Remember the time to reach frame 1000	

299	time At Frame = current Time ;	

300	std :: cout << " Time " << time At Frame << " sec at	

301	frame " << t << std :: endl ;	

302	if ( t == 100000) {	

303	Save Image (" images ", " picture_ " + std :: to_string	

304	( current Time ));		

305	has Reached Frame = true ; // Flag to not update		

306	// time again after 10000		

307	}		

308	}		

309	}		
310			

311	// render Quad () renders a 1 x1 XY quad in NDC		

312	void init Quad () {		

313	// Each vertex consists of		

314	// positions (3 elements ),		

315	// texture coordinates (2 elements ).		

316	float quad Vertices [] = {		
317	-1.0 f, 1.0 f, 0.0 f, 0.0 f, 1.0 f, -1.0 f, -1.0 f,
0.0 f, 0.0 f, 0.0 f, 1.0 f,  1.0 f, 0.0 f, 1.0 f,		
318	1.0 f, 1.0 f, -1.0 f, 0.0 f, 1.0 f, 0.0 f,		

319	};		
320	// setup plane VAO		

321	gl Gen Vertex Arrays (1 , & quad VAO );		

322	gl Gen Buffers (1 , & quad VBO );		

323	gl Bind Vertex Array ( quad VAO );		

324	gl Bind Buffer ( GL_ARRAY_BUFFER , quad VBO );		
325	gl Buffer Data ( GL_ARRAY_BUFFER , sizeof ( quad Vertices ),	&	

326	quad Vertices , GL_STATIC_DRAW );

327	gl Enable Vertex Attrib Array (0) ;

328	gl Vertex Attrib Pointer (0 , 3 , GL_FLOAT , GL_FALSE , 5 *

329	sizeof ( float ), ( void *) 0);

330	gl Enable Vertex Attrib Array (1) ;

331	gl Vertex Attrib Pointer (1 , 2 , GL_FLOAT , GL_FALSE , 5 *

332	sizeof ( float ), ( void *) (3 * sizeof ( float )));

333	}
334	

335	~ Path Tracing () {

336	gl Delete Textures (1 , & image Texture );

337	gl Delete Textures (1 , & pixel Parameters Texture );

338	# ifndef NDEBUG
339	std :: cout <<   PRETTY_FUNCTION   << std :: endl;

340		#endif

341	}	
342		

343	void	Render Text ( std :: string text , float x, float y, float
344	scale , glm :: vec3 color ) {
345	glm :: mat4  projection  = glm :: ortho (0.0 f,
346	static_cast <float >( WIDTH ),  0.0 f,  static_cast <float >( HEIGHT ));
347	textSP - > use ();
348	textSP - > set Value (" projection ",  gl Uniform Matrix 4 fv , 1 ,
349	GL_FALSE , & projection [ 0][ 0]) ;
350	textSP - > set Value (" text Color ", gl Uniform3fv , 1 , & color [0]) ;
351	textSP - > set Value (" text Texture ", glUniform1i , 2);
352	gl Active Texture ( GL_TEXTURE 2 );
353	gl Bind Vertex Array ( VAO );
354


355	// Iterate through all characters
356	std :: string :: const_iterator c;
357	for ( c = text . begin (); c != text . end (); c ++) {
358	Character ch = Characters [* c];
359


360	float xpos = x + ch. Bearing . x * scale ;
361	float ypos = y - ( ch. Size . y - ch. Bearing . y) * scale ;

362		

363	float w = ch. Size . x * scale ;	

364	float h = ch. Size . y * scale ;	

365	// Update VBO for each character	
366	float vertices [ 6][ 4] = {	

367	{ xpos , ypos + h, 0.0 f, 0.0 f},	{ xpos , ypos , 0.0 f, 1.0 f},

368	{ xpos + w, ypos , 1.0 f, 1.0 f},	{ xpos , ypos + h, 0.0 f,
	0.0 f},	

369	{ xpos + w, ypos , 1.0 f, 1.0 f},	{ xpos + w,

370	ypos + h, 1.0 f, 0.0 f}	

371	};

372	// Render glyph texture over quad
373	gl Bind Texture ( GL_TEXTURE_2D ,  ch. Texture ID );
374	// Update content of VBO memory
375	gl Bind Buffer ( GL_ARRAY_BUFFER , VBO );
376	// Be sure to use gl Buffer Sub Data and not gl Buffer Data
377		gl Buffer Sub Data ( GL_ARRAY_BUFFER , 0 , sizeof ( vertices ), vertices );
378	gl Bind Buffer ( GL_ARRAY_BUFFER , 0);
379	// Render quad
380	gl Draw Arrays ( GL_TRIANGLES , 0, 6);
381	// Now advance cursors for next glyph ( note that
382	// advance is number of 1/64 pixels )

383		x += ( ch. Advance >> 6) * scale ;
384		}

385		gl Bind Vertex Array (0) ;

386		gl Bind Texture ( GL_TEXTURE_2D , 0);
387
388 };	}
389		

390	int	main () {

391		Path Tracing scene (" Path Tracing ", 800 , 800) ;

392		scene . Render Loop ();

393		return 0;

394	}	
		Листинг 5. Исходный файл (main.cpp)
